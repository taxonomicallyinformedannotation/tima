---
title: "3 Formatting all inputs"
author: "Adriano Rutz"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{3 Formatting all inputs}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
knitr::opts_knit$set(root.dir = "..")
```

This vignette describes how to format all your files.

## Structural annotations of your features

For the moment, we support annotations coming from 3 different annotation tools: 

* [GNPS](https://gnps.ucsd.edu)
* [SIRIUS](https://bio.informatik.uni-jena.de/software/sirius)
* Formatted results of **ISDB** annotation.

In order to perform MS2 annotation based on an **I**n **S**ilico **D**ata**B**ase, please follow the following steps. 

### ISDB

```{r}
library("timaR")
```

```{r}
source(file = "inst/scripts/prepare_isdb_lotus.R")
```

```{r}
source(file = "inst/scripts/process_spectra.R")
```

In case, a python implementation of the spectral matching steps is also available at: <https://github.com/mandelbrot-project/spectral_lib_matcher>.
The python version also includes more elaborated similarity measures.

### Sirius, GNPS, and others

For Sirius and GNPS, please follow their own documentation.
If you have some annotations coming from a different tool, please format them as the provided examples.

#### SIRIUS

As SIRIUS jobs are long to perform, we provide an already computed SIRIUS Workspace.
It has beeen generated on the same MGF as the GNPS and ISDB jobs with the following command:

```{bash eval=FALSE, include=TRUE}
config --IsotopeSettings.filter true --FormulaSearchDB BIO,COCONUT,GNPS,KNAPSACK,UNDP,PLANTCYC --Timeout.secondsPerTree 0 --FormulaSettings.enforced HCNOP --Timeout.secondsPerInstance 0 --AdductSettings.detectable [[M + H3N + H]+, [M - H2O + H]+, [M + K]+, [M - H4O2 + H]+, [M + H]+, [M + Na]+] --UseHeuristic.mzToUseHeuristicOnly 650 --AlgorithmProfile orbitrap --IsotopeMs2Settings IGNORE --MS2MassDeviation.allowedMassDeviation 5.0ppm --NumberOfCandidatesPerIon 1 --UseHeuristic.mzToUseHeuristic 300 --FormulaSettings.detectable B,Cl,Br,Se,S --NumberOfCandidates 10 --ZodiacNumberOfConsideredCandidatesAt300Mz 10 --ZodiacRunInTwoSteps true --ZodiacEdgeFilterThresholds.minLocalConnections 10 --ZodiacEdgeFilterThresholds.thresholdFilter 0.95 --ZodiacEpochs.burnInPeriod 2000 --ZodiacEpochs.numberOfMarkovChains 10 --ZodiacNumberOfConsideredCandidatesAt800Mz 50 --ZodiacEpochs.iterations 20000 --AdductSettings.enforced , --AdductSettings.fallback [[M + K]+, [M + H]+, [M + Na]+] --FormulaResultThreshold true --InjectElGordoCompounds true --StructureSearchDB BIO,COCONUT,GNPS,KNAPSACK,UNDP,PLANTCYC --RecomputeResults false formula zodiac fingerprint structure canopus
```

These parameters were not optimized and were only used to give an example output.

Then, the summaries have been generated using:

```{bash eval=FALSE, include=TRUE}
sirius -i inst/extdata/interim/annotations/sirius_example/ write-summaries -c --digits 3
```

You can get the example running:

```{r}
source(file = "inst/scripts/get_example_sirius.R")
```

#### GNPS

We also provide an example GNPS job id, which is: `96fa7c88200e4a03bee4644e581e3fb0`

### Formatting

Before running the corresponding code, do not forget to modify `config/params/prepare_*yourAnnotationTool*.yaml`.

Depending on the annotation tool you used, you can format its results using:

```{r}
source(file = "inst/scripts/prepare_gnps.R")
```

and/or

```{r}
source(file = "inst/scripts/prepare_spectral_matches.R")
```

and/or

```{r}
source(file = "inst/scripts/prepare_sirius.R")
```

You now have your annotations well prepared and can keep on formatting the rest of your metadata.

## Chemical class annotation of your features

Within our workflow, we offer a new way to attribute chemical classes to your features.
It is analog to [Network Annotation Propagation](https://ccms-ucsd.github.io/GNPSDocumentation/nap/), but uses the edges of your network instead of the clusters.
This makes more sense in our view, as also recently illustrated by [CANOPUS](https://doi.org/10.1038/s41587-020-0740-8).

All steps can take both manual inputs or GNPS metadata directly from your GNPS job ID.

We are currently also working on CANOPUS integration for chemical class annotation but this implies way heavier computations and we want to offer our users a **fast** solution.

### Case when no network available

If no network was generated, simply use the `fake_edges` and `fake_features_components` steps instead of the `prepare_edges` and `prepare_features_components` steps.
This will mimic a false network that allows to proceed to the next steps.
However, this will not help chemical weighting.

If needed, you can get an example of what your minimal feature table should look like by running (no parameters needed):

```{r}
source(file = "inst/scripts/get_example_features.R")
```

### Formatting

Before running the corresponding code, do not forget to modify `config/params/prepare_edges.yaml`, `config/params/prepare_features_components.yaml`, and `config/params/prepare_features_classification.yaml` accordingly.

```{r}
source(file = "inst/scripts/prepare_edges.R")
```

```{r}
source(file = "inst/scripts/prepare_features_components.R")
```

```{r}
source(file = "inst/scripts/prepare_features_classification.R")
```

Your features are now not only informed with structural information but also, chemical class information.
The latter might be corresponding **or not** to the chemical class of your annotated structure, depending on the consistency of your annotations.

## Biological source annotation

This step allows you to attribute biological source information to your features.
If all your features come from a single extract, it will attribute the biological source of your extract to all your features.
If you have multiple extracts aligned, it will take the *n* (according to your parameters) highest intensities of your aligned feature table and attribute the biological source of corresponding extracts.
It can take both manual inputs or GNPS metadata directly from your GNPS job ID.

Before running the corresponding code, do not forget to modify `config/params/prepare_taxa.yaml`.

```{r}
source(file = "inst/scripts/prepare_taxa.R")
```

We now recommend you to read the [next vignette](https://taxonomicallyinformedannotation.github.io/tima-r/articles/IV-processing.html).
