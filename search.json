[
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "GNU Affero General Public License",
    "section": "",
    "text": "Version 3, 19 November 2007 Copyright (C) 2007 Free Software Foundation, Inc. &lt;https://fsf.org/&gt;\nEveryone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.\n\n\nThe GNU Affero General Public License is a free, copyleft license for software and other kinds of works, specifically designed to ensure cooperation with the community in the case of network server software.\nThe licenses for most software and other practical works are designed to take away your freedom to share and change the works. By contrast, our General Public Licenses are intended to guarantee your freedom to share and change all versions of a program–to make sure it remains free software for all its users.\nWhen we speak of free software, we are referring to freedom, not price. Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for them if you wish), that you receive source code or can get it if you want it, that you can change the software or use pieces of it in new free programs, and that you know you can do these things.\nDevelopers that use our General Public Licenses protect your rights with two steps: (1) assert copyright on the software, and (2) offer you this License which gives you legal permission to copy, distribute and/or modify the software.\nA secondary benefit of defending all users’ freedom is that improvements made in alternate versions of the program, if they receive widespread use, become available for other developers to incorporate. Many developers of free software are heartened and encouraged by the resulting cooperation. However, in the case of software used on network servers, this result may fail to come about. The GNU General Public License permits making a modified version and letting the public access it on a server without ever releasing its source code to the public.\nThe GNU Affero General Public License is designed specifically to ensure that, in such cases, the modified source code becomes available to the community. It requires the operator of a network server to provide the source code of the modified version running there to the users of that server. Therefore, public use of a modified version, on a publicly accessible server, gives the public access to the source code of the modified version.\nAn older license, called the Affero General Public License and published by Affero, was designed to accomplish similar goals. This is a different license, not a version of the Affero GPL, but Affero has released a new version of the Affero GPL which permits relicensing under this license.\nThe precise terms and conditions for copying, distribution and modification follow.\n\n\n\n\n\n“This License” refers to version 3 of the GNU Affero General Public License.\n“Copyright” also means copyright-like laws that apply to other kinds of works, such as semiconductor masks.\n“The Program” refers to any copyrightable work licensed under this License. Each licensee is addressed as “you”. “Licensees” and “recipients” may be individuals or organizations.\nTo “modify” a work means to copy from or adapt all or part of the work in a fashion requiring copyright permission, other than the making of an exact copy. The resulting work is called a “modified version” of the earlier work or a work “based on” the earlier work.\nA “covered work” means either the unmodified Program or a work based on the Program.\nTo “propagate” a work means to do anything with it that, without permission, would make you directly or secondarily liable for infringement under applicable copyright law, except executing it on a computer or modifying a private copy. Propagation includes copying, distribution (with or without modification), making available to the public, and in some countries other activities as well.\nTo “convey” a work means any kind of propagation that enables other parties to make or receive copies. Mere interaction with a user through a computer network, with no transfer of a copy, is not conveying.\nAn interactive user interface displays “Appropriate Legal Notices” to the extent that it includes a convenient and prominently visible feature that (1) displays an appropriate copyright notice, and (2) tells the user that there is no warranty for the work (except to the extent that warranties are provided), that licensees may convey the work under this License, and how to view a copy of this License. If the interface presents a list of user commands or options, such as a menu, a prominent item in the list meets this criterion.\n\n\n\nThe “source code” for a work means the preferred form of the work for making modifications to it. “Object code” means any non-source form of a work.\nA “Standard Interface” means an interface that either is an official standard defined by a recognized standards body, or, in the case of interfaces specified for a particular programming language, one that is widely used among developers working in that language.\nThe “System Libraries” of an executable work include anything, other than the work as a whole, that (a) is included in the normal form of packaging a Major Component, but which is not part of that Major Component, and (b) serves only to enable use of the work with that Major Component, or to implement a Standard Interface for which an implementation is available to the public in source code form. A “Major Component”, in this context, means a major essential component (kernel, window system, and so on) of the specific operating system (if any) on which the executable work runs, or a compiler used to produce the work, or an object code interpreter used to run it.\nThe “Corresponding Source” for a work in object code form means all the source code needed to generate, install, and (for an executable work) run the object code and to modify the work, including scripts to control those activities. However, it does not include the work’s System Libraries, or general-purpose tools or generally available free programs which are used unmodified in performing those activities but which are not part of the work. For example, Corresponding Source includes interface definition files associated with source files for the work, and the source code for shared libraries and dynamically linked subprograms that the work is specifically designed to require, such as by intimate data communication or control flow between those subprograms and other parts of the work.\nThe Corresponding Source need not include anything that users can regenerate automatically from other parts of the Corresponding Source.\nThe Corresponding Source for a work in source code form is that same work.\n\n\n\nAll rights granted under this License are granted for the term of copyright on the Program, and are irrevocable provided the stated conditions are met. This License explicitly affirms your unlimited permission to run the unmodified Program. The output from running a covered work is covered by this License only if the output, given its content, constitutes a covered work. This License acknowledges your rights of fair use or other equivalent, as provided by copyright law.\nYou may make, run and propagate covered works that you do not convey, without conditions so long as your license otherwise remains in force. You may convey covered works to others for the sole purpose of having them make modifications exclusively for you, or provide you with facilities for running those works, provided that you comply with the terms of this License in conveying all material for which you do not control copyright. Those thus making or running the covered works for you must do so exclusively on your behalf, under your direction and control, on terms that prohibit them from making any copies of your copyrighted material outside their relationship with you.\nConveying under any other circumstances is permitted solely under the conditions stated below. Sublicensing is not allowed; section 10 makes it unnecessary.\n\n\n\nNo covered work shall be deemed part of an effective technological measure under any applicable law fulfilling obligations under article 11 of the WIPO copyright treaty adopted on 20 December 1996, or similar laws prohibiting or restricting circumvention of such measures.\nWhen you convey a covered work, you waive any legal power to forbid circumvention of technological measures to the extent such circumvention is effected by exercising rights under this License with respect to the covered work, and you disclaim any intention to limit operation or modification of the work as a means of enforcing, against the work’s users, your or third parties’ legal rights to forbid circumvention of technological measures.\n\n\n\nYou may convey verbatim copies of the Program’s source code as you receive it, in any medium, provided that you conspicuously and appropriately publish on each copy an appropriate copyright notice; keep intact all notices stating that this License and any non-permissive terms added in accord with section 7 apply to the code; keep intact all notices of the absence of any warranty; and give all recipients a copy of this License along with the Program.\nYou may charge any price or no price for each copy that you convey, and you may offer support or warranty protection for a fee.\n\n\n\nYou may convey a work based on the Program, or the modifications to produce it from the Program, in the form of source code under the terms of section 4, provided that you also meet all of these conditions:\n\n\nThe work must carry prominent notices stating that you modified it, and giving a relevant date.\n\n\nThe work must carry prominent notices stating that it is released under this License and any conditions added under section 7. This requirement modifies the requirement in section 4 to “keep intact all notices”.\n\n\nYou must license the entire work, as a whole, under this License to anyone who comes into possession of a copy. This License will therefore apply, along with any applicable section 7 additional terms, to the whole of the work, and all its parts, regardless of how they are packaged. This License gives no permission to license the work in any other way, but it does not invalidate such permission if you have separately received it.\n\n\nIf the work has interactive user interfaces, each must display Appropriate Legal Notices; however, if the Program has interactive interfaces that do not display Appropriate Legal Notices, your work need not make them do so.\n\n\nA compilation of a covered work with other separate and independent works, which are not by their nature extensions of the covered work, and which are not combined with it such as to form a larger program, in or on a volume of a storage or distribution medium, is called an “aggregate” if the compilation and its resulting copyright are not used to limit the access or legal rights of the compilation’s users beyond what the individual works permit. Inclusion of a covered work in an aggregate does not cause this License to apply to the other parts of the aggregate.\n\n\n\nYou may convey a covered work in object code form under the terms of sections 4 and 5, provided that you also convey the machine-readable Corresponding Source under the terms of this License, in one of these ways:\n\n\nConvey the object code in, or embodied in, a physical product (including a physical distribution medium), accompanied by the Corresponding Source fixed on a durable physical medium customarily used for software interchange.\n\n\nConvey the object code in, or embodied in, a physical product (including a physical distribution medium), accompanied by a written offer, valid for at least three years and valid for as long as you offer spare parts or customer support for that product model, to give anyone who possesses the object code either (1) a copy of the Corresponding Source for all the software in the product that is covered by this License, on a durable physical medium customarily used for software interchange, for a price no more than your reasonable cost of physically performing this conveying of source, or (2) access to copy the Corresponding Source from a network server at no charge.\n\n\nConvey individual copies of the object code with a copy of the written offer to provide the Corresponding Source. This alternative is allowed only occasionally and noncommercially, and only if you received the object code with such an offer, in accord with subsection 6b.\n\n\nConvey the object code by offering access from a designated place (gratis or for a charge), and offer equivalent access to the Corresponding Source in the same way through the same place at no further charge. You need not require recipients to copy the Corresponding Source along with the object code. If the place to copy the object code is a network server, the Corresponding Source may be on a different server (operated by you or a third party) that supports equivalent copying facilities, provided you maintain clear directions next to the object code saying where to find the Corresponding Source. Regardless of what server hosts the Corresponding Source, you remain obligated to ensure that it is available for as long as needed to satisfy these requirements.\n\n\nConvey the object code using peer-to-peer transmission, provided you inform other peers where the object code and Corresponding Source of the work are being offered to the general public at no charge under subsection 6d.\n\n\nA separable portion of the object code, whose source code is excluded from the Corresponding Source as a System Library, need not be included in conveying the object code work.\nA “User Product” is either (1) a “consumer product”, which means any tangible personal property which is normally used for personal, family, or household purposes, or (2) anything designed or sold for incorporation into a dwelling. In determining whether a product is a consumer product, doubtful cases shall be resolved in favor of coverage. For a particular product received by a particular user, “normally used” refers to a typical or common use of that class of product, regardless of the status of the particular user or of the way in which the particular user actually uses, or expects or is expected to use, the product. A product is a consumer product regardless of whether the product has substantial commercial, industrial or non-consumer uses, unless such uses represent the only significant mode of use of the product.\n“Installation Information” for a User Product means any methods, procedures, authorization keys, or other information required to install and execute modified versions of a covered work in that User Product from a modified version of its Corresponding Source. The information must suffice to ensure that the continued functioning of the modified object code is in no case prevented or interfered with solely because modification has been made.\nIf you convey an object code work under this section in, or with, or specifically for use in, a User Product, and the conveying occurs as part of a transaction in which the right of possession and use of the User Product is transferred to the recipient in perpetuity or for a fixed term (regardless of how the transaction is characterized), the Corresponding Source conveyed under this section must be accompanied by the Installation Information. But this requirement does not apply if neither you nor any third party retains the ability to install modified object code on the User Product (for example, the work has been installed in ROM).\nThe requirement to provide Installation Information does not include a requirement to continue to provide support service, warranty, or updates for a work that has been modified or installed by the recipient, or for the User Product in which it has been modified or installed. Access to a network may be denied when the modification itself materially and adversely affects the operation of the network or violates the rules and protocols for communication across the network.\nCorresponding Source conveyed, and Installation Information provided, in accord with this section must be in a format that is publicly documented (and with an implementation available to the public in source code form), and must require no special password or key for unpacking, reading or copying.\n\n\n\n“Additional permissions” are terms that supplement the terms of this License by making exceptions from one or more of its conditions. Additional permissions that are applicable to the entire Program shall be treated as though they were included in this License, to the extent that they are valid under applicable law. If additional permissions apply only to part of the Program, that part may be used separately under those permissions, but the entire Program remains governed by this License without regard to the additional permissions.\nWhen you convey a copy of a covered work, you may at your option remove any additional permissions from that copy, or from any part of it. (Additional permissions may be written to require their own removal in certain cases when you modify the work.) You may place additional permissions on material, added by you to a covered work, for which you have or can give appropriate copyright permission.\nNotwithstanding any other provision of this License, for material you add to a covered work, you may (if authorized by the copyright holders of that material) supplement the terms of this License with terms:\n\n\nDisclaiming warranty or limiting liability differently from the terms of sections 15 and 16 of this License; or\n\n\nRequiring preservation of specified reasonable legal notices or author attributions in that material or in the Appropriate Legal Notices displayed by works containing it; or\n\n\nProhibiting misrepresentation of the origin of that material, or requiring that modified versions of such material be marked in reasonable ways as different from the original version; or\n\n\nLimiting the use for publicity purposes of names of licensors or authors of the material; or\n\n\nDeclining to grant rights under trademark law for use of some trade names, trademarks, or service marks; or\n\n\nRequiring indemnification of licensors and authors of that material by anyone who conveys the material (or modified versions of it) with contractual assumptions of liability to the recipient, for any liability that these contractual assumptions directly impose on those licensors and authors.\n\n\nAll other non-permissive additional terms are considered “further restrictions” within the meaning of section 10. If the Program as you received it, or any part of it, contains a notice stating that it is governed by this License along with a term that is a further restriction, you may remove that term. If a license document contains a further restriction but permits relicensing or conveying under this License, you may add to a covered work material governed by the terms of that license document, provided that the further restriction does not survive such relicensing or conveying.\nIf you add terms to a covered work in accord with this section, you must place, in the relevant source files, a statement of the additional terms that apply to those files, or a notice indicating where to find the applicable terms.\nAdditional terms, permissive or non-permissive, may be stated in the form of a separately written license, or stated as exceptions; the above requirements apply either way.\n\n\n\nYou may not propagate or modify a covered work except as expressly provided under this License. Any attempt otherwise to propagate or modify it is void, and will automatically terminate your rights under this License (including any patent licenses granted under the third paragraph of section 11).\nHowever, if you cease all violation of this License, then your license from a particular copyright holder is reinstated (a) provisionally, unless and until the copyright holder explicitly and finally terminates your license, and (b) permanently, if the copyright holder fails to notify you of the violation by some reasonable means prior to 60 days after the cessation.\nMoreover, your license from a particular copyright holder is reinstated permanently if the copyright holder notifies you of the violation by some reasonable means, this is the first time you have received notice of violation of this License (for any work) from that copyright holder, and you cure the violation prior to 30 days after your receipt of the notice.\nTermination of your rights under this section does not terminate the licenses of parties who have received copies or rights from you under this License. If your rights have been terminated and not permanently reinstated, you do not qualify to receive new licenses for the same material under section 10.\n\n\n\nYou are not required to accept this License in order to receive or run a copy of the Program. Ancillary propagation of a covered work occurring solely as a consequence of using peer-to-peer transmission to receive a copy likewise does not require acceptance. However, nothing other than this License grants you permission to propagate or modify any covered work. These actions infringe copyright if you do not accept this License. Therefore, by modifying or propagating a covered work, you indicate your acceptance of this License to do so.\n\n\n\nEach time you convey a covered work, the recipient automatically receives a license from the original licensors, to run, modify and propagate that work, subject to this License. You are not responsible for enforcing compliance by third parties with this License.\nAn “entity transaction” is a transaction transferring control of an organization, or substantially all assets of one, or subdividing an organization, or merging organizations. If propagation of a covered work results from an entity transaction, each party to that transaction who receives a copy of the work also receives whatever licenses to the work the party’s predecessor in interest had or could give under the previous paragraph, plus a right to possession of the Corresponding Source of the work from the predecessor in interest, if the predecessor has it or can get it with reasonable efforts.\nYou may not impose any further restrictions on the exercise of the rights granted or affirmed under this License. For example, you may not impose a license fee, royalty, or other charge for exercise of rights granted under this License, and you may not initiate litigation (including a cross-claim or counterclaim in a lawsuit) alleging that any patent claim is infringed by making, using, selling, offering for sale, or importing the Program or any portion of it.\n\n\n\nA “contributor” is a copyright holder who authorizes use under this License of the Program or a work on which the Program is based. The work thus licensed is called the contributor’s “contributor version”.\nA contributor’s “essential patent claims” are all patent claims owned or controlled by the contributor, whether already acquired or hereafter acquired, that would be infringed by some manner, permitted by this License, of making, using, or selling its contributor version, but do not include claims that would be infringed only as a consequence of further modification of the contributor version. For purposes of this definition, “control” includes the right to grant patent sublicenses in a manner consistent with the requirements of this License.\nEach contributor grants you a non-exclusive, worldwide, royalty-free patent license under the contributor’s essential patent claims, to make, use, sell, offer for sale, import and otherwise run, modify and propagate the contents of its contributor version.\nIn the following three paragraphs, a “patent license” is any express agreement or commitment, however denominated, not to enforce a patent (such as an express permission to practice a patent or covenant not to sue for patent infringement). To “grant” such a patent license to a party means to make such an agreement or commitment not to enforce a patent against the party.\nIf you convey a covered work, knowingly relying on a patent license, and the Corresponding Source of the work is not available for anyone to copy, free of charge and under the terms of this License, through a publicly available network server or other readily accessible means, then you must either (1) cause the Corresponding Source to be so available, or (2) arrange to deprive yourself of the benefit of the patent license for this particular work, or (3) arrange, in a manner consistent with the requirements of this License, to extend the patent license to downstream recipients. “Knowingly relying” means you have actual knowledge that, but for the patent license, your conveying the covered work in a country, or your recipient’s use of the covered work in a country, would infringe one or more identifiable patents in that country that you have reason to believe are valid.\nIf, pursuant to or in connection with a single transaction or arrangement, you convey, or propagate by procuring conveyance of, a covered work, and grant a patent license to some of the parties receiving the covered work authorizing them to use, propagate, modify or convey a specific copy of the covered work, then the patent license you grant is automatically extended to all recipients of the covered work and works based on it.\nA patent license is “discriminatory” if it does not include within the scope of its coverage, prohibits the exercise of, or is conditioned on the non-exercise of one or more of the rights that are specifically granted under this License. You may not convey a covered work if you are a party to an arrangement with a third party that is in the business of distributing software, under which you make payment to the third party based on the extent of your activity of conveying the work, and under which the third party grants, to any of the parties who would receive the covered work from you, a discriminatory patent license (a) in connection with copies of the covered work conveyed by you (or copies made from those copies), or (b) primarily for and in connection with specific products or compilations that contain the covered work, unless you entered into that arrangement, or that patent license was granted, prior to 28 March 2007.\nNothing in this License shall be construed as excluding or limiting any implied license or other defenses to infringement that may otherwise be available to you under applicable patent law.\n\n\n\nIf conditions are imposed on you (whether by court order, agreement or otherwise) that contradict the conditions of this License, they do not excuse you from the conditions of this License. If you cannot convey a covered work so as to satisfy simultaneously your obligations under this License and any other pertinent obligations, then as a consequence you may not convey it at all. For example, if you agree to terms that obligate you to collect a royalty for further conveying from those to whom you convey the Program, the only way you could satisfy both those terms and this License would be to refrain entirely from conveying the Program.\n\n\n\nNotwithstanding any other provision of this License, if you modify the Program, your modified version must prominently offer all users interacting with it remotely through a computer network (if your version supports such interaction) an opportunity to receive the Corresponding Source of your version by providing access to the Corresponding Source from a network server at no charge, through some standard or customary means of facilitating copying of software. This Corresponding Source shall include the Corresponding Source for any work covered by version 3 of the GNU General Public License that is incorporated pursuant to the following paragraph.\nNotwithstanding any other provision of this License, you have permission to link or combine any covered work with a work licensed under version 3 of the GNU General Public License into a single combined work, and to convey the resulting work. The terms of this License will continue to apply to the part which is the covered work, but the work with which it is combined will remain governed by version 3 of the GNU General Public License.\n\n\n\nThe Free Software Foundation may publish revised and/or new versions of the GNU Affero General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns.\nEach version is given a distinguishing version number. If the Program specifies that a certain numbered version of the GNU Affero General Public License “or any later version” applies to it, you have the option of following the terms and conditions either of that numbered version or of any later version published by the Free Software Foundation. If the Program does not specify a version number of the GNU Affero General Public License, you may choose any version ever published by the Free Software Foundation.\nIf the Program specifies that a proxy can decide which future versions of the GNU Affero General Public License can be used, that proxy’s public statement of acceptance of a version permanently authorizes you to choose that version for the Program.\nLater license versions may give you additional or different permissions. However, no additional obligations are imposed on any author or copyright holder as a result of your choosing to follow a later version.\n\n\n\nTHERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM “AS IS” WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU. SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n\n\nIN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\n\n\n\nIf the disclaimer of warranty and limitation of liability provided above cannot be given local legal effect according to their terms, reviewing courts shall apply local law that most closely approximates an absolute waiver of all civil liability in connection with the Program, unless a warranty or assumption of liability accompanies a copy of the Program in return for a fee.\nEND OF TERMS AND CONDITIONS\n\n\n\n\nIf you develop a new program, and you want it to be of the greatest possible use to the public, the best way to achieve this is to make it free software which everyone can redistribute and change under these terms.\nTo do so, attach the following notices to the program. It is safest to attach them to the start of each source file to most effectively state the exclusion of warranty; and each file should have at least the “copyright” line and a pointer to where the full notice is found.\n    &lt;one line to give the program's name and a brief idea of what it does.&gt;\n    Copyright (C) &lt;year&gt;  &lt;name of author&gt;\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU Affero General Public License as\n    published by the Free Software Foundation, either version 3 of the\n    License, or (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU Affero General Public License for more details.\n\n    You should have received a copy of the GNU Affero General Public License\n    along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.\nAlso add information on how to contact you by electronic and paper mail.\nIf your software can interact with users remotely through a computer network, you should also make sure that it provides a way for users to get its source. For example, if your program is a web application, its interface could display a “Source” link that leads users to an archive of the code. There are many ways you could offer source, and different solutions will be better for different programs; see section 13 for the specific requirements.\nYou should also get your employer (if you work as a programmer) or school, if any, to sign a “copyright disclaimer” for the program, if necessary. For more information on this, and how to apply and follow the GNU AGPL, see https://www.gnu.org/licenses/."
  },
  {
    "objectID": "LICENSE.html#preamble",
    "href": "LICENSE.html#preamble",
    "title": "GNU Affero General Public License",
    "section": "",
    "text": "The GNU Affero General Public License is a free, copyleft license for software and other kinds of works, specifically designed to ensure cooperation with the community in the case of network server software.\nThe licenses for most software and other practical works are designed to take away your freedom to share and change the works. By contrast, our General Public Licenses are intended to guarantee your freedom to share and change all versions of a program–to make sure it remains free software for all its users.\nWhen we speak of free software, we are referring to freedom, not price. Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for them if you wish), that you receive source code or can get it if you want it, that you can change the software or use pieces of it in new free programs, and that you know you can do these things.\nDevelopers that use our General Public Licenses protect your rights with two steps: (1) assert copyright on the software, and (2) offer you this License which gives you legal permission to copy, distribute and/or modify the software.\nA secondary benefit of defending all users’ freedom is that improvements made in alternate versions of the program, if they receive widespread use, become available for other developers to incorporate. Many developers of free software are heartened and encouraged by the resulting cooperation. However, in the case of software used on network servers, this result may fail to come about. The GNU General Public License permits making a modified version and letting the public access it on a server without ever releasing its source code to the public.\nThe GNU Affero General Public License is designed specifically to ensure that, in such cases, the modified source code becomes available to the community. It requires the operator of a network server to provide the source code of the modified version running there to the users of that server. Therefore, public use of a modified version, on a publicly accessible server, gives the public access to the source code of the modified version.\nAn older license, called the Affero General Public License and published by Affero, was designed to accomplish similar goals. This is a different license, not a version of the Affero GPL, but Affero has released a new version of the Affero GPL which permits relicensing under this license.\nThe precise terms and conditions for copying, distribution and modification follow."
  },
  {
    "objectID": "LICENSE.html#terms-and-conditions",
    "href": "LICENSE.html#terms-and-conditions",
    "title": "GNU Affero General Public License",
    "section": "",
    "text": "“This License” refers to version 3 of the GNU Affero General Public License.\n“Copyright” also means copyright-like laws that apply to other kinds of works, such as semiconductor masks.\n“The Program” refers to any copyrightable work licensed under this License. Each licensee is addressed as “you”. “Licensees” and “recipients” may be individuals or organizations.\nTo “modify” a work means to copy from or adapt all or part of the work in a fashion requiring copyright permission, other than the making of an exact copy. The resulting work is called a “modified version” of the earlier work or a work “based on” the earlier work.\nA “covered work” means either the unmodified Program or a work based on the Program.\nTo “propagate” a work means to do anything with it that, without permission, would make you directly or secondarily liable for infringement under applicable copyright law, except executing it on a computer or modifying a private copy. Propagation includes copying, distribution (with or without modification), making available to the public, and in some countries other activities as well.\nTo “convey” a work means any kind of propagation that enables other parties to make or receive copies. Mere interaction with a user through a computer network, with no transfer of a copy, is not conveying.\nAn interactive user interface displays “Appropriate Legal Notices” to the extent that it includes a convenient and prominently visible feature that (1) displays an appropriate copyright notice, and (2) tells the user that there is no warranty for the work (except to the extent that warranties are provided), that licensees may convey the work under this License, and how to view a copy of this License. If the interface presents a list of user commands or options, such as a menu, a prominent item in the list meets this criterion.\n\n\n\nThe “source code” for a work means the preferred form of the work for making modifications to it. “Object code” means any non-source form of a work.\nA “Standard Interface” means an interface that either is an official standard defined by a recognized standards body, or, in the case of interfaces specified for a particular programming language, one that is widely used among developers working in that language.\nThe “System Libraries” of an executable work include anything, other than the work as a whole, that (a) is included in the normal form of packaging a Major Component, but which is not part of that Major Component, and (b) serves only to enable use of the work with that Major Component, or to implement a Standard Interface for which an implementation is available to the public in source code form. A “Major Component”, in this context, means a major essential component (kernel, window system, and so on) of the specific operating system (if any) on which the executable work runs, or a compiler used to produce the work, or an object code interpreter used to run it.\nThe “Corresponding Source” for a work in object code form means all the source code needed to generate, install, and (for an executable work) run the object code and to modify the work, including scripts to control those activities. However, it does not include the work’s System Libraries, or general-purpose tools or generally available free programs which are used unmodified in performing those activities but which are not part of the work. For example, Corresponding Source includes interface definition files associated with source files for the work, and the source code for shared libraries and dynamically linked subprograms that the work is specifically designed to require, such as by intimate data communication or control flow between those subprograms and other parts of the work.\nThe Corresponding Source need not include anything that users can regenerate automatically from other parts of the Corresponding Source.\nThe Corresponding Source for a work in source code form is that same work.\n\n\n\nAll rights granted under this License are granted for the term of copyright on the Program, and are irrevocable provided the stated conditions are met. This License explicitly affirms your unlimited permission to run the unmodified Program. The output from running a covered work is covered by this License only if the output, given its content, constitutes a covered work. This License acknowledges your rights of fair use or other equivalent, as provided by copyright law.\nYou may make, run and propagate covered works that you do not convey, without conditions so long as your license otherwise remains in force. You may convey covered works to others for the sole purpose of having them make modifications exclusively for you, or provide you with facilities for running those works, provided that you comply with the terms of this License in conveying all material for which you do not control copyright. Those thus making or running the covered works for you must do so exclusively on your behalf, under your direction and control, on terms that prohibit them from making any copies of your copyrighted material outside their relationship with you.\nConveying under any other circumstances is permitted solely under the conditions stated below. Sublicensing is not allowed; section 10 makes it unnecessary.\n\n\n\nNo covered work shall be deemed part of an effective technological measure under any applicable law fulfilling obligations under article 11 of the WIPO copyright treaty adopted on 20 December 1996, or similar laws prohibiting or restricting circumvention of such measures.\nWhen you convey a covered work, you waive any legal power to forbid circumvention of technological measures to the extent such circumvention is effected by exercising rights under this License with respect to the covered work, and you disclaim any intention to limit operation or modification of the work as a means of enforcing, against the work’s users, your or third parties’ legal rights to forbid circumvention of technological measures.\n\n\n\nYou may convey verbatim copies of the Program’s source code as you receive it, in any medium, provided that you conspicuously and appropriately publish on each copy an appropriate copyright notice; keep intact all notices stating that this License and any non-permissive terms added in accord with section 7 apply to the code; keep intact all notices of the absence of any warranty; and give all recipients a copy of this License along with the Program.\nYou may charge any price or no price for each copy that you convey, and you may offer support or warranty protection for a fee.\n\n\n\nYou may convey a work based on the Program, or the modifications to produce it from the Program, in the form of source code under the terms of section 4, provided that you also meet all of these conditions:\n\n\nThe work must carry prominent notices stating that you modified it, and giving a relevant date.\n\n\nThe work must carry prominent notices stating that it is released under this License and any conditions added under section 7. This requirement modifies the requirement in section 4 to “keep intact all notices”.\n\n\nYou must license the entire work, as a whole, under this License to anyone who comes into possession of a copy. This License will therefore apply, along with any applicable section 7 additional terms, to the whole of the work, and all its parts, regardless of how they are packaged. This License gives no permission to license the work in any other way, but it does not invalidate such permission if you have separately received it.\n\n\nIf the work has interactive user interfaces, each must display Appropriate Legal Notices; however, if the Program has interactive interfaces that do not display Appropriate Legal Notices, your work need not make them do so.\n\n\nA compilation of a covered work with other separate and independent works, which are not by their nature extensions of the covered work, and which are not combined with it such as to form a larger program, in or on a volume of a storage or distribution medium, is called an “aggregate” if the compilation and its resulting copyright are not used to limit the access or legal rights of the compilation’s users beyond what the individual works permit. Inclusion of a covered work in an aggregate does not cause this License to apply to the other parts of the aggregate.\n\n\n\nYou may convey a covered work in object code form under the terms of sections 4 and 5, provided that you also convey the machine-readable Corresponding Source under the terms of this License, in one of these ways:\n\n\nConvey the object code in, or embodied in, a physical product (including a physical distribution medium), accompanied by the Corresponding Source fixed on a durable physical medium customarily used for software interchange.\n\n\nConvey the object code in, or embodied in, a physical product (including a physical distribution medium), accompanied by a written offer, valid for at least three years and valid for as long as you offer spare parts or customer support for that product model, to give anyone who possesses the object code either (1) a copy of the Corresponding Source for all the software in the product that is covered by this License, on a durable physical medium customarily used for software interchange, for a price no more than your reasonable cost of physically performing this conveying of source, or (2) access to copy the Corresponding Source from a network server at no charge.\n\n\nConvey individual copies of the object code with a copy of the written offer to provide the Corresponding Source. This alternative is allowed only occasionally and noncommercially, and only if you received the object code with such an offer, in accord with subsection 6b.\n\n\nConvey the object code by offering access from a designated place (gratis or for a charge), and offer equivalent access to the Corresponding Source in the same way through the same place at no further charge. You need not require recipients to copy the Corresponding Source along with the object code. If the place to copy the object code is a network server, the Corresponding Source may be on a different server (operated by you or a third party) that supports equivalent copying facilities, provided you maintain clear directions next to the object code saying where to find the Corresponding Source. Regardless of what server hosts the Corresponding Source, you remain obligated to ensure that it is available for as long as needed to satisfy these requirements.\n\n\nConvey the object code using peer-to-peer transmission, provided you inform other peers where the object code and Corresponding Source of the work are being offered to the general public at no charge under subsection 6d.\n\n\nA separable portion of the object code, whose source code is excluded from the Corresponding Source as a System Library, need not be included in conveying the object code work.\nA “User Product” is either (1) a “consumer product”, which means any tangible personal property which is normally used for personal, family, or household purposes, or (2) anything designed or sold for incorporation into a dwelling. In determining whether a product is a consumer product, doubtful cases shall be resolved in favor of coverage. For a particular product received by a particular user, “normally used” refers to a typical or common use of that class of product, regardless of the status of the particular user or of the way in which the particular user actually uses, or expects or is expected to use, the product. A product is a consumer product regardless of whether the product has substantial commercial, industrial or non-consumer uses, unless such uses represent the only significant mode of use of the product.\n“Installation Information” for a User Product means any methods, procedures, authorization keys, or other information required to install and execute modified versions of a covered work in that User Product from a modified version of its Corresponding Source. The information must suffice to ensure that the continued functioning of the modified object code is in no case prevented or interfered with solely because modification has been made.\nIf you convey an object code work under this section in, or with, or specifically for use in, a User Product, and the conveying occurs as part of a transaction in which the right of possession and use of the User Product is transferred to the recipient in perpetuity or for a fixed term (regardless of how the transaction is characterized), the Corresponding Source conveyed under this section must be accompanied by the Installation Information. But this requirement does not apply if neither you nor any third party retains the ability to install modified object code on the User Product (for example, the work has been installed in ROM).\nThe requirement to provide Installation Information does not include a requirement to continue to provide support service, warranty, or updates for a work that has been modified or installed by the recipient, or for the User Product in which it has been modified or installed. Access to a network may be denied when the modification itself materially and adversely affects the operation of the network or violates the rules and protocols for communication across the network.\nCorresponding Source conveyed, and Installation Information provided, in accord with this section must be in a format that is publicly documented (and with an implementation available to the public in source code form), and must require no special password or key for unpacking, reading or copying.\n\n\n\n“Additional permissions” are terms that supplement the terms of this License by making exceptions from one or more of its conditions. Additional permissions that are applicable to the entire Program shall be treated as though they were included in this License, to the extent that they are valid under applicable law. If additional permissions apply only to part of the Program, that part may be used separately under those permissions, but the entire Program remains governed by this License without regard to the additional permissions.\nWhen you convey a copy of a covered work, you may at your option remove any additional permissions from that copy, or from any part of it. (Additional permissions may be written to require their own removal in certain cases when you modify the work.) You may place additional permissions on material, added by you to a covered work, for which you have or can give appropriate copyright permission.\nNotwithstanding any other provision of this License, for material you add to a covered work, you may (if authorized by the copyright holders of that material) supplement the terms of this License with terms:\n\n\nDisclaiming warranty or limiting liability differently from the terms of sections 15 and 16 of this License; or\n\n\nRequiring preservation of specified reasonable legal notices or author attributions in that material or in the Appropriate Legal Notices displayed by works containing it; or\n\n\nProhibiting misrepresentation of the origin of that material, or requiring that modified versions of such material be marked in reasonable ways as different from the original version; or\n\n\nLimiting the use for publicity purposes of names of licensors or authors of the material; or\n\n\nDeclining to grant rights under trademark law for use of some trade names, trademarks, or service marks; or\n\n\nRequiring indemnification of licensors and authors of that material by anyone who conveys the material (or modified versions of it) with contractual assumptions of liability to the recipient, for any liability that these contractual assumptions directly impose on those licensors and authors.\n\n\nAll other non-permissive additional terms are considered “further restrictions” within the meaning of section 10. If the Program as you received it, or any part of it, contains a notice stating that it is governed by this License along with a term that is a further restriction, you may remove that term. If a license document contains a further restriction but permits relicensing or conveying under this License, you may add to a covered work material governed by the terms of that license document, provided that the further restriction does not survive such relicensing or conveying.\nIf you add terms to a covered work in accord with this section, you must place, in the relevant source files, a statement of the additional terms that apply to those files, or a notice indicating where to find the applicable terms.\nAdditional terms, permissive or non-permissive, may be stated in the form of a separately written license, or stated as exceptions; the above requirements apply either way.\n\n\n\nYou may not propagate or modify a covered work except as expressly provided under this License. Any attempt otherwise to propagate or modify it is void, and will automatically terminate your rights under this License (including any patent licenses granted under the third paragraph of section 11).\nHowever, if you cease all violation of this License, then your license from a particular copyright holder is reinstated (a) provisionally, unless and until the copyright holder explicitly and finally terminates your license, and (b) permanently, if the copyright holder fails to notify you of the violation by some reasonable means prior to 60 days after the cessation.\nMoreover, your license from a particular copyright holder is reinstated permanently if the copyright holder notifies you of the violation by some reasonable means, this is the first time you have received notice of violation of this License (for any work) from that copyright holder, and you cure the violation prior to 30 days after your receipt of the notice.\nTermination of your rights under this section does not terminate the licenses of parties who have received copies or rights from you under this License. If your rights have been terminated and not permanently reinstated, you do not qualify to receive new licenses for the same material under section 10.\n\n\n\nYou are not required to accept this License in order to receive or run a copy of the Program. Ancillary propagation of a covered work occurring solely as a consequence of using peer-to-peer transmission to receive a copy likewise does not require acceptance. However, nothing other than this License grants you permission to propagate or modify any covered work. These actions infringe copyright if you do not accept this License. Therefore, by modifying or propagating a covered work, you indicate your acceptance of this License to do so.\n\n\n\nEach time you convey a covered work, the recipient automatically receives a license from the original licensors, to run, modify and propagate that work, subject to this License. You are not responsible for enforcing compliance by third parties with this License.\nAn “entity transaction” is a transaction transferring control of an organization, or substantially all assets of one, or subdividing an organization, or merging organizations. If propagation of a covered work results from an entity transaction, each party to that transaction who receives a copy of the work also receives whatever licenses to the work the party’s predecessor in interest had or could give under the previous paragraph, plus a right to possession of the Corresponding Source of the work from the predecessor in interest, if the predecessor has it or can get it with reasonable efforts.\nYou may not impose any further restrictions on the exercise of the rights granted or affirmed under this License. For example, you may not impose a license fee, royalty, or other charge for exercise of rights granted under this License, and you may not initiate litigation (including a cross-claim or counterclaim in a lawsuit) alleging that any patent claim is infringed by making, using, selling, offering for sale, or importing the Program or any portion of it.\n\n\n\nA “contributor” is a copyright holder who authorizes use under this License of the Program or a work on which the Program is based. The work thus licensed is called the contributor’s “contributor version”.\nA contributor’s “essential patent claims” are all patent claims owned or controlled by the contributor, whether already acquired or hereafter acquired, that would be infringed by some manner, permitted by this License, of making, using, or selling its contributor version, but do not include claims that would be infringed only as a consequence of further modification of the contributor version. For purposes of this definition, “control” includes the right to grant patent sublicenses in a manner consistent with the requirements of this License.\nEach contributor grants you a non-exclusive, worldwide, royalty-free patent license under the contributor’s essential patent claims, to make, use, sell, offer for sale, import and otherwise run, modify and propagate the contents of its contributor version.\nIn the following three paragraphs, a “patent license” is any express agreement or commitment, however denominated, not to enforce a patent (such as an express permission to practice a patent or covenant not to sue for patent infringement). To “grant” such a patent license to a party means to make such an agreement or commitment not to enforce a patent against the party.\nIf you convey a covered work, knowingly relying on a patent license, and the Corresponding Source of the work is not available for anyone to copy, free of charge and under the terms of this License, through a publicly available network server or other readily accessible means, then you must either (1) cause the Corresponding Source to be so available, or (2) arrange to deprive yourself of the benefit of the patent license for this particular work, or (3) arrange, in a manner consistent with the requirements of this License, to extend the patent license to downstream recipients. “Knowingly relying” means you have actual knowledge that, but for the patent license, your conveying the covered work in a country, or your recipient’s use of the covered work in a country, would infringe one or more identifiable patents in that country that you have reason to believe are valid.\nIf, pursuant to or in connection with a single transaction or arrangement, you convey, or propagate by procuring conveyance of, a covered work, and grant a patent license to some of the parties receiving the covered work authorizing them to use, propagate, modify or convey a specific copy of the covered work, then the patent license you grant is automatically extended to all recipients of the covered work and works based on it.\nA patent license is “discriminatory” if it does not include within the scope of its coverage, prohibits the exercise of, or is conditioned on the non-exercise of one or more of the rights that are specifically granted under this License. You may not convey a covered work if you are a party to an arrangement with a third party that is in the business of distributing software, under which you make payment to the third party based on the extent of your activity of conveying the work, and under which the third party grants, to any of the parties who would receive the covered work from you, a discriminatory patent license (a) in connection with copies of the covered work conveyed by you (or copies made from those copies), or (b) primarily for and in connection with specific products or compilations that contain the covered work, unless you entered into that arrangement, or that patent license was granted, prior to 28 March 2007.\nNothing in this License shall be construed as excluding or limiting any implied license or other defenses to infringement that may otherwise be available to you under applicable patent law.\n\n\n\nIf conditions are imposed on you (whether by court order, agreement or otherwise) that contradict the conditions of this License, they do not excuse you from the conditions of this License. If you cannot convey a covered work so as to satisfy simultaneously your obligations under this License and any other pertinent obligations, then as a consequence you may not convey it at all. For example, if you agree to terms that obligate you to collect a royalty for further conveying from those to whom you convey the Program, the only way you could satisfy both those terms and this License would be to refrain entirely from conveying the Program.\n\n\n\nNotwithstanding any other provision of this License, if you modify the Program, your modified version must prominently offer all users interacting with it remotely through a computer network (if your version supports such interaction) an opportunity to receive the Corresponding Source of your version by providing access to the Corresponding Source from a network server at no charge, through some standard or customary means of facilitating copying of software. This Corresponding Source shall include the Corresponding Source for any work covered by version 3 of the GNU General Public License that is incorporated pursuant to the following paragraph.\nNotwithstanding any other provision of this License, you have permission to link or combine any covered work with a work licensed under version 3 of the GNU General Public License into a single combined work, and to convey the resulting work. The terms of this License will continue to apply to the part which is the covered work, but the work with which it is combined will remain governed by version 3 of the GNU General Public License.\n\n\n\nThe Free Software Foundation may publish revised and/or new versions of the GNU Affero General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns.\nEach version is given a distinguishing version number. If the Program specifies that a certain numbered version of the GNU Affero General Public License “or any later version” applies to it, you have the option of following the terms and conditions either of that numbered version or of any later version published by the Free Software Foundation. If the Program does not specify a version number of the GNU Affero General Public License, you may choose any version ever published by the Free Software Foundation.\nIf the Program specifies that a proxy can decide which future versions of the GNU Affero General Public License can be used, that proxy’s public statement of acceptance of a version permanently authorizes you to choose that version for the Program.\nLater license versions may give you additional or different permissions. However, no additional obligations are imposed on any author or copyright holder as a result of your choosing to follow a later version.\n\n\n\nTHERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM “AS IS” WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU. SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n\n\nIN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\n\n\n\nIf the disclaimer of warranty and limitation of liability provided above cannot be given local legal effect according to their terms, reviewing courts shall apply local law that most closely approximates an absolute waiver of all civil liability in connection with the Program, unless a warranty or assumption of liability accompanies a copy of the Program in return for a fee.\nEND OF TERMS AND CONDITIONS"
  },
  {
    "objectID": "LICENSE.html#how-to-apply-these-terms-to-your-new-programs",
    "href": "LICENSE.html#how-to-apply-these-terms-to-your-new-programs",
    "title": "GNU Affero General Public License",
    "section": "",
    "text": "If you develop a new program, and you want it to be of the greatest possible use to the public, the best way to achieve this is to make it free software which everyone can redistribute and change under these terms.\nTo do so, attach the following notices to the program. It is safest to attach them to the start of each source file to most effectively state the exclusion of warranty; and each file should have at least the “copyright” line and a pointer to where the full notice is found.\n    &lt;one line to give the program's name and a brief idea of what it does.&gt;\n    Copyright (C) &lt;year&gt;  &lt;name of author&gt;\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU Affero General Public License as\n    published by the Free Software Foundation, either version 3 of the\n    License, or (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU Affero General Public License for more details.\n\n    You should have received a copy of the GNU Affero General Public License\n    along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.\nAlso add information on how to contact you by electronic and paper mail.\nIf your software can interact with users remotely through a computer network, you should also make sure that it provides a way for users to get its source. For example, if your program is a web application, its interface could display a “Source” link that leads users to an archive of the code. There are many ways you could offer source, and different solutions will be better for different programs; see section 13 for the specific requirements.\nYou should also get your employer (if you work as a programmer) or school, if any, to sign a “copyright disclaimer” for the program, if necessary. For more information on this, and how to apply and follow the GNU AGPL, see https://www.gnu.org/licenses/."
  },
  {
    "objectID": "CITATION.html",
    "href": "CITATION.html",
    "title": "Citation",
    "section": "",
    "text": "Citation\nTo cite tima in publications use:\n\nRutz A, Allard P (2025). tima: Taxonomically Informed Metabolite Annotation. doi:10.5281/zenodo.5797920, R package, version 2.11.0.\n\n\nRutz A, Dounoue-Kubo M, Ollivier S, Bisson J, Bagheri M, Saesong T, Ebrahimi S, Ingkaninan K, Wolfender J, Allard P (2019). “Taxonomically Informed Scoring Enhances Confidence in Natural Products Annotation.” Frontiers in Plant Science, 10. ISSN 1664-462X, doi:10.3389/FPLS.2019.01329, https://doi.org/10.3389/fpls.2019.01329."
  },
  {
    "objectID": "man/decorate_bio.html",
    "href": "man/decorate_bio.html",
    "title": "tima",
    "section": "",
    "text": "This function outputs information about biological weighting\n\n\n\ndecorate_bio(\n  annot_table_wei_bio = get(\"annot_table_wei_bio\", envir = parent.frame()),\n  score_biological_kingdom = get(\"score_biological_kingdom\", envir = parent.frame()),\n  score_biological_phylum = get(\"score_biological_phylum\", envir = parent.frame()),\n  score_biological_class = get(\"score_biological_class\", envir = parent.frame()),\n  score_biological_order = get(\"score_biological_order\", envir = parent.frame()),\n  score_biological_family = get(\"score_biological_family\", envir = parent.frame()),\n  score_biological_tribe = get(\"score_biological_tribe\", envir = parent.frame()),\n  score_biological_genus = get(\"score_biological_genus\", envir = parent.frame()),\n  score_biological_species = get(\"score_biological_species\", envir = parent.frame()),\n  score_biological_variety = get(\"score_biological_variety\", envir = parent.frame())\n)\n\n\n\n\n\n\n\nannot_table_wei_bio\n\n\nTable to decorate\n\n\n\n\nscore_biological_kingdom\n\n\nKingdom score\n\n\n\n\nscore_biological_phylum\n\n\nPhylum score\n\n\n\n\nscore_biological_class\n\n\nClass score\n\n\n\n\nscore_biological_order\n\n\nOrder score\n\n\n\n\nscore_biological_family\n\n\nFamily score\n\n\n\n\nscore_biological_tribe\n\n\nTribe score\n\n\n\n\nscore_biological_genus\n\n\nGenus score\n\n\n\n\nscore_biological_species\n\n\nSpecies score\n\n\n\n\nscore_biological_variety\n\n\nVariety score\n\n\n\n\n\n\nMessage indicating the number of annotations weighted at each biological level\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/decorate_bio.html#decorate-bio",
    "href": "man/decorate_bio.html#decorate-bio",
    "title": "tima",
    "section": "",
    "text": "This function outputs information about biological weighting\n\n\n\ndecorate_bio(\n  annot_table_wei_bio = get(\"annot_table_wei_bio\", envir = parent.frame()),\n  score_biological_kingdom = get(\"score_biological_kingdom\", envir = parent.frame()),\n  score_biological_phylum = get(\"score_biological_phylum\", envir = parent.frame()),\n  score_biological_class = get(\"score_biological_class\", envir = parent.frame()),\n  score_biological_order = get(\"score_biological_order\", envir = parent.frame()),\n  score_biological_family = get(\"score_biological_family\", envir = parent.frame()),\n  score_biological_tribe = get(\"score_biological_tribe\", envir = parent.frame()),\n  score_biological_genus = get(\"score_biological_genus\", envir = parent.frame()),\n  score_biological_species = get(\"score_biological_species\", envir = parent.frame()),\n  score_biological_variety = get(\"score_biological_variety\", envir = parent.frame())\n)\n\n\n\n\n\n\n\nannot_table_wei_bio\n\n\nTable to decorate\n\n\n\n\nscore_biological_kingdom\n\n\nKingdom score\n\n\n\n\nscore_biological_phylum\n\n\nPhylum score\n\n\n\n\nscore_biological_class\n\n\nClass score\n\n\n\n\nscore_biological_order\n\n\nOrder score\n\n\n\n\nscore_biological_family\n\n\nFamily score\n\n\n\n\nscore_biological_tribe\n\n\nTribe score\n\n\n\n\nscore_biological_genus\n\n\nGenus score\n\n\n\n\nscore_biological_species\n\n\nSpecies score\n\n\n\n\nscore_biological_variety\n\n\nVariety score\n\n\n\n\n\n\nMessage indicating the number of annotations weighted at each biological level\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/replace_id.html",
    "href": "man/replace_id.html",
    "title": "tima",
    "section": "",
    "text": "This function replaces the default ID in the example by a user-specified one\n\n\n\nreplace_id(\n  x,\n  user_filename = get_params(step = \"prepare_params\")\\$files\\$pattern,\n  user_gnps = get_params(step = \"prepare_params\")\\$gnps\\$id,\n  example_gnps = get_default_paths()\\$gnps\\$example\n)\n\n\n\n\n\n\n\nx\n\n\na character string containing the default ID\n\n\n\n\nuser_filename\n\n\na user-specified value for a file name job ID\n\n\n\n\nuser_gnps\n\n\na user-specified value for a GNPS job ID\n\n\n\n\nexample_gnps\n\n\nan example value for a GNPS job ID\n\n\n\n\n\n\nCharacter string with the GNPS job ID modified according to the rules specified in the function\n\n\n\n\nlibrary(\"tima\")\n\nreplace_id(\n  x = \"example/123456_features.tsv\",\n  user_gnps = NULL,\n  user_filename = \"Foo\"\n)"
  },
  {
    "objectID": "man/replace_id.html#replace-id-in-file-paths",
    "href": "man/replace_id.html#replace-id-in-file-paths",
    "title": "tima",
    "section": "",
    "text": "This function replaces the default ID in the example by a user-specified one\n\n\n\nreplace_id(\n  x,\n  user_filename = get_params(step = \"prepare_params\")\\$files\\$pattern,\n  user_gnps = get_params(step = \"prepare_params\")\\$gnps\\$id,\n  example_gnps = get_default_paths()\\$gnps\\$example\n)\n\n\n\n\n\n\n\nx\n\n\na character string containing the default ID\n\n\n\n\nuser_filename\n\n\na user-specified value for a file name job ID\n\n\n\n\nuser_gnps\n\n\na user-specified value for a GNPS job ID\n\n\n\n\nexample_gnps\n\n\nan example value for a GNPS job ID\n\n\n\n\n\n\nCharacter string with the GNPS job ID modified according to the rules specified in the function\n\n\n\n\nlibrary(\"tima\")\n\nreplace_id(\n  x = \"example/123456_features.tsv\",\n  user_gnps = NULL,\n  user_filename = \"Foo\"\n)"
  },
  {
    "objectID": "man/select_annotations_columns.html",
    "href": "man/select_annotations_columns.html",
    "title": "tima",
    "section": "",
    "text": "This function selects annotations columns\n\n\n\nselect_annotations_columns(\n  df,\n  str_stereo = get(\"str_stereo\", envir = parent.frame()),\n  str_met = get(\"str_met\", envir = parent.frame()),\n  str_nam = get(\"str_nam\", envir = parent.frame()),\n  str_tax_cla = get(\"str_tax_cla\", envir = parent.frame()),\n  str_tax_npc = get(\"str_tax_npc\", envir = parent.frame())\n)\n\n\n\n\n\n\n\ndf\n\n\nDataframe\n\n\n\n\nstr_stereo\n\n\nFile containing structures stereo\n\n\n\n\nstr_met\n\n\nFile containing structures metadata\n\n\n\n\nstr_nam\n\n\nFile containing structures names\n\n\n\n\nstr_tax_cla\n\n\nFile containing Classyfire taxonomy\n\n\n\n\nstr_tax_npc\n\n\nFile containing NPClassifier taxonomy\n\n\n\n\n\n\nThe dataframe with annotation columns selected\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/select_annotations_columns.html#select-annotations-columns",
    "href": "man/select_annotations_columns.html#select-annotations-columns",
    "title": "tima",
    "section": "",
    "text": "This function selects annotations columns\n\n\n\nselect_annotations_columns(\n  df,\n  str_stereo = get(\"str_stereo\", envir = parent.frame()),\n  str_met = get(\"str_met\", envir = parent.frame()),\n  str_nam = get(\"str_nam\", envir = parent.frame()),\n  str_tax_cla = get(\"str_tax_cla\", envir = parent.frame()),\n  str_tax_npc = get(\"str_tax_npc\", envir = parent.frame())\n)\n\n\n\n\n\n\n\ndf\n\n\nDataframe\n\n\n\n\nstr_stereo\n\n\nFile containing structures stereo\n\n\n\n\nstr_met\n\n\nFile containing structures metadata\n\n\n\n\nstr_nam\n\n\nFile containing structures names\n\n\n\n\nstr_tax_cla\n\n\nFile containing Classyfire taxonomy\n\n\n\n\nstr_tax_npc\n\n\nFile containing NPClassifier taxonomy\n\n\n\n\n\n\nThe dataframe with annotation columns selected\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/harmonize_names_sirius.html",
    "href": "man/harmonize_names_sirius.html",
    "title": "tima",
    "section": "",
    "text": "This function harmonizes the names of Sirius outputs to make them compatible\n\n\n\nharmonize_names_sirius(x)\n\n\n\n\n\n\n\nx\n\n\nCharacter string containing a name\n\n\n\n\n\n\nCharacter string with the name modified according to the rules specified in the function\n\n\n\n\nlibrary(\"tima\")\n\nharmonized_name &lt;- harmonize_names_sirius(\"My_name\")"
  },
  {
    "objectID": "man/harmonize_names_sirius.html#harmonize-names-sirius",
    "href": "man/harmonize_names_sirius.html#harmonize-names-sirius",
    "title": "tima",
    "section": "",
    "text": "This function harmonizes the names of Sirius outputs to make them compatible\n\n\n\nharmonize_names_sirius(x)\n\n\n\n\n\n\n\nx\n\n\nCharacter string containing a name\n\n\n\n\n\n\nCharacter string with the name modified according to the rules specified in the function\n\n\n\n\nlibrary(\"tima\")\n\nharmonized_name &lt;- harmonize_names_sirius(\"My_name\")"
  },
  {
    "objectID": "man/install.html",
    "href": "man/install.html",
    "title": "tima",
    "section": "",
    "text": "This function runs some required install\n\n\n\ninstall(\n  package = \"tima\",\n  repos = c(\"https://taxonomicallyinformedannotation.r-universe.dev\",\n    \"https://bioc.r-universe.dev\", \"https://cloud.r-project.org\"),\n  dependencies = TRUE,\n  test = FALSE\n)\n\n\n\n\n\n\n\npackage\n\n\nPackage name\n\n\n\n\nrepos\n\n\nRepositories for install.packages\n\n\n\n\ndependencies\n\n\nWhether to install dependencies\n\n\n\n\ntest\n\n\nWhether to retry with source or test install\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/install.html#install",
    "href": "man/install.html#install",
    "title": "tima",
    "section": "",
    "text": "This function runs some required install\n\n\n\ninstall(\n  package = \"tima\",\n  repos = c(\"https://taxonomicallyinformedannotation.r-universe.dev\",\n    \"https://bioc.r-universe.dev\", \"https://cloud.r-project.org\"),\n  dependencies = TRUE,\n  test = FALSE\n)\n\n\n\n\n\n\n\npackage\n\n\nPackage name\n\n\n\n\nrepos\n\n\nRepositories for install.packages\n\n\n\n\ndependencies\n\n\nWhether to install dependencies\n\n\n\n\ntest\n\n\nWhether to retry with source or test install\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/get_file.html",
    "href": "man/get_file.html",
    "title": "tima",
    "section": "",
    "text": "This function get files\n\n\n\nget_file(url, export, limit = 3600)\n\n\n\n\n\n\n\nurl\n\n\nURL of the file to be downloaded\n\n\n\n\nexport\n\n\nFile path where the file should be saved\n\n\n\n\nlimit\n\n\nTimeout limit (in seconds)\n\n\n\n\n\n\nThe path to the file\n\n\n\n\nlibrary(\"tima\")\n\ngit &lt;- \"https://github.com/\"\norg &lt;- \"taxonomicallyinformedannotation\"\nrepo &lt;- \"tima-example-files\"\nbranch &lt;- \"main\"\nfile &lt;- \"example_metadata.tsv\"\nget_file(\n  url = paste(git, org, repo, \"raw\", branch, file, sep = \"/\"),\n  export = \"data/source/example_metadata.tsv\"\n)"
  },
  {
    "objectID": "man/get_file.html#get-file",
    "href": "man/get_file.html#get-file",
    "title": "tima",
    "section": "",
    "text": "This function get files\n\n\n\nget_file(url, export, limit = 3600)\n\n\n\n\n\n\n\nurl\n\n\nURL of the file to be downloaded\n\n\n\n\nexport\n\n\nFile path where the file should be saved\n\n\n\n\nlimit\n\n\nTimeout limit (in seconds)\n\n\n\n\n\n\nThe path to the file\n\n\n\n\nlibrary(\"tima\")\n\ngit &lt;- \"https://github.com/\"\norg &lt;- \"taxonomicallyinformedannotation\"\nrepo &lt;- \"tima-example-files\"\nbranch &lt;- \"main\"\nfile &lt;- \"example_metadata.tsv\"\nget_file(\n  url = paste(git, org, repo, \"raw\", branch, file, sep = \"/\"),\n  export = \"data/source/example_metadata.tsv\"\n)"
  },
  {
    "objectID": "man/calculate_mass_of_m.html",
    "href": "man/calculate_mass_of_m.html",
    "title": "tima",
    "section": "",
    "text": "This function calculates the mass of M\n\n\n\ncalculate_mass_of_m(adduct_string, mz, electron_mass = 0.0005485799)\n\n\n\n\n\n\n\nadduct_string\n\n\nAdduct to be parsed\n\n\n\n\nmz\n\n\nmz\n\n\n\n\nelectron_mass\n\n\nElectron mass\n\n\n\n\n\n\nA mass\n\n\n\n\nlibrary(\"tima\")\n\ncalculate_mass_of_m(mz = 123.4567, adduct_string = \"[M+H]+\")\n\n   n_iso \n122.4483 \n\ncalculate_mass_of_m(mz = 123.4567, adduct_string = \"[M+Na]+\")\n\n   n_iso \n100.4664 \n\ncalculate_mass_of_m(mz = 123.4567, adduct_string = \"[2M1-C6H12O6 (hexose)+NaCl+H]2+\")\n\n   n_iso \n185.0046"
  },
  {
    "objectID": "man/calculate_mass_of_m.html#calculate-mass-of-m",
    "href": "man/calculate_mass_of_m.html#calculate-mass-of-m",
    "title": "tima",
    "section": "",
    "text": "This function calculates the mass of M\n\n\n\ncalculate_mass_of_m(adduct_string, mz, electron_mass = 0.0005485799)\n\n\n\n\n\n\n\nadduct_string\n\n\nAdduct to be parsed\n\n\n\n\nmz\n\n\nmz\n\n\n\n\nelectron_mass\n\n\nElectron mass\n\n\n\n\n\n\nA mass\n\n\n\n\nlibrary(\"tima\")\n\ncalculate_mass_of_m(mz = 123.4567, adduct_string = \"[M+H]+\")\n\n   n_iso \n122.4483 \n\ncalculate_mass_of_m(mz = 123.4567, adduct_string = \"[M+Na]+\")\n\n   n_iso \n100.4664 \n\ncalculate_mass_of_m(mz = 123.4567, adduct_string = \"[2M1-C6H12O6 (hexose)+NaCl+H]2+\")\n\n   n_iso \n185.0046"
  },
  {
    "objectID": "man/create_dir.html",
    "href": "man/create_dir.html",
    "title": "tima",
    "section": "",
    "text": "This function creates a directory at the specified path if it does not already exist.\n\n\n\ncreate_dir(export)\n\n\n\n\n\n\n\nexport\n\n\nPath to the directory to be created\n\n\n\n\n\n\nMessage indicating the status of directory creation\n\n\n\n\nlibrary(\"tima\")\n\ncreate_dir(export = \"path/to/directory_of_file\")"
  },
  {
    "objectID": "man/create_dir.html#create-directory",
    "href": "man/create_dir.html#create-directory",
    "title": "tima",
    "section": "",
    "text": "This function creates a directory at the specified path if it does not already exist.\n\n\n\ncreate_dir(export)\n\n\n\n\n\n\n\nexport\n\n\nPath to the directory to be created\n\n\n\n\n\n\nMessage indicating the status of directory creation\n\n\n\n\nlibrary(\"tima\")\n\ncreate_dir(export = \"path/to/directory_of_file\")"
  },
  {
    "objectID": "man/columns_model.html",
    "href": "man/columns_model.html",
    "title": "tima",
    "section": "",
    "text": "This function models columns\n\n\n\ncolumns_model()\n\n\n\n\nThe columns model\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/columns_model.html#columns-model",
    "href": "man/columns_model.html#columns-model",
    "title": "tima",
    "section": "",
    "text": "This function models columns\n\n\n\ncolumns_model()\n\n\n\n\nThe columns model\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/get_example_sirius.html",
    "href": "man/get_example_sirius.html",
    "title": "tima",
    "section": "",
    "text": "This function gets example SIRIUS annotations\n\n\n\nget_example_sirius(\n  url = get_default_paths()\\$urls\\$examples\\$sirius,\n  export = get_default_paths()\\$data\\$interim\\$annotations\\$example_sirius\n)\n\n\n\n\n\n\n\nurl\n\n\nURL where the example is accessible\n\n\n\n\nexport\n\n\nPath where to save the example\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/get_example_sirius.html#get-example-sirius",
    "href": "man/get_example_sirius.html#get-example-sirius",
    "title": "tima",
    "section": "",
    "text": "This function gets example SIRIUS annotations\n\n\n\nget_example_sirius(\n  url = get_default_paths()\\$urls\\$examples\\$sirius,\n  export = get_default_paths()\\$data\\$interim\\$annotations\\$example_sirius\n)\n\n\n\n\n\n\n\nurl\n\n\nURL where the example is accessible\n\n\n\n\nexport\n\n\nPath where to save the example\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/prepare_libraries_sop_ecmdb.html",
    "href": "man/prepare_libraries_sop_ecmdb.html",
    "title": "tima",
    "section": "",
    "text": "Prepare libraries of structure organism pairs ECMDB\n\n\n\nprepare_libraries_sop_ecmdb(\n  input = get_params(step = \"prepare_libraries_sop_ecmdb\")\\$files\\$libraries\\$sop\\$raw\\$ecmdb,\n  output = get_params(step =\n    \"prepare_libraries_sop_ecmdb\")\\$files\\$libraries\\$sop\\$prepared\\$ecmdb\n)\n\n\n\n\n\n\n\ninput\n\n\nInput file\n\n\n\n\noutput\n\n\nOutput file\n\n\n\n\n\n\nThe path to the prepared structure-organism pairs library ECMDB\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\nprepare_libraries_sop_ecmdb()\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/prepare_libraries_sop_ecmdb.html#prepare-libraries-of-structure-organism-pairs-ecmdb",
    "href": "man/prepare_libraries_sop_ecmdb.html#prepare-libraries-of-structure-organism-pairs-ecmdb",
    "title": "tima",
    "section": "",
    "text": "Prepare libraries of structure organism pairs ECMDB\n\n\n\nprepare_libraries_sop_ecmdb(\n  input = get_params(step = \"prepare_libraries_sop_ecmdb\")\\$files\\$libraries\\$sop\\$raw\\$ecmdb,\n  output = get_params(step =\n    \"prepare_libraries_sop_ecmdb\")\\$files\\$libraries\\$sop\\$prepared\\$ecmdb\n)\n\n\n\n\n\n\n\ninput\n\n\nInput file\n\n\n\n\noutput\n\n\nOutput file\n\n\n\n\n\n\nThe path to the prepared structure-organism pairs library ECMDB\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\nprepare_libraries_sop_ecmdb()\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/prepare_libraries_sop_closed.html",
    "href": "man/prepare_libraries_sop_closed.html",
    "title": "tima",
    "section": "",
    "text": "Prepare libraries of structure organism pairs CLOSED\n\n\n\nprepare_libraries_sop_closed(\n  input = get_params(step =\n    \"prepare_libraries_sop_closed\")\\$files\\$libraries\\$sop\\$raw\\$closed,\n  output = get_params(step =\n    \"prepare_libraries_sop_closed\")\\$files\\$libraries\\$sop\\$prepared\\$closed\n)\n\n\n\n\n\n\n\ninput\n\n\nInput file\n\n\n\n\noutput\n\n\nOutput file\n\n\n\n\n\n\nThe path to the prepared structure-organism pairs library CLOSED\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\nprepare_libraries_sop_closed()\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/prepare_libraries_sop_closed.html#prepare-libraries-of-structure-organism-pairs-closed",
    "href": "man/prepare_libraries_sop_closed.html#prepare-libraries-of-structure-organism-pairs-closed",
    "title": "tima",
    "section": "",
    "text": "Prepare libraries of structure organism pairs CLOSED\n\n\n\nprepare_libraries_sop_closed(\n  input = get_params(step =\n    \"prepare_libraries_sop_closed\")\\$files\\$libraries\\$sop\\$raw\\$closed,\n  output = get_params(step =\n    \"prepare_libraries_sop_closed\")\\$files\\$libraries\\$sop\\$prepared\\$closed\n)\n\n\n\n\n\n\n\ninput\n\n\nInput file\n\n\n\n\noutput\n\n\nOutput file\n\n\n\n\n\n\nThe path to the prepared structure-organism pairs library CLOSED\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\nprepare_libraries_sop_closed()\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/summarize_results.html",
    "href": "man/summarize_results.html",
    "title": "tima",
    "section": "",
    "text": "This function summarizes results\n\n\n\nsummarize_results(\n  df,\n  features_table,\n  components_table,\n  structure_organism_pairs_table,\n  annot_table_wei_chemo,\n  remove_ties,\n  summarize\n)\n\n\n\n\n\n\n\ndf\n\n\nDataframe\n\n\n\n\nfeatures_table\n\n\nPrepared features file\n\n\n\n\ncomponents_table\n\n\nPrepared components file\n\n\n\n\nstructure_organism_pairs_table\n\n\nTable containing the structure - organism pairs\n\n\n\n\nannot_table_wei_chemo\n\n\nTable containing your chemically weighted annotation\n\n\n\n\nremove_ties\n\n\nRemove ties. BOOLEAN\n\n\n\n\nsummarize\n\n\nBoolean. summarize results (1 row per feature)\n\n\n\n\n\n\nA summarized table\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/summarize_results.html#summarize-results",
    "href": "man/summarize_results.html#summarize-results",
    "title": "tima",
    "section": "",
    "text": "This function summarizes results\n\n\n\nsummarize_results(\n  df,\n  features_table,\n  components_table,\n  structure_organism_pairs_table,\n  annot_table_wei_chemo,\n  remove_ties,\n  summarize\n)\n\n\n\n\n\n\n\ndf\n\n\nDataframe\n\n\n\n\nfeatures_table\n\n\nPrepared features file\n\n\n\n\ncomponents_table\n\n\nPrepared components file\n\n\n\n\nstructure_organism_pairs_table\n\n\nTable containing the structure - organism pairs\n\n\n\n\nannot_table_wei_chemo\n\n\nTable containing your chemically weighted annotation\n\n\n\n\nremove_ties\n\n\nRemove ties. BOOLEAN\n\n\n\n\nsummarize\n\n\nBoolean. summarize results (1 row per feature)\n\n\n\n\n\n\nA summarized table\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/parse_cli_params.html",
    "href": "man/parse_cli_params.html",
    "title": "tima",
    "section": "",
    "text": "This function parses command line parameters\n\n\n\nparse_cli_params(arguments, parameters)\n\n\n\n\n\n\n\narguments\n\n\nCLI arguments\n\n\n\n\nparameters\n\n\nParameters\n\n\n\n\n\n\nParameters coming from the CLI\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/parse_cli_params.html#parse-cli-parameters",
    "href": "man/parse_cli_params.html#parse-cli-parameters",
    "title": "tima",
    "section": "",
    "text": "This function parses command line parameters\n\n\n\nparse_cli_params(arguments, parameters)\n\n\n\n\n\n\n\narguments\n\n\nCLI arguments\n\n\n\n\nparameters\n\n\nParameters\n\n\n\n\n\n\nParameters coming from the CLI\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/read_from_sirius_zip.html",
    "href": "man/read_from_sirius_zip.html",
    "title": "tima",
    "section": "",
    "text": "This function reads files from Sirius compressed workspace\n\n\n\nread_from_sirius_zip(sirius_zip, file)\n\n\n\n\n\n\n\nsirius_zip\n\n\nCompressed directory containing the Sirius results\n\n\n\n\nfile\n\n\nFile to be read\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/read_from_sirius_zip.html#read-from-sirius-zip",
    "href": "man/read_from_sirius_zip.html#read-from-sirius-zip",
    "title": "tima",
    "section": "",
    "text": "This function reads files from Sirius compressed workspace\n\n\n\nread_from_sirius_zip(sirius_zip, file)\n\n\n\n\n\n\n\nsirius_zip\n\n\nCompressed directory containing the Sirius results\n\n\n\n\nfile\n\n\nFile to be read\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/select_sirius_columns_formulas.html",
    "href": "man/select_sirius_columns_formulas.html",
    "title": "tima",
    "section": "",
    "text": "This function selects sirius columns (formulas)\n\n\n\nselect_sirius_columns_formulas(df, sirius_version)\n\n\n\n\n\n\n\ndf\n\n\nDataframe\n\n\n\n\nsirius_version\n\n\nSirius version\n\n\n\n\n\n\nThe dataframe with selected sirius columns\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/select_sirius_columns_formulas.html#select-sirius-columns-formulas",
    "href": "man/select_sirius_columns_formulas.html#select-sirius-columns-formulas",
    "title": "tima",
    "section": "",
    "text": "This function selects sirius columns (formulas)\n\n\n\nselect_sirius_columns_formulas(df, sirius_version)\n\n\n\n\n\n\n\ndf\n\n\nDataframe\n\n\n\n\nsirius_version\n\n\nSirius version\n\n\n\n\n\n\nThe dataframe with selected sirius columns\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/join_gnps_wrapper.html",
    "href": "man/join_gnps_wrapper.html",
    "title": "tima",
    "section": "",
    "text": "Wrapper for the C function \"join_gnps\"\n\n\n\njoin_gnps_wrapper(x, y, xPrecursorMz, yPrecursorMz, tolerance, ppm)\n\n\n\n\n\n\n\nx\n\n\nNumeric vector or matrix for query masses.\n\n\n\n\ny\n\n\nNumeric vector or matrix for target masses.\n\n\n\n\nxPrecursorMz\n\n\nNumeric vector of precursor values for queries.\n\n\n\n\nyPrecursorMz\n\n\nNumeric vector of precursor values for targets.\n\n\n\n\ntolerance\n\n\nNumeric value specifying the tolerance in daltons.\n\n\n\n\nppm\n\n\nNumeric value specifying the tolerance in ppm.\n\n\n\n\n\n\nThe result returned from the C function \"join_gnps\"."
  },
  {
    "objectID": "man/join_gnps_wrapper.html#wrapper-for-the-c-function-join_gnps",
    "href": "man/join_gnps_wrapper.html#wrapper-for-the-c-function-join_gnps",
    "title": "tima",
    "section": "",
    "text": "Wrapper for the C function \"join_gnps\"\n\n\n\njoin_gnps_wrapper(x, y, xPrecursorMz, yPrecursorMz, tolerance, ppm)\n\n\n\n\n\n\n\nx\n\n\nNumeric vector or matrix for query masses.\n\n\n\n\ny\n\n\nNumeric vector or matrix for target masses.\n\n\n\n\nxPrecursorMz\n\n\nNumeric vector of precursor values for queries.\n\n\n\n\nyPrecursorMz\n\n\nNumeric vector of precursor values for targets.\n\n\n\n\ntolerance\n\n\nNumeric value specifying the tolerance in daltons.\n\n\n\n\nppm\n\n\nNumeric value specifying the tolerance in ppm.\n\n\n\n\n\n\nThe result returned from the C function \"join_gnps\"."
  },
  {
    "objectID": "man/calculate_entropy_and_similarity.html",
    "href": "man/calculate_entropy_and_similarity.html",
    "title": "tima",
    "section": "",
    "text": "This function applies similarity calculation to a list of spectra to obtain entropy scores\n\n\n\ncalculate_entropy_and_similarity(\n  lib_ids,\n  lib_precursors,\n  lib_spectra,\n  query_ids,\n  query_precursors,\n  query_spectra,\n  method,\n  dalton,\n  ppm,\n  threshold,\n  approx\n)\n\n\n\n\n\n\n\nlib_ids\n\n\nLib Ids\n\n\n\n\nlib_precursors\n\n\nLib precursors\n\n\n\n\nlib_spectra\n\n\nLib spectra\n\n\n\n\nquery_ids\n\n\nQuery Ids\n\n\n\n\nquery_precursors\n\n\nQuery precursors\n\n\n\n\nquery_spectra\n\n\nQuery spectra\n\n\n\n\nmethod\n\n\nMethod\n\n\n\n\ndalton\n\n\nDalton\n\n\n\n\nppm\n\n\nPpm\n\n\n\n\nthreshold\n\n\nThreshold\n\n\n\n\napprox\n\n\nApprox\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/calculate_entropy_and_similarity.html#calculate-entropy-score",
    "href": "man/calculate_entropy_and_similarity.html#calculate-entropy-score",
    "title": "tima",
    "section": "",
    "text": "This function applies similarity calculation to a list of spectra to obtain entropy scores\n\n\n\ncalculate_entropy_and_similarity(\n  lib_ids,\n  lib_precursors,\n  lib_spectra,\n  query_ids,\n  query_precursors,\n  query_spectra,\n  method,\n  dalton,\n  ppm,\n  threshold,\n  approx\n)\n\n\n\n\n\n\n\nlib_ids\n\n\nLib Ids\n\n\n\n\nlib_precursors\n\n\nLib precursors\n\n\n\n\nlib_spectra\n\n\nLib spectra\n\n\n\n\nquery_ids\n\n\nQuery Ids\n\n\n\n\nquery_precursors\n\n\nQuery precursors\n\n\n\n\nquery_spectra\n\n\nQuery spectra\n\n\n\n\nmethod\n\n\nMethod\n\n\n\n\ndalton\n\n\nDalton\n\n\n\n\nppm\n\n\nPpm\n\n\n\n\nthreshold\n\n\nThreshold\n\n\n\n\napprox\n\n\nApprox\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/run_app.html",
    "href": "man/run_app.html",
    "title": "tima",
    "section": "",
    "text": "This function runs the app\n\n\n\nrun_app(host = \"127.0.0.1\", port = 3838, browser = TRUE)\n\n\n\n\n\n\n\nhost\n\n\nHost. Default to 127.0.0.1\n\n\n\n\nport\n\n\nPort. Default to 3838\n\n\n\n\nbrowser\n\n\nFlag for browser use. Default to TRUE\n\n\n\n\n\n\nOpens the app\n\n\n\n\nlibrary(\"tima\")\n\nrun_app()"
  },
  {
    "objectID": "man/run_app.html#run-app",
    "href": "man/run_app.html#run-app",
    "title": "tima",
    "section": "",
    "text": "This function runs the app\n\n\n\nrun_app(host = \"127.0.0.1\", port = 3838, browser = TRUE)\n\n\n\n\n\n\n\nhost\n\n\nHost. Default to 127.0.0.1\n\n\n\n\nport\n\n\nPort. Default to 3838\n\n\n\n\nbrowser\n\n\nFlag for browser use. Default to TRUE\n\n\n\n\n\n\nOpens the app\n\n\n\n\nlibrary(\"tima\")\n\nrun_app()"
  },
  {
    "objectID": "man/harmonize_spectra.html",
    "href": "man/harmonize_spectra.html",
    "title": "tima",
    "section": "",
    "text": "This function harmonizes spectra headers\n\n\n\nharmonize_spectra(\n  spectra,\n  metad = get(\"metad\", envir = parent.frame()),\n  mode,\n  col_ad = get(\"col_ad\", envir = parent.frame()),\n  col_ce = get(\"col_ce\", envir = parent.frame()),\n  col_ci = get(\"col_ci\", envir = parent.frame()),\n  col_em = get(\"col_em\", envir = parent.frame()),\n  col_in = get(\"col_in\", envir = parent.frame()),\n  col_io = get(\"col_io\", envir = parent.frame()),\n  col_ik = get(\"col_ik\", envir = parent.frame()),\n  col_il = get(\"col_il\", envir = parent.frame()),\n  col_mf = get(\"col_mf\", envir = parent.frame()),\n  col_na = get(\"col_na\", envir = parent.frame()),\n  col_po = get(\"col_po\", envir = parent.frame()),\n  col_sm = get(\"col_sm\", envir = parent.frame()),\n  col_sn = get(\"col_sn\", envir = parent.frame()),\n  col_si = get(\"col_si\", envir = parent.frame()),\n  col_sp = get(\"col_sp\", envir = parent.frame()),\n  col_sy = get(\"col_sy\", envir = parent.frame()),\n  col_xl = get(\"col_xl\", envir = parent.frame())\n)\n\n\n\n\n\n\n\nspectra\n\n\nSpectra object to be harmonized\n\n\n\n\nmetad\n\n\nMetadata to identify the library\n\n\n\n\nmode\n\n\nMS ionization mode. Must contain ‘pos’ or ‘neg’\n\n\n\n\ncol_ad\n\n\nName of the adduct in mgf\n\n\n\n\ncol_ce\n\n\nName of the collision energy in mgf\n\n\n\n\ncol_ci\n\n\nName of the compound id in mgf\n\n\n\n\ncol_em\n\n\nName of the exact mass in mgf\n\n\n\n\ncol_in\n\n\nName of the InChI in mgf\n\n\n\n\ncol_io\n\n\nName of the InChI without stereo in mgf\n\n\n\n\ncol_ik\n\n\nName of the InChIKey in mgf\n\n\n\n\ncol_il\n\n\nName of the InChIKey without stereo in mgf\n\n\n\n\ncol_mf\n\n\nName of the molecular formula in mgf\n\n\n\n\ncol_na\n\n\nName of the name in mgf\n\n\n\n\ncol_po\n\n\nName of the polarity in mgf\n\n\n\n\ncol_sm\n\n\nName of the SMILES in mgf\n\n\n\n\ncol_sn\n\n\nName of the SMILES without stereo in mgf\n\n\n\n\ncol_si\n\n\nName of the spectrum id in mgf\n\n\n\n\ncol_sp\n\n\nName of the SPLASH in mgf\n\n\n\n\ncol_sy\n\n\nName of the synonyms in mgf\n\n\n\n\ncol_xl\n\n\nName of the xlogp in mgf\n\n\n\n\n\n\nThe harmonized spectra\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/harmonize_spectra.html#harmonize-spectra",
    "href": "man/harmonize_spectra.html#harmonize-spectra",
    "title": "tima",
    "section": "",
    "text": "This function harmonizes spectra headers\n\n\n\nharmonize_spectra(\n  spectra,\n  metad = get(\"metad\", envir = parent.frame()),\n  mode,\n  col_ad = get(\"col_ad\", envir = parent.frame()),\n  col_ce = get(\"col_ce\", envir = parent.frame()),\n  col_ci = get(\"col_ci\", envir = parent.frame()),\n  col_em = get(\"col_em\", envir = parent.frame()),\n  col_in = get(\"col_in\", envir = parent.frame()),\n  col_io = get(\"col_io\", envir = parent.frame()),\n  col_ik = get(\"col_ik\", envir = parent.frame()),\n  col_il = get(\"col_il\", envir = parent.frame()),\n  col_mf = get(\"col_mf\", envir = parent.frame()),\n  col_na = get(\"col_na\", envir = parent.frame()),\n  col_po = get(\"col_po\", envir = parent.frame()),\n  col_sm = get(\"col_sm\", envir = parent.frame()),\n  col_sn = get(\"col_sn\", envir = parent.frame()),\n  col_si = get(\"col_si\", envir = parent.frame()),\n  col_sp = get(\"col_sp\", envir = parent.frame()),\n  col_sy = get(\"col_sy\", envir = parent.frame()),\n  col_xl = get(\"col_xl\", envir = parent.frame())\n)\n\n\n\n\n\n\n\nspectra\n\n\nSpectra object to be harmonized\n\n\n\n\nmetad\n\n\nMetadata to identify the library\n\n\n\n\nmode\n\n\nMS ionization mode. Must contain ‘pos’ or ‘neg’\n\n\n\n\ncol_ad\n\n\nName of the adduct in mgf\n\n\n\n\ncol_ce\n\n\nName of the collision energy in mgf\n\n\n\n\ncol_ci\n\n\nName of the compound id in mgf\n\n\n\n\ncol_em\n\n\nName of the exact mass in mgf\n\n\n\n\ncol_in\n\n\nName of the InChI in mgf\n\n\n\n\ncol_io\n\n\nName of the InChI without stereo in mgf\n\n\n\n\ncol_ik\n\n\nName of the InChIKey in mgf\n\n\n\n\ncol_il\n\n\nName of the InChIKey without stereo in mgf\n\n\n\n\ncol_mf\n\n\nName of the molecular formula in mgf\n\n\n\n\ncol_na\n\n\nName of the name in mgf\n\n\n\n\ncol_po\n\n\nName of the polarity in mgf\n\n\n\n\ncol_sm\n\n\nName of the SMILES in mgf\n\n\n\n\ncol_sn\n\n\nName of the SMILES without stereo in mgf\n\n\n\n\ncol_si\n\n\nName of the spectrum id in mgf\n\n\n\n\ncol_sp\n\n\nName of the SPLASH in mgf\n\n\n\n\ncol_sy\n\n\nName of the synonyms in mgf\n\n\n\n\ncol_xl\n\n\nName of the xlogp in mgf\n\n\n\n\n\n\nThe harmonized spectra\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/go_to_cache.html",
    "href": "man/go_to_cache.html",
    "title": "tima",
    "section": "",
    "text": "This function goes to cache\n\n\n\ngo_to_cache(dir = \".tima\")\n\n\n\n\n\n\n\ndir\n\n\nDirectory\n\n\n\n\n\n\nGoes to cache\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/go_to_cache.html#go-to-cache",
    "href": "man/go_to_cache.html#go-to-cache",
    "title": "tima",
    "section": "",
    "text": "This function goes to cache\n\n\n\ngo_to_cache(dir = \".tima\")\n\n\n\n\n\n\n\ndir\n\n\nDirectory\n\n\n\n\n\n\nGoes to cache\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/calculate_similarity.html",
    "href": "man/calculate_similarity.html",
    "title": "tima",
    "section": "",
    "text": "Efficiently calculates similarity scores between query and target spectra using either entropy or GNPS methods\n\n\n\ncalculate_similarity(\n  method,\n  query_spectrum,\n  target_spectrum,\n  query_precursor,\n  target_precursor,\n  dalton,\n  ppm,\n  return_matched_peaks = FALSE,\n  ...\n)\n\n\n\n\n\n\n\nmethod\n\n\nMethod (\"entropy\" or \"gnps\")\n\n\n\n\nquery_spectrum\n\n\nQuery spectrum matrix\n\n\n\n\ntarget_spectrum\n\n\nTarget spectrum matrix\n\n\n\n\nquery_precursor\n\n\nQuery precursor\n\n\n\n\ntarget_precursor\n\n\nTarget precursor\n\n\n\n\ndalton\n\n\nDalton tolerance\n\n\n\n\nppm\n\n\nPPM tolerance\n\n\n\n\nreturn_matched_peaks\n\n\nReturn matched peaks. Not compatible with ‘entropy’. Default: FALSE\n\n\n\n\n…\n\n\nNot documented for now\n\n\n\n\n\n\nSimilarity score or NA_real_ if calculation fails\n\n\n\n\nlibrary(\"tima\")\n\nsp_1 &lt;- cbind(\n  mz = c(10, 36, 63, 91, 93),\n  intensity = c(14, 15, 999, 650, 1)\n)\nprecursor_1 &lt;- 123.4567\nprecursor_2 &lt;- precursor_1 + 14\nsp_2 &lt;- cbind(\n  mz = c(10, 12, 50, 63, 105),\n  intensity = c(35, 5, 16, 999, 450)\n)\ncalculate_similarity(\n  method = \"entropy\",\n  query_spectrum = sp_1,\n  target_spectrum = sp_2,\n  query_precursor = precursor_1,\n  target_precursor = precursor_2,\n  dalton = 0.005,\n  ppm = 10.0\n)\n\n[1] 0.5427377\n\ncalculate_similarity(\n  method = \"gnps\",\n  query_spectrum = sp_1,\n  target_spectrum = sp_2,\n  query_precursor = precursor_1,\n  target_precursor = precursor_2,\n  dalton = 0.005,\n  ppm = 10.0,\n  return_matched_peaks = TRUE\n)\n\n$score\n[1] 0.9923501\n\n$matches\n[1] 4"
  },
  {
    "objectID": "man/calculate_similarity.html#calculate-similarity-between-spectra",
    "href": "man/calculate_similarity.html#calculate-similarity-between-spectra",
    "title": "tima",
    "section": "",
    "text": "Efficiently calculates similarity scores between query and target spectra using either entropy or GNPS methods\n\n\n\ncalculate_similarity(\n  method,\n  query_spectrum,\n  target_spectrum,\n  query_precursor,\n  target_precursor,\n  dalton,\n  ppm,\n  return_matched_peaks = FALSE,\n  ...\n)\n\n\n\n\n\n\n\nmethod\n\n\nMethod (\"entropy\" or \"gnps\")\n\n\n\n\nquery_spectrum\n\n\nQuery spectrum matrix\n\n\n\n\ntarget_spectrum\n\n\nTarget spectrum matrix\n\n\n\n\nquery_precursor\n\n\nQuery precursor\n\n\n\n\ntarget_precursor\n\n\nTarget precursor\n\n\n\n\ndalton\n\n\nDalton tolerance\n\n\n\n\nppm\n\n\nPPM tolerance\n\n\n\n\nreturn_matched_peaks\n\n\nReturn matched peaks. Not compatible with ‘entropy’. Default: FALSE\n\n\n\n\n…\n\n\nNot documented for now\n\n\n\n\n\n\nSimilarity score or NA_real_ if calculation fails\n\n\n\n\nlibrary(\"tima\")\n\nsp_1 &lt;- cbind(\n  mz = c(10, 36, 63, 91, 93),\n  intensity = c(14, 15, 999, 650, 1)\n)\nprecursor_1 &lt;- 123.4567\nprecursor_2 &lt;- precursor_1 + 14\nsp_2 &lt;- cbind(\n  mz = c(10, 12, 50, 63, 105),\n  intensity = c(35, 5, 16, 999, 450)\n)\ncalculate_similarity(\n  method = \"entropy\",\n  query_spectrum = sp_1,\n  target_spectrum = sp_2,\n  query_precursor = precursor_1,\n  target_precursor = precursor_2,\n  dalton = 0.005,\n  ppm = 10.0\n)\n\n[1] 0.5427377\n\ncalculate_similarity(\n  method = \"gnps\",\n  query_spectrum = sp_1,\n  target_spectrum = sp_2,\n  query_precursor = precursor_1,\n  target_precursor = precursor_2,\n  dalton = 0.005,\n  ppm = 10.0,\n  return_matched_peaks = TRUE\n)\n\n$score\n[1] 0.9923501\n\n$matches\n[1] 4"
  },
  {
    "objectID": "man/read_mgf_opti.html",
    "href": "man/read_mgf_opti.html",
    "title": "tima",
    "section": "",
    "text": "This function reads a Mascot Generic Format (MGF) file while mimicking the MsBackendMgf implementation but using significantly lower memory, making it more suitable for large MGF files.\n\n\n\nread_mgf_opti(\n  f,\n  msLevel = 2L,\n  mapping = Spectra::spectraVariableMapping(MsBackendMgf::MsBackendMgf())\n)\n\n\n\n\n\n\n\nf\n\n\nA character string specifying the path to a single MGF file.\n\n\n\n\nmsLevel\n\n\nAn integer specifying the MS level. Default is 2L.\n\n\n\n\nmapping\n\n\nA named character vector mapping MGF fields to standard spectra variables. Defaults to Spectra::spectraVariableMapping(MsBackendMgf::MsBackendMgf()).\n\n\n\n\n\n\nA DataFrame containing the parsed spectra data.\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/read_mgf_opti.html#read-mgf-opti",
    "href": "man/read_mgf_opti.html#read-mgf-opti",
    "title": "tima",
    "section": "",
    "text": "This function reads a Mascot Generic Format (MGF) file while mimicking the MsBackendMgf implementation but using significantly lower memory, making it more suitable for large MGF files.\n\n\n\nread_mgf_opti(\n  f,\n  msLevel = 2L,\n  mapping = Spectra::spectraVariableMapping(MsBackendMgf::MsBackendMgf())\n)\n\n\n\n\n\n\n\nf\n\n\nA character string specifying the path to a single MGF file.\n\n\n\n\nmsLevel\n\n\nAn integer specifying the MS level. Default is 2L.\n\n\n\n\nmapping\n\n\nA named character vector mapping MGF fields to standard spectra variables. Defaults to Spectra::spectraVariableMapping(MsBackendMgf::MsBackendMgf()).\n\n\n\n\n\n\nA DataFrame containing the parsed spectra data.\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/prepare_annotations_spectra.html",
    "href": "man/prepare_annotations_spectra.html",
    "title": "tima",
    "section": "",
    "text": "This function prepares the spectral matches obtained previously to make them compatible\n\n\n\nprepare_annotations_spectra(\n  input = get_params(step =\n    \"prepare_annotations_spectra\")\\$files\\$annotations\\$raw\\$spectral\\$spectral,\n  output = get_params(step =\n    \"prepare_annotations_spectra\")\\$files\\$annotations\\$prepared\\$structural\\$spectral,\n  str_stereo = get_params(step =\n    \"prepare_annotations_spectra\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$stereo,\n  str_met = get_params(step =\n    \"prepare_annotations_spectra\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$metadata,\n  str_nam = get_params(step =\n    \"prepare_annotations_spectra\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$names,\n  str_tax_cla = get_params(step =\n    \"prepare_annotations_spectra\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$taxonomies\\$cla,\n  str_tax_npc = get_params(step =\n    \"prepare_annotations_spectra\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$taxonomies\\$npc\n)\n\n\n\n\n\n\n\ninput\n\n\nInput file\n\n\n\n\noutput\n\n\nOutput file\n\n\n\n\nstr_stereo\n\n\nFile containing structures stereo\n\n\n\n\nstr_met\n\n\nFile containing structures metadata\n\n\n\n\nstr_nam\n\n\nFile containing structures names\n\n\n\n\nstr_tax_cla\n\n\nFile containing Classyfire taxonomy\n\n\n\n\nstr_tax_npc\n\n\nFile containing NPClassifier taxonomy\n\n\n\n\n\n\nThe path to the prepared spectral annotations\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\ngithub &lt;- \"https://raw.githubusercontent.com/\"\nrepo &lt;- \"taxonomicallyinformedannotation/tima-example-files/main/\"\ndata_interim &lt;- \"data/interim/\"\ndir &lt;- paste0(github, repo)\ninput &lt;- get_params(step = \"prepare_annotations_spectra\")$files$annotations$raw$spectral$spectral |&gt;\n  gsub(\n    pattern = \".tsv.gz\",\n    replacement = \"_pos.tsv\",\n    fixed = TRUE\n  )\nget_file(url = paste0(dir, input), export = input)\ndir &lt;- paste0(dir, data_interim)\nprepare_annotations_spectra(\n  input = input,\n  str_stereo = paste0(dir, \"libraries/sop/merged/structures/stereo.tsv\"),\n  str_met = paste0(dir, \"libraries/sop/merged/structures/metadata.tsv\"),\n  str_nam = paste0(dir, \"libraries/sop/merged/structures/names.tsv\"),\n  str_tax_cla = paste0(dir, \"libraries/sop/merged/structures/taxonomies/classyfire.tsv\"),\n  str_tax_npc = paste0(dir, \"libraries/sop/merged/structures/taxonomies/npc.tsv\")\n)\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/prepare_annotations_spectra.html#prepare-annotations-ms2",
    "href": "man/prepare_annotations_spectra.html#prepare-annotations-ms2",
    "title": "tima",
    "section": "",
    "text": "This function prepares the spectral matches obtained previously to make them compatible\n\n\n\nprepare_annotations_spectra(\n  input = get_params(step =\n    \"prepare_annotations_spectra\")\\$files\\$annotations\\$raw\\$spectral\\$spectral,\n  output = get_params(step =\n    \"prepare_annotations_spectra\")\\$files\\$annotations\\$prepared\\$structural\\$spectral,\n  str_stereo = get_params(step =\n    \"prepare_annotations_spectra\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$stereo,\n  str_met = get_params(step =\n    \"prepare_annotations_spectra\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$metadata,\n  str_nam = get_params(step =\n    \"prepare_annotations_spectra\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$names,\n  str_tax_cla = get_params(step =\n    \"prepare_annotations_spectra\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$taxonomies\\$cla,\n  str_tax_npc = get_params(step =\n    \"prepare_annotations_spectra\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$taxonomies\\$npc\n)\n\n\n\n\n\n\n\ninput\n\n\nInput file\n\n\n\n\noutput\n\n\nOutput file\n\n\n\n\nstr_stereo\n\n\nFile containing structures stereo\n\n\n\n\nstr_met\n\n\nFile containing structures metadata\n\n\n\n\nstr_nam\n\n\nFile containing structures names\n\n\n\n\nstr_tax_cla\n\n\nFile containing Classyfire taxonomy\n\n\n\n\nstr_tax_npc\n\n\nFile containing NPClassifier taxonomy\n\n\n\n\n\n\nThe path to the prepared spectral annotations\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\ngithub &lt;- \"https://raw.githubusercontent.com/\"\nrepo &lt;- \"taxonomicallyinformedannotation/tima-example-files/main/\"\ndata_interim &lt;- \"data/interim/\"\ndir &lt;- paste0(github, repo)\ninput &lt;- get_params(step = \"prepare_annotations_spectra\")$files$annotations$raw$spectral$spectral |&gt;\n  gsub(\n    pattern = \".tsv.gz\",\n    replacement = \"_pos.tsv\",\n    fixed = TRUE\n  )\nget_file(url = paste0(dir, input), export = input)\ndir &lt;- paste0(dir, data_interim)\nprepare_annotations_spectra(\n  input = input,\n  str_stereo = paste0(dir, \"libraries/sop/merged/structures/stereo.tsv\"),\n  str_met = paste0(dir, \"libraries/sop/merged/structures/metadata.tsv\"),\n  str_nam = paste0(dir, \"libraries/sop/merged/structures/names.tsv\"),\n  str_tax_cla = paste0(dir, \"libraries/sop/merged/structures/taxonomies/classyfire.tsv\"),\n  str_tax_npc = paste0(dir, \"libraries/sop/merged/structures/taxonomies/npc.tsv\")\n)\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/parse_adduct.html",
    "href": "man/parse_adduct.html",
    "title": "tima",
    "section": "",
    "text": "This function parses adducts\n\n\n\nparse_adduct(\n  adduct_string,\n  regex = \"\\\\[(\\\\d*)M(?![a-z])(\\\\d*)([+-][\\\\w\\\\d].*)?.*\\\\](\\\\d*)([+-])?\"\n)\n\n\n\n\n\n\n\nadduct_string\n\n\nAdduct to be parsed\n\n\n\n\nregex\n\n\nRegex used for parsing\n\n\n\n\n\n\nParsed elements from adduct\n\n\n\n\nlibrary(\"tima\")\n\nparse_adduct(\"[M+H]+\")\nparse_adduct(\"[2M1-C6H12O6 (hexose)+NaCl+H]2+\")"
  },
  {
    "objectID": "man/parse_adduct.html#parse-adduct",
    "href": "man/parse_adduct.html#parse-adduct",
    "title": "tima",
    "section": "",
    "text": "This function parses adducts\n\n\n\nparse_adduct(\n  adduct_string,\n  regex = \"\\\\[(\\\\d*)M(?![a-z])(\\\\d*)([+-][\\\\w\\\\d].*)?.*\\\\](\\\\d*)([+-])?\"\n)\n\n\n\n\n\n\n\nadduct_string\n\n\nAdduct to be parsed\n\n\n\n\nregex\n\n\nRegex used for parsing\n\n\n\n\n\n\nParsed elements from adduct\n\n\n\n\nlibrary(\"tima\")\n\nparse_adduct(\"[M+H]+\")\nparse_adduct(\"[2M1-C6H12O6 (hexose)+NaCl+H]2+\")"
  },
  {
    "objectID": "man/get_example_files.html",
    "href": "man/get_example_files.html",
    "title": "tima",
    "section": "",
    "text": "This function downloads example files\n\n\n\nget_example_files(\n  example = c(\"features\", \"metadata\", \"sirius\", \"spectra\"),\n  in_cache = TRUE\n)\n\n\n\n\n\n\n\nexample\n\n\nThe example(s) you want to download\n\n\n\n\nin_cache\n\n\nFlag to indicate if storing the files in cache\n\n\n\n\n\n\nExample files.\n\n\n\n\nlibrary(\"tima\")\n\nget_example_files(example = c(\"features\"), in_cache = FALSE)"
  },
  {
    "objectID": "man/get_example_files.html#get-example-files",
    "href": "man/get_example_files.html#get-example-files",
    "title": "tima",
    "section": "",
    "text": "This function downloads example files\n\n\n\nget_example_files(\n  example = c(\"features\", \"metadata\", \"sirius\", \"spectra\"),\n  in_cache = TRUE\n)\n\n\n\n\n\n\n\nexample\n\n\nThe example(s) you want to download\n\n\n\n\nin_cache\n\n\nFlag to indicate if storing the files in cache\n\n\n\n\n\n\nExample files.\n\n\n\n\nlibrary(\"tima\")\n\nget_example_files(example = c(\"features\"), in_cache = FALSE)"
  },
  {
    "objectID": "man/prepare_features_edges.html",
    "href": "man/prepare_features_edges.html",
    "title": "tima",
    "section": "",
    "text": "This function prepares edges for further use\n\n\n\nprepare_features_edges(\n  input = get_params(step = \"prepare_features_edges\")\\$files\\$networks\\$spectral\\$edges\\$raw,\n  output = get_params(step =\n    \"prepare_features_edges\")\\$files\\$networks\\$spectral\\$edges\\$prepared,\n  name_source = get_params(step = \"prepare_features_edges\")\\$names\\$source,\n  name_target = get_params(step = \"prepare_features_edges\")\\$names\\$target\n)\n\n\n\n\n\n\n\ninput\n\n\nInput file if ‘manual’\n\n\n\n\noutput\n\n\nOutput file\n\n\n\n\nname_source\n\n\nName of the source features column\n\n\n\n\nname_target\n\n\nName of the target features column\n\n\n\n\n\n\nThe path to the prepared edges\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\ngithub &lt;- \"https://raw.githubusercontent.com/\"\nrepo &lt;- \"taxonomicallyinformedannotation/tima-example-files/main/\"\ndir &lt;- paste0(github, repo)\ninput_1 &lt;- get_params(step = \"prepare_features_edges\")$files$networks$spectral$edges$raw$ms1\ninput_2 &lt;- get_params(step = \"prepare_features_edges\")$files$networks$spectral$edges$raw$spectral\nget_file(url = paste0(dir, input_1), export = input_1)\nget_file(url = paste0(dir, input_2), export = input_2)\nprepare_features_edges(\n  input = list(\"ms1\" = input_1, \"spectral\" = input_2)\n)\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/prepare_features_edges.html#prepare-features-edges",
    "href": "man/prepare_features_edges.html#prepare-features-edges",
    "title": "tima",
    "section": "",
    "text": "This function prepares edges for further use\n\n\n\nprepare_features_edges(\n  input = get_params(step = \"prepare_features_edges\")\\$files\\$networks\\$spectral\\$edges\\$raw,\n  output = get_params(step =\n    \"prepare_features_edges\")\\$files\\$networks\\$spectral\\$edges\\$prepared,\n  name_source = get_params(step = \"prepare_features_edges\")\\$names\\$source,\n  name_target = get_params(step = \"prepare_features_edges\")\\$names\\$target\n)\n\n\n\n\n\n\n\ninput\n\n\nInput file if ‘manual’\n\n\n\n\noutput\n\n\nOutput file\n\n\n\n\nname_source\n\n\nName of the source features column\n\n\n\n\nname_target\n\n\nName of the target features column\n\n\n\n\n\n\nThe path to the prepared edges\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\ngithub &lt;- \"https://raw.githubusercontent.com/\"\nrepo &lt;- \"taxonomicallyinformedannotation/tima-example-files/main/\"\ndir &lt;- paste0(github, repo)\ninput_1 &lt;- get_params(step = \"prepare_features_edges\")$files$networks$spectral$edges$raw$ms1\ninput_2 &lt;- get_params(step = \"prepare_features_edges\")$files$networks$spectral$edges$raw$spectral\nget_file(url = paste0(dir, input_1), export = input_1)\nget_file(url = paste0(dir, input_2), export = input_2)\nprepare_features_edges(\n  input = list(\"ms1\" = input_1, \"spectral\" = input_2)\n)\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/prepare_libraries_sop_merged.html",
    "href": "man/prepare_libraries_sop_merged.html",
    "title": "tima",
    "section": "",
    "text": "This function prepares the libraries made of all sub-libraries containing structure-organism pairs\n\n\n\nprepare_libraries_sop_merged(\n  files = get_params(step = \"prepare_libraries_sop_merged\")\\$files\\$libraries\\$sop\\$prepared,\n  filter = get_params(step = \"prepare_libraries_sop_merged\")\\$organisms\\$filter\\$mode,\n  level = get_params(step = \"prepare_libraries_sop_merged\")\\$organisms\\$filter\\$level,\n  value = get_params(step = \"prepare_libraries_sop_merged\")\\$organisms\\$filter\\$value,\n  cache = get_params(step =\n    \"prepare_libraries_sop_merged\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$processed,\n  output_key = get_params(step =\n    \"prepare_libraries_sop_merged\")\\$files\\$libraries\\$sop\\$merged\\$keys,\n  output_org_tax_ott = get_params(step =\n    \"prepare_libraries_sop_merged\")\\$files\\$libraries\\$sop\\$merged\\$organisms\\$taxonomies\\$ott,\n  output_str_stereo = get_params(step =\n    \"prepare_libraries_sop_merged\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$stereo,\n  output_str_met = get_params(step =\n    \"prepare_libraries_sop_merged\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$metadata,\n  output_str_nam = get_params(step =\n    \"prepare_libraries_sop_merged\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$names,\n  output_str_tax_cla = get_params(step =\n    \"prepare_libraries_sop_merged\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$taxonomies\\$cla,\n  output_str_tax_npc = get_params(step =\n    \"prepare_libraries_sop_merged\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$taxonomies\\$npc\n)\n\n\n\n\n\n\n\nfiles\n\n\nList of libraries to be merged\n\n\n\n\nfilter\n\n\nBoolean. TRUE or FALSE if you want to filter the library\n\n\n\n\nlevel\n\n\nBiological rank to be filtered. Kingdom, phylum, family, genus, …\n\n\n\n\nvalue\n\n\nName of the taxon or taxa to be kept, e.g. ‘Gentianaceae|Apocynaceae’\n\n\n\n\ncache\n\n\nCache where already processed SMILES are located\n\n\n\n\noutput_key\n\n\nOutput file for keys\n\n\n\n\noutput_org_tax_ott\n\n\nOutput file for organisms taxonomy (OTT)\n\n\n\n\noutput_str_stereo\n\n\nOutput file for structures stereo\n\n\n\n\noutput_str_met\n\n\nOutput file for structures metadata\n\n\n\n\noutput_str_nam\n\n\nOutput file for structures names\n\n\n\n\noutput_str_tax_cla\n\n\nOutput file for structures taxonomy (Classyfire)\n\n\n\n\noutput_str_tax_npc\n\n\nOutput file for structures taxonomy (NPC)\n\n\n\n\n\n\nIt can be restricted to specific taxa to have more biologically meaningful annotation.\n\n\n\nThe path to the prepared structure-organism pairs library MERGED\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\ngithub &lt;- \"https://raw.githubusercontent.com/\"\nrepo &lt;- \"taxonomicallyinformedannotation/tima-example-files/main/\"\ndir &lt;- paste0(github, repo)\nfiles &lt;- get_params(step = \"prepare_libraries_sop_merged\")$files$libraries$sop$prepared$lotus |&gt;\n  gsub(\n    pattern = \".gz\",\n    replacement = \"\",\n    fixed = TRUE\n  )\nget_file(url = paste0(dir, files), export = files)\nprepare_libraries_sop_merged(files = files)\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/prepare_libraries_sop_merged.html#prepare-merged-structure-organism-pairs-libraries",
    "href": "man/prepare_libraries_sop_merged.html#prepare-merged-structure-organism-pairs-libraries",
    "title": "tima",
    "section": "",
    "text": "This function prepares the libraries made of all sub-libraries containing structure-organism pairs\n\n\n\nprepare_libraries_sop_merged(\n  files = get_params(step = \"prepare_libraries_sop_merged\")\\$files\\$libraries\\$sop\\$prepared,\n  filter = get_params(step = \"prepare_libraries_sop_merged\")\\$organisms\\$filter\\$mode,\n  level = get_params(step = \"prepare_libraries_sop_merged\")\\$organisms\\$filter\\$level,\n  value = get_params(step = \"prepare_libraries_sop_merged\")\\$organisms\\$filter\\$value,\n  cache = get_params(step =\n    \"prepare_libraries_sop_merged\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$processed,\n  output_key = get_params(step =\n    \"prepare_libraries_sop_merged\")\\$files\\$libraries\\$sop\\$merged\\$keys,\n  output_org_tax_ott = get_params(step =\n    \"prepare_libraries_sop_merged\")\\$files\\$libraries\\$sop\\$merged\\$organisms\\$taxonomies\\$ott,\n  output_str_stereo = get_params(step =\n    \"prepare_libraries_sop_merged\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$stereo,\n  output_str_met = get_params(step =\n    \"prepare_libraries_sop_merged\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$metadata,\n  output_str_nam = get_params(step =\n    \"prepare_libraries_sop_merged\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$names,\n  output_str_tax_cla = get_params(step =\n    \"prepare_libraries_sop_merged\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$taxonomies\\$cla,\n  output_str_tax_npc = get_params(step =\n    \"prepare_libraries_sop_merged\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$taxonomies\\$npc\n)\n\n\n\n\n\n\n\nfiles\n\n\nList of libraries to be merged\n\n\n\n\nfilter\n\n\nBoolean. TRUE or FALSE if you want to filter the library\n\n\n\n\nlevel\n\n\nBiological rank to be filtered. Kingdom, phylum, family, genus, …\n\n\n\n\nvalue\n\n\nName of the taxon or taxa to be kept, e.g. ‘Gentianaceae|Apocynaceae’\n\n\n\n\ncache\n\n\nCache where already processed SMILES are located\n\n\n\n\noutput_key\n\n\nOutput file for keys\n\n\n\n\noutput_org_tax_ott\n\n\nOutput file for organisms taxonomy (OTT)\n\n\n\n\noutput_str_stereo\n\n\nOutput file for structures stereo\n\n\n\n\noutput_str_met\n\n\nOutput file for structures metadata\n\n\n\n\noutput_str_nam\n\n\nOutput file for structures names\n\n\n\n\noutput_str_tax_cla\n\n\nOutput file for structures taxonomy (Classyfire)\n\n\n\n\noutput_str_tax_npc\n\n\nOutput file for structures taxonomy (NPC)\n\n\n\n\n\n\nIt can be restricted to specific taxa to have more biologically meaningful annotation.\n\n\n\nThe path to the prepared structure-organism pairs library MERGED\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\ngithub &lt;- \"https://raw.githubusercontent.com/\"\nrepo &lt;- \"taxonomicallyinformedannotation/tima-example-files/main/\"\ndir &lt;- paste0(github, repo)\nfiles &lt;- get_params(step = \"prepare_libraries_sop_merged\")$files$libraries$sop$prepared$lotus |&gt;\n  gsub(\n    pattern = \".gz\",\n    replacement = \"\",\n    fixed = TRUE\n  )\nget_file(url = paste0(dir, files), export = files)\nprepare_libraries_sop_merged(files = files)\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/prepare_libraries_sop_hmdb.html",
    "href": "man/prepare_libraries_sop_hmdb.html",
    "title": "tima",
    "section": "",
    "text": "This function prepares the HMDB structure-organism pairs\n\n\n\nprepare_libraries_sop_hmdb(\n  input = get_params(step = \"prepare_libraries_sop_hmdb\")\\$files\\$libraries\\$sop\\$raw\\$hmdb,\n  output = get_params(step =\n    \"prepare_libraries_sop_hmdb\")\\$files\\$libraries\\$sop\\$prepared\\$hmdb\n)\n\n\n\n\n\n\n\ninput\n\n\nInput file\n\n\n\n\noutput\n\n\nOutput file\n\n\n\n\n\n\nThe path to the prepared structure-organism pairs library HMDB\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\nprepare_libraries_sop_hmdb()\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/prepare_libraries_sop_hmdb.html#prepare-libraries-of-structure-organism-pairs-hmdb",
    "href": "man/prepare_libraries_sop_hmdb.html#prepare-libraries-of-structure-organism-pairs-hmdb",
    "title": "tima",
    "section": "",
    "text": "This function prepares the HMDB structure-organism pairs\n\n\n\nprepare_libraries_sop_hmdb(\n  input = get_params(step = \"prepare_libraries_sop_hmdb\")\\$files\\$libraries\\$sop\\$raw\\$hmdb,\n  output = get_params(step =\n    \"prepare_libraries_sop_hmdb\")\\$files\\$libraries\\$sop\\$prepared\\$hmdb\n)\n\n\n\n\n\n\n\ninput\n\n\nInput file\n\n\n\n\noutput\n\n\nOutput file\n\n\n\n\n\n\nThe path to the prepared structure-organism pairs library HMDB\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\nprepare_libraries_sop_hmdb()\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/fake_annotations_columns.html",
    "href": "man/fake_annotations_columns.html",
    "title": "tima",
    "section": "",
    "text": "This function fakes annotations columns\n\n\n\nfake_annotations_columns()\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/fake_annotations_columns.html#fake-annotations-columns",
    "href": "man/fake_annotations_columns.html#fake-annotations-columns",
    "title": "tima",
    "section": "",
    "text": "This function fakes annotations columns\n\n\n\nfake_annotations_columns()\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/fake_lotus.html",
    "href": "man/fake_lotus.html",
    "title": "tima",
    "section": "",
    "text": "This function fakes LOTUS in case the download failed\n\n\n\nfake_lotus(export)\n\n\n\n\n\n\n\nexport\n\n\nPath to save the file to\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/fake_lotus.html#fake-lotus",
    "href": "man/fake_lotus.html#fake-lotus",
    "title": "tima",
    "section": "",
    "text": "This function fakes LOTUS in case the download failed\n\n\n\nfake_lotus(export)\n\n\n\n\n\n\n\nexport\n\n\nPath to save the file to\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/create_edges.html",
    "href": "man/create_edges.html",
    "title": "tima",
    "section": "",
    "text": "This function applies similarity calculation to a list of spectra to create edges\n\n\n\ncreate_edges(\n  frags,\n  nspecs,\n  precs,\n  method,\n  ms2_tolerance,\n  ppm_tolerance,\n  threshold,\n  matched_peaks\n)\n\n\n\n\n\n\n\nfrags\n\n\nFragments\n\n\n\n\nnspecs\n\n\nNumber of spectra\n\n\n\n\nprecs\n\n\nPrecursors\n\n\n\n\nmethod\n\n\nMethod\n\n\n\n\nms2_tolerance\n\n\nMS2 tolerance\n\n\n\n\nppm_tolerance\n\n\nppm tolerance\n\n\n\n\nthreshold\n\n\nThreshold\n\n\n\n\nmatched_peaks\n\n\nMatched peaks\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/create_edges.html#create-edges",
    "href": "man/create_edges.html#create-edges",
    "title": "tima",
    "section": "",
    "text": "This function applies similarity calculation to a list of spectra to create edges\n\n\n\ncreate_edges(\n  frags,\n  nspecs,\n  precs,\n  method,\n  ms2_tolerance,\n  ppm_tolerance,\n  threshold,\n  matched_peaks\n)\n\n\n\n\n\n\n\nfrags\n\n\nFragments\n\n\n\n\nnspecs\n\n\nNumber of spectra\n\n\n\n\nprecs\n\n\nPrecursors\n\n\n\n\nmethod\n\n\nMethod\n\n\n\n\nms2_tolerance\n\n\nMS2 tolerance\n\n\n\n\nppm_tolerance\n\n\nppm tolerance\n\n\n\n\nthreshold\n\n\nThreshold\n\n\n\n\nmatched_peaks\n\n\nMatched peaks\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/tima_full.html",
    "href": "man/tima_full.html",
    "title": "tima",
    "section": "",
    "text": "This function runs everything you need.\n\n\n\ntima_full()\n\n\n\n\nEverything you need.\n\n\n\n\nlibrary(\"tima\")\n\ntima_full()"
  },
  {
    "objectID": "man/tima_full.html#tima-full",
    "href": "man/tima_full.html#tima-full",
    "title": "tima",
    "section": "",
    "text": "This function runs everything you need.\n\n\n\ntima_full()\n\n\n\n\nEverything you need.\n\n\n\n\nlibrary(\"tima\")\n\ntima_full()"
  },
  {
    "objectID": "man/fake_hmdb.html",
    "href": "man/fake_hmdb.html",
    "title": "tima",
    "section": "",
    "text": "This function fakes HMDB in case the download failed\n\n\n\nfake_hmdb(export)\n\n\n\n\n\n\n\nexport\n\n\nPath to save the file to\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/fake_hmdb.html#fake-hmdb",
    "href": "man/fake_hmdb.html#fake-hmdb",
    "title": "tima",
    "section": "",
    "text": "This function fakes HMDB in case the download failed\n\n\n\nfake_hmdb(export)\n\n\n\n\n\n\n\nexport\n\n\nPath to save the file to\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/prepare_taxa.html",
    "href": "man/prepare_taxa.html",
    "title": "tima",
    "section": "",
    "text": "This function performs taxon name preparation to match the Open Tree of Life taxonomy\n\n\n\nprepare_taxa(\n  input = get_params(step = \"prepare_taxa\")\\$files\\$features\\$prepared,\n  extension = get_params(step = \"prepare_taxa\")\\$names\\$extension,\n  name_filename = get_params(step = \"prepare_taxa\")\\$names\\$filename,\n  colname = get_params(step = \"prepare_taxa\")\\$names\\$taxon,\n  metadata = get_params(step = \"prepare_taxa\")\\$files\\$metadata\\$raw,\n  org_tax_ott = get_params(step =\n    \"prepare_taxa\")\\$files\\$libraries\\$sop\\$merged\\$organisms\\$taxonomies\\$ott,\n  output = get_params(step = \"prepare_taxa\")\\$files\\$metadata\\$prepared,\n  taxon = get_params(step = \"prepare_taxa\")\\$organisms\\$taxon\n)\n\n\n\n\n\n\n\ninput\n\n\nFile containing your features intensities\n\n\n\n\nextension\n\n\nDoes your column names contain the file extension? (mzmine mainly)\n\n\n\n\nname_filename\n\n\nName of the file name column in the metadata file\n\n\n\n\ncolname\n\n\nName of the column containing biological source information\n\n\n\n\nmetadata\n\n\nFile containing your metadata including biological source\n\n\n\n\norg_tax_ott\n\n\nFile containing Open Tree of Life Taxonomy\n\n\n\n\noutput\n\n\nOutput file\n\n\n\n\ntaxon\n\n\nIf you want to enforce all features to a given taxon, put its name here.\n\n\n\n\n\n\nDepending if the features are aligned between samples originating from various organisms or not, It can either attribute all features to a single organism, or attribute them to multiple ones, according to their relative intensities among the samples.\n\n\n\nThe path to the prepared taxa\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\ngithub &lt;- \"https://raw.githubusercontent.com/\"\nrepo &lt;- \"taxonomicallyinformedannotation/tima-example-files/main/\"\ndir &lt;- paste0(github, repo)\norg_tax_ott &lt;- paste0(\n  \"data/interim/libraries/\",\n  \"sop/merged/organisms/taxonomies/ott.tsv\"\n)\nget_file(url = paste0(dir, org_tax_ott), export = org_tax_ott)\nget_file(\n  url = paste0(dir, \"data/interim/features/example_features.tsv\"),\n  export = get_params(step = \"prepare_taxa\")$files$features$prepared\n)\nprepare_taxa(\n  taxon = \"Homo sapiens\",\n  org_tax_ott = org_tax_ott\n)\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/prepare_taxa.html#prepare-taxa",
    "href": "man/prepare_taxa.html#prepare-taxa",
    "title": "tima",
    "section": "",
    "text": "This function performs taxon name preparation to match the Open Tree of Life taxonomy\n\n\n\nprepare_taxa(\n  input = get_params(step = \"prepare_taxa\")\\$files\\$features\\$prepared,\n  extension = get_params(step = \"prepare_taxa\")\\$names\\$extension,\n  name_filename = get_params(step = \"prepare_taxa\")\\$names\\$filename,\n  colname = get_params(step = \"prepare_taxa\")\\$names\\$taxon,\n  metadata = get_params(step = \"prepare_taxa\")\\$files\\$metadata\\$raw,\n  org_tax_ott = get_params(step =\n    \"prepare_taxa\")\\$files\\$libraries\\$sop\\$merged\\$organisms\\$taxonomies\\$ott,\n  output = get_params(step = \"prepare_taxa\")\\$files\\$metadata\\$prepared,\n  taxon = get_params(step = \"prepare_taxa\")\\$organisms\\$taxon\n)\n\n\n\n\n\n\n\ninput\n\n\nFile containing your features intensities\n\n\n\n\nextension\n\n\nDoes your column names contain the file extension? (mzmine mainly)\n\n\n\n\nname_filename\n\n\nName of the file name column in the metadata file\n\n\n\n\ncolname\n\n\nName of the column containing biological source information\n\n\n\n\nmetadata\n\n\nFile containing your metadata including biological source\n\n\n\n\norg_tax_ott\n\n\nFile containing Open Tree of Life Taxonomy\n\n\n\n\noutput\n\n\nOutput file\n\n\n\n\ntaxon\n\n\nIf you want to enforce all features to a given taxon, put its name here.\n\n\n\n\n\n\nDepending if the features are aligned between samples originating from various organisms or not, It can either attribute all features to a single organism, or attribute them to multiple ones, according to their relative intensities among the samples.\n\n\n\nThe path to the prepared taxa\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\ngithub &lt;- \"https://raw.githubusercontent.com/\"\nrepo &lt;- \"taxonomicallyinformedannotation/tima-example-files/main/\"\ndir &lt;- paste0(github, repo)\norg_tax_ott &lt;- paste0(\n  \"data/interim/libraries/\",\n  \"sop/merged/organisms/taxonomies/ott.tsv\"\n)\nget_file(url = paste0(dir, org_tax_ott), export = org_tax_ott)\nget_file(\n  url = paste0(dir, \"data/interim/features/example_features.tsv\"),\n  export = get_params(step = \"prepare_taxa\")$files$features$prepared\n)\nprepare_taxa(\n  taxon = \"Homo sapiens\",\n  org_tax_ott = org_tax_ott\n)\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/fake_sop_columns.html",
    "href": "man/fake_sop_columns.html",
    "title": "tima",
    "section": "",
    "text": "This function fakes sop columns\n\n\n\nfake_sop_columns()\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/fake_sop_columns.html#fake-sop-columns",
    "href": "man/fake_sop_columns.html#fake-sop-columns",
    "title": "tima",
    "section": "",
    "text": "This function fakes sop columns\n\n\n\nfake_sop_columns()\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/get_params.html",
    "href": "man/get_params.html",
    "title": "tima",
    "section": "",
    "text": "This function gets the parameters for the job. Combination of cli and yaml parameters\n\n\n\nget_params(step)\n\n\n\n\n\n\n\nstep\n\n\nName of the step being performed\n\n\n\n\n\n\nThe parameters\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\nget_params(\"prepare_params\")"
  },
  {
    "objectID": "man/get_params.html#get-parameters",
    "href": "man/get_params.html#get-parameters",
    "title": "tima",
    "section": "",
    "text": "This function gets the parameters for the job. Combination of cli and yaml parameters\n\n\n\nget_params(step)\n\n\n\n\n\n\n\nstep\n\n\nName of the step being performed\n\n\n\n\n\n\nThe parameters\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\nget_params(\"prepare_params\")"
  },
  {
    "objectID": "man/get_default_paths.html",
    "href": "man/get_default_paths.html",
    "title": "tima",
    "section": "",
    "text": "This function gets default paths\n\n\n\nget_default_paths(yaml = system.file(\"paths.yaml\", package = \"tima\"))\n\n\n\n\n\n\n\nyaml\n\n\nThe YAML file containing the paths (default is \"paths.yaml\")\n\n\n\n\n\n\nA list containing the paths specified in the YAML file\n\n\n\n\nlibrary(\"tima\")\n\nget_default_paths()"
  },
  {
    "objectID": "man/get_default_paths.html#get-default-paths",
    "href": "man/get_default_paths.html#get-default-paths",
    "title": "tima",
    "section": "",
    "text": "This function gets default paths\n\n\n\nget_default_paths(yaml = system.file(\"paths.yaml\", package = \"tima\"))\n\n\n\n\n\n\n\nyaml\n\n\nThe YAML file containing the paths (default is \"paths.yaml\")\n\n\n\n\n\n\nA list containing the paths specified in the YAML file\n\n\n\n\nlibrary(\"tima\")\n\nget_default_paths()"
  },
  {
    "objectID": "man/clean_bio.html",
    "href": "man/clean_bio.html",
    "title": "tima",
    "section": "",
    "text": "This function cleans the results obtained after biological weighting\n\n\n\nclean_bio(\n  annot_table_wei_bio = get(\"annot_table_wei_bio\", envir = parent.frame()),\n  edges_table = get(\"edges_table\", envir = parent.frame()),\n  minimal_consistency = get(\"minimal_consistency\", envir = parent.frame())\n)\n\n\n\n\n\n\n\nannot_table_wei_bio\n\n\nTable containing your biologically weighted annotation\n\n\n\n\nedges_table\n\n\nTable containing the edges between features\n\n\n\n\nminimal_consistency\n\n\nMinimal consistency score for a class. FLOAT\n\n\n\n\n\n\nA table containing the biologically weighted annotation where only a given number of initial candidates are kept\n\n\n\nweight_bio\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/clean_bio.html#clean-bio",
    "href": "man/clean_bio.html#clean-bio",
    "title": "tima",
    "section": "",
    "text": "This function cleans the results obtained after biological weighting\n\n\n\nclean_bio(\n  annot_table_wei_bio = get(\"annot_table_wei_bio\", envir = parent.frame()),\n  edges_table = get(\"edges_table\", envir = parent.frame()),\n  minimal_consistency = get(\"minimal_consistency\", envir = parent.frame())\n)\n\n\n\n\n\n\n\nannot_table_wei_bio\n\n\nTable containing your biologically weighted annotation\n\n\n\n\nedges_table\n\n\nTable containing the edges between features\n\n\n\n\nminimal_consistency\n\n\nMinimal consistency score for a class. FLOAT\n\n\n\n\n\n\nA table containing the biologically weighted annotation where only a given number of initial candidates are kept\n\n\n\nweight_bio\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/get_spectra_ids.html",
    "href": "man/get_spectra_ids.html",
    "title": "tima",
    "section": "",
    "text": "This function extracts spectra IDs as they are yet not consistently named\n\n\n\nget_spectra_ids(spectra)\n\n\n\n\n\n\n\nspectra\n\n\nSpectra.\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/get_spectra_ids.html#get-spectra-ids",
    "href": "man/get_spectra_ids.html#get-spectra-ids",
    "title": "tima",
    "section": "",
    "text": "This function extracts spectra IDs as they are yet not consistently named\n\n\n\nget_spectra_ids(spectra)\n\n\n\n\n\n\n\nspectra\n\n\nSpectra.\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/select_sirius_columns_canopus.html",
    "href": "man/select_sirius_columns_canopus.html",
    "title": "tima",
    "section": "",
    "text": "This function selects sirius columns (canopus)\n\n\n\nselect_sirius_columns_canopus(df, sirius_version)\n\n\n\n\n\n\n\ndf\n\n\nDataframe\n\n\n\n\nsirius_version\n\n\nSirius version\n\n\n\n\n\n\nThe dataframe with selected canopus columns\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/select_sirius_columns_canopus.html#select-sirius-columns-canopus",
    "href": "man/select_sirius_columns_canopus.html#select-sirius-columns-canopus",
    "title": "tima",
    "section": "",
    "text": "This function selects sirius columns (canopus)\n\n\n\nselect_sirius_columns_canopus(df, sirius_version)\n\n\n\n\n\n\n\ndf\n\n\nDataframe\n\n\n\n\nsirius_version\n\n\nSirius version\n\n\n\n\n\n\nThe dataframe with selected canopus columns\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/decorate_masses.html",
    "href": "man/decorate_masses.html",
    "title": "tima",
    "section": "",
    "text": "This function outputs information about MS1 annotation\n\n\n\ndecorate_masses(\n  annotation_table_ms1 = get(\"annotation_table_ms1\", envir = parent.frame())\n)\n\n\n\n\n\n\n\nannotation_table_ms1\n\n\nTable to decorate\n\n\n\n\n\n\nMessage indicating the number of annotations obtained by MS1\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/decorate_masses.html#decorate-masses",
    "href": "man/decorate_masses.html#decorate-masses",
    "title": "tima",
    "section": "",
    "text": "This function outputs information about MS1 annotation\n\n\n\ndecorate_masses(\n  annotation_table_ms1 = get(\"annotation_table_ms1\", envir = parent.frame())\n)\n\n\n\n\n\n\n\nannotation_table_ms1\n\n\nTable to decorate\n\n\n\n\n\n\nMessage indicating the number of annotations obtained by MS1\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/extract_spectra.html",
    "href": "man/extract_spectra.html",
    "title": "tima",
    "section": "",
    "text": "This function extracts spectra from a Spectraobject\n\n\n\nextract_spectra(object)\n\n\n\n\n\n\n\nobject\n\n\nObject of class Spectra\n\n\n\n\n\n\nData frame containing spectra data\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/extract_spectra.html#extract-spectra-from-a-spectra-object",
    "href": "man/extract_spectra.html#extract-spectra-from-a-spectra-object",
    "title": "tima",
    "section": "",
    "text": "This function extracts spectra from a Spectraobject\n\n\n\nextract_spectra(object)\n\n\n\n\n\n\n\nobject\n\n\nObject of class Spectra\n\n\n\n\n\n\nData frame containing spectra data\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/import_spectra.html",
    "href": "man/import_spectra.html",
    "title": "tima",
    "section": "",
    "text": "This function imports spectra from a file (.mgf or .sqlite)\n\n\n\nimport_spectra(\n  file,\n  cutoff = 0,\n  dalton = 0.01,\n  polarity = NA,\n  ppm = 10,\n  sanitize = TRUE,\n  combine = TRUE\n)\n\n\n\n\n\n\n\nfile\n\n\nFile path of the spectrum file to be imported\n\n\n\n\ncutoff\n\n\nAbsolute minimal intensity\n\n\n\n\ndalton\n\n\nDalton tolerance\n\n\n\n\npolarity\n\n\nPolarity\n\n\n\n\nppm\n\n\nPPM tolerance\n\n\n\n\nsanitize\n\n\nFlag indicating whether to sanitize. Default TRUE\n\n\n\n\ncombine\n\n\nFlag indicating whether to combine Default TRUE\n\n\n\n\n\n\nSpectra object containing the imported spectra\n\n\n\n\nlibrary(\"tima\")\n\nget_file(\n  url = get_default_paths()$urls$examples$spectra_mini,\n  export = get_default_paths()$data$source$spectra\n)\nimport_spectra(file = get_default_paths()$data$source$spectra)\nimport_spectra(\n  file = get_default_paths()$data$source$spectra,\n  sanitize = FALSE\n)"
  },
  {
    "objectID": "man/import_spectra.html#import-spectra",
    "href": "man/import_spectra.html#import-spectra",
    "title": "tima",
    "section": "",
    "text": "This function imports spectra from a file (.mgf or .sqlite)\n\n\n\nimport_spectra(\n  file,\n  cutoff = 0,\n  dalton = 0.01,\n  polarity = NA,\n  ppm = 10,\n  sanitize = TRUE,\n  combine = TRUE\n)\n\n\n\n\n\n\n\nfile\n\n\nFile path of the spectrum file to be imported\n\n\n\n\ncutoff\n\n\nAbsolute minimal intensity\n\n\n\n\ndalton\n\n\nDalton tolerance\n\n\n\n\npolarity\n\n\nPolarity\n\n\n\n\nppm\n\n\nPPM tolerance\n\n\n\n\nsanitize\n\n\nFlag indicating whether to sanitize. Default TRUE\n\n\n\n\ncombine\n\n\nFlag indicating whether to combine Default TRUE\n\n\n\n\n\n\nSpectra object containing the imported spectra\n\n\n\n\nlibrary(\"tima\")\n\nget_file(\n  url = get_default_paths()$urls$examples$spectra_mini,\n  export = get_default_paths()$data$source$spectra\n)\nimport_spectra(file = get_default_paths()$data$source$spectra)\nimport_spectra(\n  file = get_default_paths()$data$source$spectra,\n  sanitize = FALSE\n)"
  },
  {
    "objectID": "man/prepare_libraries_sop_lotus.html",
    "href": "man/prepare_libraries_sop_lotus.html",
    "title": "tima",
    "section": "",
    "text": "This function prepares the LOTUS structure-organism pairs\n\n\n\nprepare_libraries_sop_lotus(\n  input = get_params(step = \"prepare_libraries_sop_lotus\")\\$files\\$libraries\\$sop\\$raw\\$lotus,\n  output = get_params(step =\n    \"prepare_libraries_sop_lotus\")\\$files\\$libraries\\$sop\\$prepared\\$lotus\n)\n\n\n\n\n\n\n\ninput\n\n\nInput file\n\n\n\n\noutput\n\n\nOutput file\n\n\n\n\n\n\nThe path to the prepared structure-organism pairs library LOTUS\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\nprepare_libraries_sop_lotus()\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/prepare_libraries_sop_lotus.html#prepare-libraries-of-structure-organism-pairs-lotus",
    "href": "man/prepare_libraries_sop_lotus.html#prepare-libraries-of-structure-organism-pairs-lotus",
    "title": "tima",
    "section": "",
    "text": "This function prepares the LOTUS structure-organism pairs\n\n\n\nprepare_libraries_sop_lotus(\n  input = get_params(step = \"prepare_libraries_sop_lotus\")\\$files\\$libraries\\$sop\\$raw\\$lotus,\n  output = get_params(step =\n    \"prepare_libraries_sop_lotus\")\\$files\\$libraries\\$sop\\$prepared\\$lotus\n)\n\n\n\n\n\n\n\ninput\n\n\nInput file\n\n\n\n\noutput\n\n\nOutput file\n\n\n\n\n\n\nThe path to the prepared structure-organism pairs library LOTUS\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\nprepare_libraries_sop_lotus()\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/clean_collapse.html",
    "href": "man/clean_collapse.html",
    "title": "tima",
    "section": "",
    "text": "This function collapses a grouped dataframe and trims it\n\n\n\nclean_collapse(grouped_df, cols = NULL)\n\n\n\n\n\n\n\ngrouped_df\n\n\nGrouped dataframe\n\n\n\n\ncols\n\n\nColumn(s) to apply collapse to\n\n\n\n\n\n\nCleaned and collapsed dataframe\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/clean_collapse.html#clean-collapse",
    "href": "man/clean_collapse.html#clean-collapse",
    "title": "tima",
    "section": "",
    "text": "This function collapses a grouped dataframe and trims it\n\n\n\nclean_collapse(grouped_df, cols = NULL)\n\n\n\n\n\n\n\ngrouped_df\n\n\nGrouped dataframe\n\n\n\n\ncols\n\n\nColumn(s) to apply collapse to\n\n\n\n\n\n\nCleaned and collapsed dataframe\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "vignettes/articles/III-processing.html",
    "href": "vignettes/articles/III-processing.html",
    "title": "3 Performing Taxonomically Informed Metabolite Annotation",
    "section": "",
    "text": "This vignette describes how Taxonomically Informed Metabolite Annotation is performed. If you followed all previous steps successfully, this should be a piece of cake, you deserve it!\n\ntima::tima_full()\n#&gt; + par_def_ann_spe dispatched\n#&gt; ✔ par_def_ann_spe completed [28ms, 2.14 kB]\n#&gt; + par_def_wei_ann dispatched\n#&gt; ✔ par_def_wei_ann completed [1ms, 5.05 kB]\n#&gt; + par_def_pre_ann_gnp dispatched\n#&gt; ✔ par_def_pre_ann_gnp completed [0ms, 1.42 kB]\n#&gt; + par_def_pre_lib_sop_mer dispatched\n#&gt; ✔ par_def_pre_lib_sop_mer completed [1ms, 3.40 kB]\n#&gt; + yaml_paths dispatched\n#&gt; ✔ yaml_paths completed [1ms, 11.52 kB]\n#&gt; + par_def_pre_lib_sop_lot dispatched\n#&gt; ✔ par_def_pre_lib_sop_lot completed [1ms, 494 B]\n#&gt; + par_def_ann_mas dispatched\n#&gt; ✔ par_def_ann_mas completed [1ms, 6.09 kB]\n#&gt; + par_def_pre_lib_sop_hmd dispatched\n#&gt; ✔ par_def_pre_lib_sop_hmd completed [1ms, 492 B]\n#&gt; + par_def_fil_ann dispatched\n#&gt; ✔ par_def_fil_ann completed [1ms, 1.34 kB]\n#&gt; + par_def_pre_lib_sop_clo dispatched\n#&gt; ✔ par_def_pre_lib_sop_clo completed [0ms, 523 B]\n#&gt; + par_def_pre_lib_spe dispatched\n#&gt; ✔ par_def_pre_lib_spe completed [1ms, 1.57 kB]\n#&gt; + par_def_pre_fea_com dispatched\n#&gt; ✔ par_def_pre_fea_com completed [1ms, 358 B]\n#&gt; + par_def_cre_com dispatched\n#&gt; ✔ par_def_cre_com completed [1ms, 375 B]\n#&gt; + par_def_cre_edg_spe dispatched\n#&gt; ✔ par_def_cre_edg_spe completed [1ms, 1.42 kB]\n#&gt; + par_def_pre_fea_edg dispatched\n#&gt; ✔ par_def_pre_fea_edg completed [1ms, 706 B]\n#&gt; + par_def_pre_fea_tab dispatched\n#&gt; ✔ par_def_pre_fea_tab completed [0ms, 860 B]\n#&gt; + par_def_pre_lib_rt dispatched\n#&gt; ✔ par_def_pre_lib_rt completed [1ms, 2.05 kB]\n#&gt; + par_def_pre_ann_spe dispatched\n#&gt; ✔ par_def_pre_ann_spe completed [1ms, 1.46 kB]\n#&gt; + par_def_pre_ann_sir dispatched\n#&gt; ✔ par_def_pre_ann_sir completed [0ms, 1.93 kB]\n#&gt; + par_def_pre_tax dispatched\n#&gt; ✔ par_def_pre_tax completed [0ms, 1.51 kB]\n#&gt; + par_def_pre_lib_sop_ecm dispatched\n#&gt; ✔ par_def_pre_lib_sop_ecm completed [0ms, 492 B]\n#&gt; + paths dispatched\n#&gt; ✔ paths completed [2ms, 2.52 kB]\n#&gt; + lib_spe_exp_gnp_pre_sop dispatched\n#&gt; INFO [2025-07-10 07:42:28] Directory data/interim/libraries/sop created.\n#&gt; ✔ lib_spe_exp_gnp_pre_sop completed [383ms, 1.42 MB]\n#&gt; + lib_spe_exp_mb_pre_sop dispatched\n#&gt; ✔ lib_spe_exp_mb_pre_sop completed [174ms, 480.97 kB]\n#&gt; + lib_spe_exp_mer_pre_sop dispatched\n#&gt; ✔ lib_spe_exp_mer_pre_sop completed [250ms, 1.19 MB]\n#&gt; + lib_spe_is_wik_pre_sop dispatched\n#&gt; ✔ lib_spe_is_wik_pre_sop completed [185ms, 37.90 MB]\n#&gt; + lib_spe_exp_mb_pre_pos dispatched\n#&gt; INFO [2025-07-10 07:42:30] Directory data/interim/libraries/spectra/exp created.\n#&gt; ✔ lib_spe_exp_mb_pre_pos completed [782ms, 19.41 MB]\n#&gt; + par_pre_par dispatched\n#&gt; ✔ par_pre_par completed [0ms, 1.38 kB]\n#&gt; + lib_spe_exp_mer_pre_neg dispatched\n#&gt; ✔ lib_spe_exp_mer_pre_neg completed [831ms, 31.54 MB]\n#&gt; + lib_spe_is_wik_pre_neg dispatched\n#&gt; INFO [2025-07-10 07:42:32] Directory data/interim/libraries/spectra/is created.\n#&gt; ✔ lib_spe_is_wik_pre_neg completed [9.6s, 687.33 MB]\n#&gt; + par_pre_par2 dispatched\n#&gt; ✔ par_pre_par2 completed [0ms, 21.17 kB]\n#&gt; + lib_spe_is_wik_pre_pos dispatched\n#&gt; Downloading  44% ■■■■■■■■■■■■■■                    1s\n#&gt; Downloading 100% ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■   0s\n#&gt; ✔ lib_spe_is_wik_pre_pos completed [11.4s, 863.95 MB]\n#&gt; + lib_sop_lot dispatched\n#&gt; INFO [2025-07-10 07:42:55] Downloading 230106_frozen_metadata.csv.gz from https://doi.org/10.5281/zenodo.5794106 (The LOTUS Initiative for Open Natural Products Research: frozen dataset union wikidata (with metadata); unique identifier: https://doi.org/10.5281/zenodo.7534071)\n#&gt; INFO [2025-07-10 07:42:55] Directory data/source/libraries/sop created.\n#&gt; ✔ lib_sop_lot completed [33.8s, 92.98 MB]\n#&gt; + lib_sop_hmd dispatched\n#&gt; INFO [2025-07-10 07:43:28] Directory data/source/libraries/sop/hmdb created.\n#&gt; Downloading  41% ■■■■■■■■■■■■■                     1s\n#&gt; Downloading  99% ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■   0s\n#&gt; Downloading 100% ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■   0s\n#&gt; ✔ lib_sop_hmd completed [3.1s, 96.48 MB]\n#&gt; + lib_spe_exp_gnp_pre_neg dispatched\n#&gt; ✔ lib_spe_exp_gnp_pre_neg completed [2.6s, 154.12 MB]\n#&gt; + lib_spe_exp_mer_pre_pos dispatched\n#&gt; ✔ lib_spe_exp_mer_pre_pos completed [1.6s, 84.94 MB]\n#&gt; + lib_sop_ecm dispatched\n#&gt; ✔ lib_sop_ecm completed [824ms, 1.33 MB]\n#&gt; + lib_spe_exp_mb_pre_neg dispatched\n#&gt; ✔ lib_spe_exp_mb_pre_neg completed [564ms, 7.06 MB]\n#&gt; + lib_spe_exp_gnp_pre_pos dispatched\n#&gt; ✔ lib_spe_exp_gnp_pre_pos completed [7s, 481.27 MB]\n#&gt; + par_fin_par dispatched\n#&gt; ✔ par_fin_par completed [1ms, 307 B]\n#&gt; + par_fin_par2 dispatched\n#&gt; ✔ par_fin_par2 completed [3ms, 2.96 kB]\n#&gt; + par_usr_pre_lib_sop_mer dispatched\n#&gt; TRACE [2025-07-10 07:43:45] Loading default params\n#&gt; TRACE [2025-07-10 07:43:45] All params\n#&gt; TRACE [2025-07-10 07:43:45] Small params\n#&gt; TRACE [2025-07-10 07:43:45] Advanced params\n#&gt; TRACE [2025-07-10 07:43:45] Changing params\n#&gt; TRACE [2025-07-10 07:43:45] Changing filenames\n#&gt; TRACE [2025-07-10 07:43:46] Exporting params\n#&gt; INFO [2025-07-10 07:43:46] Directory params/user created.\n#&gt; ✔ par_usr_pre_lib_sop_mer completed [1.4s, 1.55 kB]\n#&gt; + par_usr_pre_lib_sop_lot dispatched\n#&gt; TRACE [2025-07-10 07:43:46] Loading default params\n#&gt; TRACE [2025-07-10 07:43:46] All params\n#&gt; TRACE [2025-07-10 07:43:46] Small params\n#&gt; TRACE [2025-07-10 07:43:46] Advanced params\n#&gt; TRACE [2025-07-10 07:43:46] Changing params\n#&gt; TRACE [2025-07-10 07:43:46] Changing filenames\n#&gt; TRACE [2025-07-10 07:43:48] Exporting params\n#&gt; ✔ par_usr_pre_lib_sop_lot completed [1.3s, 174 B]\n#&gt; + par_usr_pre_tax dispatched\n#&gt; TRACE [2025-07-10 07:43:48] Loading default params\n#&gt; TRACE [2025-07-10 07:43:48] All params\n#&gt; TRACE [2025-07-10 07:43:48] Small params\n#&gt; TRACE [2025-07-10 07:43:48] Advanced params\n#&gt; TRACE [2025-07-10 07:43:48] Changing params\n#&gt; TRACE [2025-07-10 07:43:48] Changing filenames\n#&gt; TRACE [2025-07-10 07:43:49] Exporting params\n#&gt; ✔ par_usr_pre_tax completed [1.3s, 438 B]\n#&gt; + par_usr_pre_ann_gnp dispatched\n#&gt; TRACE [2025-07-10 07:43:49] Loading default params\n#&gt; TRACE [2025-07-10 07:43:49] All params\n#&gt; TRACE [2025-07-10 07:43:49] Small params\n#&gt; TRACE [2025-07-10 07:43:49] Advanced params\n#&gt; TRACE [2025-07-10 07:43:49] Changing params\n#&gt; TRACE [2025-07-10 07:43:49] Changing filenames\n#&gt; TRACE [2025-07-10 07:43:51] Exporting params\n#&gt; ✔ par_usr_pre_ann_gnp completed [1.3s, 708 B]\n#&gt; + par_usr_pre_lib_sop_hmd dispatched\n#&gt; TRACE [2025-07-10 07:43:51] Loading default params\n#&gt; TRACE [2025-07-10 07:43:51] All params\n#&gt; TRACE [2025-07-10 07:43:51] Small params\n#&gt; TRACE [2025-07-10 07:43:51] Advanced params\n#&gt; TRACE [2025-07-10 07:43:51] Changing params\n#&gt; TRACE [2025-07-10 07:43:51] Changing filenames\n#&gt; TRACE [2025-07-10 07:43:52] Exporting params\n#&gt; ✔ par_usr_pre_lib_sop_hmd completed [1.3s, 178 B]\n#&gt; + par_usr_cre_com dispatched\n#&gt; TRACE [2025-07-10 07:43:52] Loading default params\n#&gt; TRACE [2025-07-10 07:43:52] All params\n#&gt; TRACE [2025-07-10 07:43:52] Small params\n#&gt; TRACE [2025-07-10 07:43:52] Advanced params\n#&gt; TRACE [2025-07-10 07:43:52] Changing params\n#&gt; TRACE [2025-07-10 07:43:52] Changing filenames\n#&gt; TRACE [2025-07-10 07:43:54] Exporting params\n#&gt; ✔ par_usr_cre_com completed [1.3s, 200 B]\n#&gt; + par_usr_pre_lib_sop_clo dispatched\n#&gt; TRACE [2025-07-10 07:43:54] Loading default params\n#&gt; TRACE [2025-07-10 07:43:54] All params\n#&gt; TRACE [2025-07-10 07:43:54] Small params\n#&gt; TRACE [2025-07-10 07:43:54] Advanced params\n#&gt; TRACE [2025-07-10 07:43:54] Changing params\n#&gt; TRACE [2025-07-10 07:43:54] Changing filenames\n#&gt; TRACE [2025-07-10 07:43:55] Exporting params\n#&gt; ✔ par_usr_pre_lib_sop_clo completed [1.3s, 205 B]\n#&gt; + par_usr_cre_edg_spe dispatched\n#&gt; TRACE [2025-07-10 07:43:55] Loading default params\n#&gt; TRACE [2025-07-10 07:43:55] All params\n#&gt; TRACE [2025-07-10 07:43:55] Small params\n#&gt; TRACE [2025-07-10 07:43:55] Advanced params\n#&gt; TRACE [2025-07-10 07:43:55] Changing params\n#&gt; TRACE [2025-07-10 07:43:55] Changing filenames\n#&gt; TRACE [2025-07-10 07:43:57] Exporting params\n#&gt; ✔ par_usr_cre_edg_spe completed [1.3s, 452 B]\n#&gt; + par_usr_pre_fea_com dispatched\n#&gt; TRACE [2025-07-10 07:43:57] Loading default params\n#&gt; TRACE [2025-07-10 07:43:57] All params\n#&gt; TRACE [2025-07-10 07:43:57] Small params\n#&gt; TRACE [2025-07-10 07:43:57] Advanced params\n#&gt; TRACE [2025-07-10 07:43:57] Changing params\n#&gt; TRACE [2025-07-10 07:43:57] Changing filenames\n#&gt; TRACE [2025-07-10 07:43:58] Exporting params\n#&gt; ✔ par_usr_pre_fea_com completed [1.5s, 200 B]\n#&gt; + par_usr_pre_fea_edg dispatched\n#&gt; TRACE [2025-07-10 07:43:58] Loading default params\n#&gt; TRACE [2025-07-10 07:43:58] All params\n#&gt; TRACE [2025-07-10 07:43:58] Small params\n#&gt; TRACE [2025-07-10 07:43:58] Advanced params\n#&gt; TRACE [2025-07-10 07:43:58] Changing params\n#&gt; TRACE [2025-07-10 07:43:58] Changing filenames\n#&gt; TRACE [2025-07-10 07:44:00] Exporting params\n#&gt; ✔ par_usr_pre_fea_edg completed [1.3s, 328 B]\n#&gt; + par_usr_pre_lib_sop_ecm dispatched\n#&gt; TRACE [2025-07-10 07:44:00] Loading default params\n#&gt; TRACE [2025-07-10 07:44:00] All params\n#&gt; TRACE [2025-07-10 07:44:00] Small params\n#&gt; TRACE [2025-07-10 07:44:00] Advanced params\n#&gt; TRACE [2025-07-10 07:44:00] Changing params\n#&gt; TRACE [2025-07-10 07:44:00] Changing filenames\n#&gt; TRACE [2025-07-10 07:44:01] Exporting params\n#&gt; ✔ par_usr_pre_lib_sop_ecm completed [1.3s, 176 B]\n#&gt; + par_usr_fil_ann dispatched\n#&gt; TRACE [2025-07-10 07:44:01] Loading default params\n#&gt; TRACE [2025-07-10 07:44:01] All params\n#&gt; TRACE [2025-07-10 07:44:01] Small params\n#&gt; TRACE [2025-07-10 07:44:01] Advanced params\n#&gt; TRACE [2025-07-10 07:44:01] Changing params\n#&gt; TRACE [2025-07-10 07:44:01] Changing filenames\n#&gt; TRACE [2025-07-10 07:44:03] Exporting params\n#&gt; ✔ par_usr_fil_ann completed [1.3s, 668 B]\n#&gt; + par_usr_pre_fea_tab dispatched\n#&gt; TRACE [2025-07-10 07:44:03] Loading default params\n#&gt; TRACE [2025-07-10 07:44:03] All params\n#&gt; TRACE [2025-07-10 07:44:03] Small params\n#&gt; TRACE [2025-07-10 07:44:03] Advanced params\n#&gt; TRACE [2025-07-10 07:44:03] Changing params\n#&gt; TRACE [2025-07-10 07:44:03] Changing filenames\n#&gt; TRACE [2025-07-10 07:44:04] Exporting params\n#&gt; ✔ par_usr_pre_fea_tab completed [1.3s, 274 B]\n#&gt; + par_usr_pre_lib_rt dispatched\n#&gt; TRACE [2025-07-10 07:44:04] Loading default params\n#&gt; TRACE [2025-07-10 07:44:04] All params\n#&gt; TRACE [2025-07-10 07:44:04] Small params\n#&gt; TRACE [2025-07-10 07:44:04] Advanced params\n#&gt; TRACE [2025-07-10 07:44:04] Changing params\n#&gt; TRACE [2025-07-10 07:44:04] Changing filenames\n#&gt; TRACE [2025-07-10 07:44:06] Exporting params\n#&gt; ✔ par_usr_pre_lib_rt completed [1.3s, 440 B]\n#&gt; + par_usr_ann_spe dispatched\n#&gt; TRACE [2025-07-10 07:44:06] Loading default params\n#&gt; TRACE [2025-07-10 07:44:06] All params\n#&gt; TRACE [2025-07-10 07:44:06] Small params\n#&gt; TRACE [2025-07-10 07:44:06] Advanced params\n#&gt; TRACE [2025-07-10 07:44:06] Changing params\n#&gt; TRACE [2025-07-10 07:44:06] Changing filenames\n#&gt; TRACE [2025-07-10 07:44:07] Exporting params\n#&gt; ✔ par_usr_ann_spe completed [1.3s, 1.03 kB]\n#&gt; + par_usr_pre_ann_spe dispatched\n#&gt; TRACE [2025-07-10 07:44:07] Loading default params\n#&gt; TRACE [2025-07-10 07:44:07] All params\n#&gt; TRACE [2025-07-10 07:44:07] Small params\n#&gt; TRACE [2025-07-10 07:44:07] Advanced params\n#&gt; TRACE [2025-07-10 07:44:07] Changing params\n#&gt; TRACE [2025-07-10 07:44:07] Changing filenames\n#&gt; TRACE [2025-07-10 07:44:09] Exporting params\n#&gt; ✔ par_usr_pre_ann_spe completed [1.3s, 731 B]\n#&gt; + par_usr_pre_lib_spe dispatched\n#&gt; TRACE [2025-07-10 07:44:09] Loading default params\n#&gt; TRACE [2025-07-10 07:44:09] All params\n#&gt; TRACE [2025-07-10 07:44:09] Small params\n#&gt; TRACE [2025-07-10 07:44:09] Advanced params\n#&gt; TRACE [2025-07-10 07:44:09] Changing params\n#&gt; TRACE [2025-07-10 07:44:09] Changing filenames\n#&gt; TRACE [2025-07-10 07:44:10] Exporting params\n#&gt; ✔ par_usr_pre_lib_spe completed [1.3s, 298 B]\n#&gt; + par_usr_pre_ann_sir dispatched\n#&gt; TRACE [2025-07-10 07:44:10] Loading default params\n#&gt; TRACE [2025-07-10 07:44:10] All params\n#&gt; TRACE [2025-07-10 07:44:10] Small params\n#&gt; TRACE [2025-07-10 07:44:10] Advanced params\n#&gt; TRACE [2025-07-10 07:44:10] Changing params\n#&gt; TRACE [2025-07-10 07:44:10] Changing filenames\n#&gt; TRACE [2025-07-10 07:44:12] Exporting params\n#&gt; ✔ par_usr_pre_ann_sir completed [1.3s, 900 B]\n#&gt; + par_usr_ann_mas dispatched\n#&gt; TRACE [2025-07-10 07:44:12] Loading default params\n#&gt; TRACE [2025-07-10 07:44:12] All params\n#&gt; TRACE [2025-07-10 07:44:12] Small params\n#&gt; TRACE [2025-07-10 07:44:12] Advanced params\n#&gt; TRACE [2025-07-10 07:44:12] Changing params\n#&gt; TRACE [2025-07-10 07:44:12] Changing filenames\n#&gt; TRACE [2025-07-10 07:44:13] Exporting params\n#&gt; ✔ par_usr_ann_mas completed [1.3s, 2.68 kB]\n#&gt; + par_usr_wei_ann dispatched\n#&gt; TRACE [2025-07-10 07:44:13] Loading default params\n#&gt; TRACE [2025-07-10 07:44:13] All params\n#&gt; TRACE [2025-07-10 07:44:13] Small params\n#&gt; TRACE [2025-07-10 07:44:13] Advanced params\n#&gt; TRACE [2025-07-10 07:44:13] Changing params\n#&gt; TRACE [2025-07-10 07:44:13] Changing filenames\n#&gt; TRACE [2025-07-10 07:44:15] Exporting params\n#&gt; ✔ par_usr_wei_ann completed [1.3s, 1.76 kB]\n#&gt; + par_pre_lib_sop_mer dispatched\n#&gt; ✔ par_pre_lib_sop_mer completed [1ms, 558 B]\n#&gt; + par_pre_lib_sop_lot dispatched\n#&gt; ✔ par_pre_lib_sop_lot completed [1ms, 186 B]\n#&gt; + par_pre_tax dispatched\n#&gt; ✔ par_pre_tax completed [1ms, 327 B]\n#&gt; + par_pre_ann_gnp dispatched\n#&gt; ✔ par_pre_ann_gnp completed [0ms, 336 B]\n#&gt; + par_pre_lib_sop_hmd dispatched\n#&gt; ✔ par_pre_lib_sop_hmd completed [1ms, 191 B]\n#&gt; + par_cre_com dispatched\n#&gt; ✔ par_cre_com completed [0ms, 191 B]\n#&gt; + par_pre_lib_sop_clo dispatched\n#&gt; ✔ par_pre_lib_sop_clo completed [0ms, 213 B]\n#&gt; + par_cre_edg_spe dispatched\n#&gt; ✔ par_cre_edg_spe completed [0ms, 389 B]\n#&gt; + par_pre_fea_com dispatched\n#&gt; ✔ par_pre_fea_com completed [0ms, 184 B]\n#&gt; + par_pre_fea_edg dispatched\n#&gt; ✔ par_pre_fea_edg completed [0ms, 244 B]\n#&gt; + par_pre_lib_sop_ecm dispatched\n#&gt; ✔ par_pre_lib_sop_ecm completed [0ms, 191 B]\n#&gt; + par_fil_ann dispatched\n#&gt; ✔ par_fil_ann completed [1ms, 347 B]\n#&gt; + par_pre_fea_tab dispatched\n#&gt; ✔ par_pre_fea_tab completed [1ms, 278 B]\n#&gt; + par_pre_lib_rt dispatched\n#&gt; ✔ par_pre_lib_rt completed [0ms, 329 B]\n#&gt; + par_ann_spe dispatched\n#&gt; ✔ par_ann_spe completed [1ms, 497 B]\n#&gt; + par_pre_ann_spe dispatched\n#&gt; ✔ par_pre_ann_spe completed [1ms, 334 B]\n#&gt; + par_pre_lib_spe dispatched\n#&gt; ✔ par_pre_lib_spe completed [1ms, 305 B]\n#&gt; + par_pre_ann_sir dispatched\n#&gt; ✔ par_pre_ann_sir completed [0ms, 405 B]\n#&gt; + par_ann_mas dispatched\n#&gt; ✔ par_ann_mas completed [1ms, 1.13 kB]\n#&gt; + par_wei_ann dispatched\n#&gt; ✔ par_wei_ann completed [1ms, 932 B]\n#&gt; + lib_sop_mer_str_pro dispatched\n#&gt; INFO [2025-07-10 07:44:18] Directory data/interim/libraries/sop/merged/structures created.\n#&gt; ✔ lib_sop_mer_str_pro completed [395ms, 90.51 MB]\n#&gt; + lib_sop_lot_pre dispatched\n#&gt; TRACE [2025-07-10 07:44:19] Loading and preparing LOTUS\n#&gt; INFO [2025-07-10 07:44:29] ... path to export is data/interim/libraries/sop/lotus_prepared.tsv.gz\n#&gt; ✔ lib_sop_lot_pre completed [13.8s, 46.52 MB]\n#&gt; + lib_sop_hmd_pre dispatched\n#&gt; TRACE [2025-07-10 07:44:33] Unzipping HMDB\n#&gt; TRACE [2025-07-10 07:44:36] Loading HMDB\n#&gt; TRACE [2025-07-10 07:45:16] Formatting HMDB\n#&gt; TRACE [2025-07-10 07:45:16] Deleting unzipped file\n#&gt; INFO [2025-07-10 07:45:17] ... path to export is data/interim/libraries/sop/hmdb_prepared.tsv.gz\n#&gt; ✔ lib_sop_hmd_pre completed [44.3s, 8.06 MB]\n#&gt; + lib_sop_clo_pre dispatched\n#&gt; WARN [2025-07-10 07:45:18] Sorry, you do not have access to the closed resource,\n#&gt; returning an empty file instead\n#&gt; INFO [2025-07-10 07:45:18] Directory data/interim/params created.\n#&gt; INFO [2025-07-10 07:45:18] ... path to used parameters is data/interim/params\n#&gt; INFO [2025-07-10 07:45:18] ... path to export is data/interim/libraries/sop/closed_prepared.tsv.gz\n#&gt; ✔ lib_sop_clo_pre completed [21ms, 273 B]\n#&gt; + lib_sop_ecm_pre dispatched\n#&gt; TRACE [2025-07-10 07:45:18] Loading ECMDB resources\n#&gt; TRACE [2025-07-10 07:45:19] Formatting ECMDB\n#&gt; INFO [2025-07-10 07:45:19] ... path to used parameters is data/interim/params\n#&gt; INFO [2025-07-10 07:45:19] ... path to export is data/interim/libraries/sop/ecmdb_prepared.tsv.gz\n#&gt; ✔ lib_sop_ecm_pre completed [639ms, 177.47 kB]\n#&gt; + par_pre_fea_tab_fil_fea_raw dispatched\n#&gt; ✔ par_pre_fea_tab_fil_fea_raw completed [0ms, 451.55 kB]\n#&gt; + lib_rt dispatched\n#&gt; WARN [2025-07-10 07:45:19] No retention time library found, returning empty sop table.\n#&gt; WARN [2025-07-10 07:45:19] No retention time library found, returning empty retention time table.\n#&gt; INFO [2025-07-10 07:45:19] ... path to used parameters is data/interim/params\n#&gt; INFO [2025-07-10 07:45:19] Directory data/interim/libraries/rt created.\n#&gt; INFO [2025-07-10 07:45:19] ... path to export is data/interim/libraries/rt/prepared.tsv.gz\n#&gt; INFO [2025-07-10 07:45:19] ... path to export is data/interim/libraries/sop/rt_prepared.tsv.gz\n#&gt; ✔ lib_rt completed [52ms, 182 B]\n#&gt; + par_ann_spe_fil_spe_raw dispatched\n#&gt; ✔ par_ann_spe_fil_spe_raw completed [0ms, 44.68 kB]\n#&gt; + lib_spe_exp_int_pre dispatched\n#&gt; TRACE [2025-07-10 07:45:19] Importing\n#&gt; TRACE [2025-07-10 07:45:21] Harmonizing names\n#&gt; TRACE [2025-07-10 07:45:21] Filtering MS2 only\n#&gt; TRACE [2025-07-10 07:45:21] Applying sanitization of the spectra\n#&gt; TRACE [2025-07-10 07:45:21] Filtering empty spectra\n#&gt; INFO [2025-07-10 07:45:21] Considering 402 spectra\n#&gt; TRACE [2025-07-10 07:45:21] Extracting\n#&gt; TRACE [2025-07-10 07:45:21] Harmonizing\n#&gt; TRACE [2025-07-10 07:45:21] ... pos\n#&gt; TRACE [2025-07-10 07:45:21] ... neg\n#&gt; TRACE [2025-07-10 07:45:21] Extracting structures for the SOP library.\n#&gt; INFO [2025-07-10 07:45:21] ... path to export is data/interim/libraries/sop/internal_prepared.tsv.gz\n#&gt; INFO [2025-07-10 07:45:21] ... path to used parameters is data/interim/params\n#&gt; ✔ lib_spe_exp_int_pre completed [1.8s, 155 B]\n#&gt; + input_features dispatched\n#&gt; ✔ input_features completed [0ms, 451.55 kB]\n#&gt; + lib_rt_sop dispatched\n#&gt; ✔ lib_rt_sop completed [0ms, 96 B]\n#&gt; + lib_rt_rts dispatched\n#&gt; ✔ lib_rt_rts completed [0ms, 86 B]\n#&gt; + input_spectra dispatched\n#&gt; INFO [2025-07-10 07:45:23] File already exists. Skipping.\n#&gt; ✔ input_spectra completed [1ms, 44.68 kB]\n#&gt; + lib_spe_exp_int_pre_sop dispatched\n#&gt; ✔ lib_spe_exp_int_pre_sop completed [0ms, 108 B]\n#&gt; + lib_spe_exp_int_pre_pos dispatched\n#&gt; ✔ lib_spe_exp_int_pre_pos completed [0ms, 139.71 kB]\n#&gt; + lib_spe_exp_int_pre_neg dispatched\n#&gt; ✔ lib_spe_exp_int_pre_neg completed [0ms, 50.68 kB]\n#&gt; + fea_pre dispatched\n#&gt; TRACE [2025-07-10 07:45:24] Preparing features table\n#&gt; TRACE [2025-07-10 07:45:24] Formatting feature table\n#&gt; TRACE [2025-07-10 07:45:24] ... requires 'Peak area' or ':area' in columns (mzmine format)\n#&gt; TRACE [2025-07-10 07:45:24] ... or 'quant_' in columns (SLAW format)\n#&gt; TRACE [2025-07-10 07:45:24] ... or 'Peak height' in columns (SIRIUS format)\n#&gt; TRACE [2025-07-10 07:45:24] Filtering top intensities per feature\n#&gt; INFO [2025-07-10 07:45:24] ... path to used parameters is data/interim/params\n#&gt; INFO [2025-07-10 07:45:24] Directory data/interim/features created.\n#&gt; INFO [2025-07-10 07:45:24] ... path to export is data/interim/features/example_features.tsv.gz\n#&gt; ✔ fea_pre completed [149ms, 95.63 kB]\n#&gt; + fea_edg_spe dispatched\n#&gt; TRACE [2025-07-10 07:45:24] Harmonizing names\n#&gt; TRACE [2025-07-10 07:45:24] Filtering MS2 only\n#&gt; TRACE [2025-07-10 07:45:24] Combining spectra in case\n#&gt; TRACE [2025-07-10 07:45:26] Applying sanitization of the spectra\n#&gt; TRACE [2025-07-10 07:45:26] Filtering empty spectra\n#&gt; INFO [2025-07-10 07:45:26] Considering 22 spectra\n#&gt; TRACE [2025-07-10 07:45:26] Performing spectral comparison\n#&gt; TRACE [2025-07-10 07:45:26] As we do not limit the precursors delta,\n#&gt; expect a (relatively) long processing time.\n#&gt; INFO [2025-07-10 07:45:26] =====================================================\n#&gt; INFO [2025-07-10 07:45:26] = Take yourself a break, you deserve it.            =\n#&gt; INFO [2025-07-10 07:45:26] =====================================================\n#&gt; TRACE [2025-07-10 07:45:26] Calculating features' entropy\n#&gt; TRACE [2025-07-10 07:45:26] Counting features' number of peaks\n#&gt; INFO [2025-07-10 07:45:26] ... path to used parameters is data/interim/params\n#&gt; INFO [2025-07-10 07:45:26] ... path to export is data/interim/features/example_edgesSpectra.tsv\n#&gt; ✔ fea_edg_spe completed [1.4s, 852 B]\n#&gt; + lib_sop_mer dispatched\n#&gt; TRACE [2025-07-10 07:45:26] Loading and concatenating prepared libraries\n#&gt; TRACE [2025-07-10 07:45:37] Splitting the concatenated library into smaller standardized pieces\n#&gt; TRACE [2025-07-10 07:45:45] Sanitizing structures\n#&gt; TRACE [2025-07-10 07:45:45] Processing SMILES\n#&gt; INFO [2025-07-10 07:45:54] Passing 61 SMILES to RDKit\n#&gt; [07:45:54] Explicit valence for atom # 1 N, 3, is greater than permitted\n#&gt; [07:45:54] ERROR: Could not sanitize molecule on line 1\n#&gt; [07:45:54] ERROR: Explicit valence for atom # 1 N, 3, is greater than permitted\n#&gt; [07:45:54] Explicit valence for atom # 0 P, 11, is greater than permitted\n#&gt; [07:45:54] ERROR: Could not sanitize molecule on line 2\n#&gt; [07:45:54] ERROR: Explicit valence for atom # 0 P, 11, is greater than permitted\n#&gt; [07:45:54] Explicit valence for atom # 21 N, 4, is greater than permitted\n#&gt; [07:45:54] ERROR: Could not sanitize molecule on line 3\n#&gt; [07:45:54] ERROR: Explicit valence for atom # 21 N, 4, is greater than permitted\n#&gt; [07:45:54] Explicit valence for atom # 1 Cl, 4, is greater than permitted\n#&gt; [07:45:54] ERROR: Could not sanitize molecule on line 4\n#&gt; [07:45:54] ERROR: Explicit valence for atom # 1 Cl, 4, is greater than permitted\n#&gt; [07:45:54] Explicit valence for atom # 6 C, 5, is greater than permitted\n#&gt; [07:45:54] ERROR: Could not sanitize molecule on line 5\n#&gt; [07:45:54] ERROR: Explicit valence for atom # 6 C, 5, is greater than permitted\n#&gt; [07:45:54] Explicit valence for atom # 18 S, 7, is greater than permitted\n#&gt; [07:45:54] ERROR: Could not sanitize molecule on line 6\n#&gt; [07:45:54] ERROR: Explicit valence for atom # 18 S, 7, is greater than permitted\n#&gt; [07:45:54] SMILES Parse Error: syntax error while parsing: OC1=CC=CC(=C1)C-1=C2\\CCC(=N2)\\C(=C2/N\\C(\\C=C2)=C(/C2=N/C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC(O)=CC=C1)C1=CC(O)=CC=C1)\\C1=CC(O)=CC=C1\n#&gt; [07:45:54] SMILES Parse Error: check for mistakes around position 76:\n#&gt; [07:45:54] C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC(O)=CC=C1)C\n#&gt; [07:45:54] ~~~~~~~~~~~~~~~~~~~~^\n#&gt; [07:45:54] SMILES Parse Error: Failed parsing SMILES 'OC1=CC=CC(=C1)C-1=C2\\CCC(=N2)\\C(=C2/N\\C(\\C=C2)=C(/C2=N/C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC(O)=CC=C1)C1=CC(O)=CC=C1)\\C1=CC(O)=CC=C1' for input: 'OC1=CC=CC(=C1)C-1=C2\\CCC(=N2)\\C(=C2/N\\C(\\C=C2)=C(/C2=N/C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC(O)=CC=C1)C1=CC(O)=CC=C1)\\C1=CC(O)=CC=C1'\n#&gt; [07:45:54] ERROR: Smiles parse error on line 7\n#&gt; [07:45:54] ERROR: Cannot create molecule from : 'OC1=CC=CC(=C1)C-1=C2\\CCC(=N2)\\C(=C2/N\\C(\\C=C2)=C(/C2=N/C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC(O)=CC=C1)C1=CC(O)=CC=C1)\\C1=CC(O)=CC=C1'\n#&gt; INFO [2025-07-10 07:46:17] Led to 877903 referenced structure-organism pairs\n#&gt; INFO [2025-07-10 07:46:19] Corresponding to 393389 unique stereoisomers (excluding structures without stereochemistry)...\n#&gt; INFO [2025-07-10 07:46:21] ... and 1007790 unique structures without stereochemistry...\n#&gt; INFO [2025-07-10 07:46:21] ... or 1184311 unique constitutional isomers (ignoring stereochemistry)\n#&gt; INFO [2025-07-10 07:46:42] ... among 36800 unique organisms\n#&gt; TRACE [2025-07-10 07:46:42] Keeping keys\n#&gt; TRACE [2025-07-10 07:46:42] Keeping organisms\n#&gt; TRACE [2025-07-10 07:46:42] Completing organisms taxonomy\n#&gt; TRACE [2025-07-10 07:46:42] Testing if Open Tree of Life API is up\n#&gt; TRACE [2025-07-10 07:46:42] Success! Submitting request\n#&gt; TRACE [2025-07-10 07:46:45] Request finished!\n#&gt; TRACE [2025-07-10 07:46:45] Getting taxonomy\n#&gt; TRACE [2025-07-10 07:46:46] Taxonomy retrieved!\n#&gt; TRACE [2025-07-10 07:46:46] Got OTTaxonomy!\n#&gt; TRACE [2025-07-10 07:46:46] Keeping structures\n#&gt; INFO [2025-07-10 07:46:46] ... path to used parameters is data/interim/params\n#&gt; INFO [2025-07-10 07:46:46] ... path to export is data/interim/libraries/sop/merged/keys.tsv.gz\n#&gt; INFO [2025-07-10 07:46:47] Directory data/interim/libraries/sop/merged/organisms/taxonomies created.\n#&gt; INFO [2025-07-10 07:46:47] ... path to export is data/interim/libraries/sop/merged/organisms/taxonomies/ott.tsv.gz\n#&gt; INFO [2025-07-10 07:46:47] ... path to export is data/interim/libraries/sop/merged/structures/stereo.tsv.gz\n#&gt; INFO [2025-07-10 07:46:50] ... path to export is data/interim/libraries/sop/merged/structures/metadata.tsv.gz\n#&gt; INFO [2025-07-10 07:46:52] ... path to export is data/interim/libraries/sop/merged/structures/names.tsv.gz\n#&gt; INFO [2025-07-10 07:46:53] Directory data/interim/libraries/sop/merged/structures/taxonomies created.\n#&gt; INFO [2025-07-10 07:46:53] ... path to export is data/interim/libraries/sop/merged/structures/taxonomies/classyfire.tsv.gz\n#&gt; INFO [2025-07-10 07:46:53] ... path to export is data/interim/libraries/sop/merged/structures/taxonomies/npc.tsv.gz\n#&gt; ✔ lib_sop_mer completed [1m 27.2s, 250 B]\n#&gt; + ann_spe_pos dispatched\n#&gt; TRACE [2025-07-10 07:46:54] Loading spectra\n#&gt; TRACE [2025-07-10 07:46:54] Harmonizing names\n#&gt; TRACE [2025-07-10 07:46:54] Filtering MS2 only\n#&gt; TRACE [2025-07-10 07:46:54] Combining spectra in case\n#&gt; TRACE [2025-07-10 07:46:54] Applying sanitization of the spectra\n#&gt; TRACE [2025-07-10 07:46:54] Filtering empty spectra\n#&gt; INFO [2025-07-10 07:46:54] Considering 22 spectra\n#&gt; TRACE [2025-07-10 07:46:54] Loading spectral libraries\n#&gt; TRACE [2025-07-10 07:47:11] Harmonizing spectrum id\n#&gt; TRACE [2025-07-10 07:47:11] Harmonizing spectrum id\n#&gt; TRACE [2025-07-10 07:47:17] Harmonizing spectrum id\n#&gt; TRACE [2025-07-10 07:47:18] Harmonizing spectrum id\n#&gt; TRACE [2025-07-10 07:47:22] Harmonizing spectrum id\n#&gt; INFO [2025-07-10 07:47:37] Annotating using following libraries\n#&gt; INFO [2025-07-10 07:47:40]          library spectra unique_connectivities\n#&gt;  ISDB - Wikidata  998198                998198\n#&gt;             gnps  354788                 22675\n#&gt;           merlin  208273                 26197\n#&gt;         massbank   66388                  5901\n#&gt;         internal     279                     1\n#&gt; TRACE [2025-07-10 07:47:40] Reducing library size\n#&gt; TRACE [2025-07-10 07:47:40] Annotating\n#&gt; TRACE [2025-07-10 07:47:42] Trying to harmonize adducts definitions\n#&gt; TRACE [2025-07-10 07:47:42] Filtering results above threshold only\n#&gt; INFO [2025-07-10 07:47:42] 5197 Candidates were annotated on 22 features, with at least 0 similarity score.\n#&gt; INFO [2025-07-10 07:47:42] ... path to used parameters is data/interim/params\n#&gt; INFO [2025-07-10 07:47:42] ... path to export is data/interim/annotations/example_spectralMatches_pos.tsv.gz\n#&gt; ✔ ann_spe_pos completed [47.8s, 255.88 kB]\n#&gt; + ann_spe_neg dispatched\n#&gt; TRACE [2025-07-10 07:47:43] Loading spectra\n#&gt; TRACE [2025-07-10 07:47:43] Harmonizing names\n#&gt; TRACE [2025-07-10 07:47:43] Filtering MS2 only\n#&gt; TRACE [2025-07-10 07:47:43] Combining spectra in case\n#&gt; TRACE [2025-07-10 07:47:43] Applying sanitization of the spectra\n#&gt; TRACE [2025-07-10 07:47:43] Filtering empty spectra\n#&gt; INFO [2025-07-10 07:47:43] Considering 0 spectra\n#&gt; WARN [2025-07-10 07:47:43] No spectra matched the given polarity, returning an empty dataframe\n#&gt; INFO [2025-07-10 07:47:43] ... path to used parameters is data/interim/params\n#&gt; INFO [2025-07-10 07:47:43] ... path to export is data/interim/annotations/example_spectralMatches_neg.tsv.gz\n#&gt; ✔ ann_spe_neg completed [117ms, 187 B]\n#&gt; + edg_spe dispatched\n#&gt; ✔ edg_spe completed [0ms, 852 B]\n#&gt; + lib_mer_key dispatched\n#&gt; ✔ lib_mer_key completed [0ms, 18.06 MB]\n#&gt; + lib_mer_str_met dispatched\n#&gt; ✔ lib_mer_str_met completed [0ms, 36.02 MB]\n#&gt; + lib_mer_str_nam dispatched\n#&gt; ✔ lib_mer_str_nam completed [1ms, 11.28 MB]\n#&gt; + lib_mer_str_stereo dispatched\n#&gt; ✔ lib_mer_str_stereo completed [0ms, 43.58 MB]\n#&gt; + lib_mer_str_tax_cla dispatched\n#&gt; ✔ lib_mer_str_tax_cla completed [0ms, 2.51 MB]\n#&gt; + lib_mer_str_tax_npc dispatched\n#&gt; ✔ lib_mer_str_tax_npc completed [0ms, 2.44 MB]\n#&gt; + lib_mer_org_tax_ott dispatched\n#&gt; ✔ lib_mer_org_tax_ott completed [1ms, 939.13 kB]\n#&gt; + ann_ms1_pre dispatched\n#&gt; TRACE [2025-07-10 07:48:05] Filtering desired adducts and adding mz tolerance\n#&gt; INFO [2025-07-10 07:48:05] Already 2112 adducts previously detected\n#&gt; TRACE [2025-07-10 07:48:05] Trying to harmonize adducts definitions\n#&gt; TRACE [2025-07-10 07:48:05] Calculating rt tolerance\n#&gt; TRACE [2025-07-10 07:48:05] Joining within given rt tolerance\n#&gt; INFO [2025-07-10 07:48:05] Here are the top 10 observed m/z differences inside the RT windows:\n#&gt; INFO [2025-07-10 07:48:05]              bin   N\n#&gt;  (4.8501,5.0366] 352\n#&gt;  (21.822,22.009] 283\n#&gt;   (16.973,17.16] 208\n#&gt;  (17.906,18.092] 192\n#&gt;  (15.854,16.041] 172\n#&gt;    (39.914,40.1] 143\n#&gt;  (38.981,39.168] 137\n#&gt;  (34.878,35.065] 115\n#&gt;  (77.962,78.148] 114\n#&gt;  (1.8659,2.0524] 108\n#&gt; INFO [2025-07-10 07:48:05] These differences may help identify potential preprocessing issues\n#&gt; TRACE [2025-07-10 07:48:05] Forming adducts and clusters\n#&gt; TRACE [2025-07-10 07:48:05] Calculating delta mz for single charge adducts and clusters\n#&gt; TRACE [2025-07-10 07:48:05] Joining within given delta mz tolerance (neutral losses)\n#&gt; TRACE [2025-07-10 07:48:05] Joining within given delta mz tolerance (adducts)\n#&gt; TRACE [2025-07-10 07:48:05] Keeping initial and destination feature\n#&gt; TRACE [2025-07-10 07:48:05] Joining with initial results (adducts)\n#&gt; TRACE [2025-07-10 07:48:05] Joining with initial results (neutral losses)\n#&gt; TRACE [2025-07-10 07:48:07] Joining within given mz tol to exact mass library\n#&gt; TRACE [2025-07-10 07:48:07] Keeping unique exact masses and molecular formulas\n#&gt; TRACE [2025-07-10 07:48:08] Joining exact masses with single charge adducts\n#&gt; TRACE [2025-07-10 07:48:08] Getting back to M\n#&gt; TRACE [2025-07-10 07:48:08] Calculating multicharged and in source dimers\n#&gt; TRACE [2025-07-10 07:48:37] Joining within given rt tolerance\n#&gt; TRACE [2025-07-10 07:48:37] Joining within given mz tol and filtering possible adducts\n#&gt; TRACE [2025-07-10 07:48:37] Joining single adducts, in source dimers, and multicharged\n#&gt; TRACE [2025-07-10 07:48:37] Adding chemical classification\n#&gt; INFO [2025-07-10 07:48:38] MS1 annotation led to 48099 annotations on 4224 features\n#&gt; INFO [2025-07-10 07:48:38] ... path to used parameters is data/interim/params\n#&gt; INFO [2025-07-10 07:48:38] ... path to export is data/interim/features/example_edgesMasses.tsv\n#&gt; INFO [2025-07-10 07:48:38] ... path to export is data/interim/annotations/example_ms1Prepared.tsv.gz\n#&gt; ✔ ann_ms1_pre completed [52.3s, 158 B]\n#&gt; + ann_spe_exp_gnp_pre dispatched\n#&gt; WARN [2025-07-10 07:48:39] No GNPS annotations found, returning an empty file instead\n#&gt; INFO [2025-07-10 07:48:39] ... path to used parameters is data/interim/params\n#&gt; INFO [2025-07-10 07:48:39] ... path to export is data/interim/annotations/example_gnpsPrepared.tsv.gz\n#&gt; ✔ ann_spe_exp_gnp_pre completed [22ms, 237 B]\n#&gt; + ann_spe_pre dispatched\n#&gt; TRACE [2025-07-10 07:48:40] Loading and formatting spectral matches\n#&gt; TRACE [2025-07-10 07:48:40] Selecting annotations columns\n#&gt; TRACE [2025-07-10 07:48:40] Trying to look for already computed metadata\n#&gt; TRACE [2025-07-10 07:48:42] Stereo loaded\n#&gt; TRACE [2025-07-10 07:48:46] Metadata loaded\n#&gt; TRACE [2025-07-10 07:48:54] Names loaded\n#&gt; TRACE [2025-07-10 07:48:54] Classyfire done\n#&gt; TRACE [2025-07-10 07:48:54] NPClassifier done\n#&gt; TRACE [2025-07-10 07:48:55] Metadata done\n#&gt; TRACE [2025-07-10 07:48:56] Names done\n#&gt; INFO [2025-07-10 07:49:01] ... path to used parameters is data/interim/params\n#&gt; INFO [2025-07-10 07:49:01] ... path to export is data/interim/annotations/example_spectralMatchesPrepared.tsv.gz\n#&gt; ✔ ann_spe_pre completed [20.8s, 373.16 kB]\n#&gt; + ann_sir_pre dispatched\n#&gt; INFO [2025-07-10 07:49:01] Loading parameters for SIRIUS 6\n#&gt; TRACE [2025-07-10 07:49:01] Loading and formatting SIRIUS results...\n#&gt; TRACE [2025-07-10 07:49:01] ... CANOPUS loaded\n#&gt; TRACE [2025-07-10 07:49:01] ... formulas loaded\n#&gt; TRACE [2025-07-10 07:49:01] ... structures loaded\n#&gt; TRACE [2025-07-10 07:49:01] ... de novo loaded\n#&gt; TRACE [2025-07-10 07:49:01] ... CANOPUS prepared\n#&gt; TRACE [2025-07-10 07:49:01] ... formulas prepared\n#&gt; TRACE [2025-07-10 07:49:01] ... structures prepared\n#&gt; TRACE [2025-07-10 07:49:02] ... denovo prepared\n#&gt; TRACE [2025-07-10 07:49:02] Everything joined together\n#&gt; TRACE [2025-07-10 07:49:02] Selecting annotations columns\n#&gt; TRACE [2025-07-10 07:49:02] Trying to look for already computed metadata\n#&gt; TRACE [2025-07-10 07:49:04] Stereo loaded\n#&gt; TRACE [2025-07-10 07:49:10] Metadata loaded\n#&gt; TRACE [2025-07-10 07:49:17] Names loaded\n#&gt; TRACE [2025-07-10 07:49:17] Classyfire done\n#&gt; TRACE [2025-07-10 07:49:18] NPClassifier done\n#&gt; TRACE [2025-07-10 07:49:18] Metadata done\n#&gt; TRACE [2025-07-10 07:49:19] Names done\n#&gt; TRACE [2025-07-10 07:49:23] Splitting SIRIUS results\n#&gt; INFO [2025-07-10 07:49:23] ... path to used parameters is data/interim/params\n#&gt; INFO [2025-07-10 07:49:23] ... path to export is data/interim/annotations/example_canopusPrepared.tsv.gz\n#&gt; INFO [2025-07-10 07:49:23] ... path to export is data/interim/annotations/example_formulaPrepared.tsv.gz\n#&gt; INFO [2025-07-10 07:49:23] ... path to export is data/interim/annotations/example_siriusPrepared.tsv.gz\n#&gt; ✔ ann_sir_pre completed [21.6s, 165 B]\n#&gt; + tax_pre dispatched\n#&gt; TRACE [2025-07-10 07:49:24] Loading feature table\n#&gt; TRACE [2025-07-10 07:49:24] Loading metadata table\n#&gt; TRACE [2025-07-10 07:49:24] Preparing organisms names\n#&gt; TRACE [2025-07-10 07:49:24] Retrieving already computed Open Tree of Life Taxonomy\n#&gt; TRACE [2025-07-10 07:49:24] Submitting the rest to OTL\n#&gt; TRACE [2025-07-10 07:49:24] Testing if Open Tree of Life API is up\n#&gt; TRACE [2025-07-10 07:49:24] Success! Submitting request\n#&gt; TRACE [2025-07-10 07:49:24] Request finished!\n#&gt; INFO [2025-07-10 07:49:24] Retrying with blk\n#&gt; TRACE [2025-07-10 07:49:24] Getting taxonomy\n#&gt; TRACE [2025-07-10 07:49:24] Taxonomy retrieved!\n#&gt; TRACE [2025-07-10 07:49:24] Got OTTaxonomy!\n#&gt; TRACE [2025-07-10 07:49:24] Joining all results\n#&gt; TRACE [2025-07-10 07:49:24] Joining with metadata table\n#&gt; TRACE [2025-07-10 07:49:24] Joining with cleaned taxonomy table\n#&gt; INFO [2025-07-10 07:49:25] ... path to used parameters is data/interim/params\n#&gt; INFO [2025-07-10 07:49:25] Directory data/interim/taxa created.\n#&gt; INFO [2025-07-10 07:49:25] ... path to export is data/interim/taxa/example_taxed.tsv.gz\n#&gt; ✔ tax_pre completed [1.3s, 19.70 kB]\n#&gt; + ann_ms1_pre_edg dispatched\n#&gt; ✔ ann_ms1_pre_edg completed [0ms, 81.71 kB]\n#&gt; + ann_ms1_pre_ann dispatched\n#&gt; ✔ ann_ms1_pre_ann completed [0ms, 10.81 MB]\n#&gt; + ann_sir_pre_can dispatched\n#&gt; ✔ ann_sir_pre_can completed [0ms, 784 B]\n#&gt; + ann_sir_pre_for dispatched\n#&gt; ✔ ann_sir_pre_for completed [0ms, 487 B]\n#&gt; + ann_sir_pre_str dispatched\n#&gt; ✔ ann_sir_pre_str completed [1ms, 24.42 kB]\n#&gt; + fea_edg_pre dispatched\n#&gt; TRACE [2025-07-10 07:49:27] Loading edge table\n#&gt; TRACE [2025-07-10 07:49:27] Formatting edge table\n#&gt; INFO [2025-07-10 07:49:27] ... path to used parameters is data/interim/params\n#&gt; INFO [2025-07-10 07:49:27] ... path to export is data/interim/features/example_edges.tsv\n#&gt; ✔ fea_edg_pre completed [36ms, 93.83 kB]\n#&gt; + ann_fil dispatched\n#&gt; TRACE [2025-07-10 07:49:27] ... features\n#&gt; TRACE [2025-07-10 07:49:28] ... annotations\n#&gt; TRACE [2025-07-10 07:49:28] Removing MS1 annotations for which we have spectral hits\n#&gt; TRACE [2025-07-10 07:49:28] ... retention times\n#&gt; INFO [2025-07-10 07:49:28] Filtering annotations outside of Inf minutes tolerance\n#&gt; INFO [2025-07-10 07:49:29] 0 candidates were removed based on retention time.\n#&gt; INFO [2025-07-10 07:49:29] ... path to used parameters is data/interim/params\n#&gt; INFO [2025-07-10 07:49:29] ... path to export is data/interim/annotations/example_annotationsFiltered.tsv.gz\n#&gt; ✔ ann_fil completed [2.6s, 11.66 MB]\n#&gt; + fea_com dispatched\n#&gt; INFO [2025-07-10 07:49:30] ... path to used parameters is data/interim/params\n#&gt; INFO [2025-07-10 07:49:30] ... path to export is data/interim/features/example_components.tsv\n#&gt; ✔ fea_com completed [42ms, 24.13 kB]\n#&gt; + int_com dispatched\n#&gt; ✔ int_com completed [0ms, 24.13 kB]\n#&gt; + fea_com_pre dispatched\n#&gt; TRACE [2025-07-10 07:49:31] Loading files\n#&gt; TRACE [2025-07-10 07:49:31] Components table\n#&gt; INFO [2025-07-10 07:49:31] ... path to used parameters is data/interim/params\n#&gt; INFO [2025-07-10 07:49:31] ... path to export is data/interim/features/example_componentsPrepared.tsv\n#&gt; ✔ fea_com_pre completed [20ms, 24.12 kB]\n#&gt; + ann_pre dispatched\n#&gt; TRACE [2025-07-10 07:49:31] Loading files ...\n#&gt; TRACE [2025-07-10 07:49:31] ... components\n#&gt; TRACE [2025-07-10 07:49:31] ... edges\n#&gt; TRACE [2025-07-10 07:49:32] ... structure-organism pairs\n#&gt; TRACE [2025-07-10 07:49:41] ... canopus\n#&gt; TRACE [2025-07-10 07:49:42] ... formula\n#&gt; TRACE [2025-07-10 07:49:42] ... annotations\n#&gt; TRACE [2025-07-10 07:49:43] Initial annotations:\n#&gt; INFO [2025-07-10 07:49:44]  candidate_library      n\n#&gt;           TIMA MS1 161103\n#&gt;    ISDB - Wikidata   4867\n#&gt;             SIRIUS    479\n#&gt;             merlin    165\n#&gt;               gnps    151\n#&gt;           massbank     33\n#&gt; TRACE [2025-07-10 07:49:44] Re-arranging annotations\n#&gt; TRACE [2025-07-10 07:49:45] Adding biological organism metadata\n#&gt; TRACE [2025-07-10 07:49:45] Performing taxonomically informed scoring\n#&gt; TRACE [2025-07-10 07:49:48] Calculating biological score at all levels ...\n#&gt; TRACE [2025-07-10 07:49:48] ... domain\n#&gt; TRACE [2025-07-10 07:49:48] ... kingdom\n#&gt; TRACE [2025-07-10 07:49:48] ... phylum\n#&gt; TRACE [2025-07-10 07:49:48] ... class\n#&gt; TRACE [2025-07-10 07:49:48] ... order\n#&gt; TRACE [2025-07-10 07:49:48] ... family\n#&gt; TRACE [2025-07-10 07:49:48] ... tribe\n#&gt; TRACE [2025-07-10 07:49:48] ... genus\n#&gt; TRACE [2025-07-10 07:49:48] ... species\n#&gt; TRACE [2025-07-10 07:49:48] ... varietas\n#&gt; TRACE [2025-07-10 07:49:48] Keeping best biological score\n#&gt; INFO [2025-07-10 07:49:49] Taxonomically informed metabolite annotation led to \n#&gt; 31600 annotations reranked at the kingdom level, \n#&gt; 31342 annotations reranked at the phylum level, \n#&gt; 26184 annotations reranked at the class level, \n#&gt; 7506 annotations reranked at the order level, \n#&gt; 6046 annotations reranked at the family level, \n#&gt; 1020 annotations reranked at the tribe level, \n#&gt; 812 annotations reranked at the genus level, \n#&gt; 348 annotations reranked at the species level, and \n#&gt; 0 annotations reranked at the variety level. \n#&gt; WITHOUT TAKING CONSISTENCY SCORE INTO ACCOUNT! (for later predictions)\n#&gt; TRACE [2025-07-10 07:49:49] Calculating chemical consistency of features with at least 2 neighbors\n#&gt; TRACE [2025-07-10 07:49:49] Among all edges\n#&gt; TRACE [2025-07-10 07:49:49] ... at the (classyfire) kingdom level\n#&gt; TRACE [2025-07-10 07:49:50] ... at the (NPC) pathway level\n#&gt; TRACE [2025-07-10 07:49:50] ... at the (classyfire) superclass level\n#&gt; TRACE [2025-07-10 07:49:50] ... at the (NPC) superclass level\n#&gt; TRACE [2025-07-10 07:49:50] ... at the (classyfire) class level\n#&gt; TRACE [2025-07-10 07:49:50] ... at the (NPC) class level\n#&gt; TRACE [2025-07-10 07:49:50] ... at the (classyfire) parent level\n#&gt; TRACE [2025-07-10 07:49:50] Splitting already computed predictions\n#&gt; TRACE [2025-07-10 07:49:51] Joining all except -1 together\n#&gt; TRACE [2025-07-10 07:49:52] Adding already computed predictions back\n#&gt; TRACE [2025-07-10 07:49:53] Calculating chemical score at all levels ...\n#&gt; TRACE [2025-07-10 07:49:53] ... (classyfire) kingdom\n#&gt; TRACE [2025-07-10 07:49:53] ... (NPC) pathway\n#&gt; TRACE [2025-07-10 07:49:53] ... (classyfire) superclass\n#&gt; TRACE [2025-07-10 07:49:53] ... (NPC) superclass\n#&gt; TRACE [2025-07-10 07:49:53] ... (classyfire) class\n#&gt; TRACE [2025-07-10 07:49:53] ... (NPC) class\n#&gt; TRACE [2025-07-10 07:49:53] ... (classyfire) parent\n#&gt; TRACE [2025-07-10 07:49:53] ... keeping best chemical score\n#&gt; INFO [2025-07-10 07:49:54] Chemically informed scoring led to \n#&gt; 13271 annotations reranked at the (classyfire) kingdom level, \n#&gt; 9281 annotations reranked at the (NPC) pathway level, \n#&gt; 7112 annotations reranked at the (classyfire) superclass level, \n#&gt; 4758 annotations reranked at the (NPC) superclass level, \n#&gt; 7112 annotations reranked at the (classyfire) class level, \n#&gt; 4758 annotations reranked at the (NPC) class level, and \n#&gt; 4747 annotations reranked at the (classyfire) parent level. \n#&gt; WITHOUT TAKING CONSISTENCY SCORE INTO ACCOUNT!\n#&gt; INFO [2025-07-10 07:49:54] Filtering top 1 candidates and keeping only MS1 candidates with minimum 0 biological score OR 0 chemical score \n#&gt; TRACE [2025-07-10 07:50:00] Minimizing results\n#&gt; TRACE [2025-07-10 07:50:02] Keeping high confidence candidates only\n#&gt; INFO [2025-07-10 07:50:02] Removed 165909 low confidence candidates out of the 167725 total ones.\n#&gt; INFO [2025-07-10 07:50:02] 1816 high confidence candidates remaining.\n#&gt; TRACE [2025-07-10 07:50:02] Processing full results\n#&gt; TRACE [2025-07-10 07:50:02] Adding initial metadata (RT, etc.) and simplifying columns\n#&gt; TRACE [2025-07-10 07:50:08] Selecting columns to export\n#&gt; TRACE [2025-07-10 07:50:08] Adding consensus again to droped candidates\n#&gt; TRACE [2025-07-10 07:50:09] Processing filtered results\n#&gt; TRACE [2025-07-10 07:50:09] Adding initial metadata (RT, etc.) and simplifying columns\n#&gt; TRACE [2025-07-10 07:50:13] Selecting columns to export\n#&gt; TRACE [2025-07-10 07:50:13] Adding consensus again to droped candidates\n#&gt; INFO [2025-07-10 07:50:16] Directory data/processed/20250710_075016_example created.\n#&gt; INFO [2025-07-10 07:50:16] ... path to used parameters is data/processed/20250710_075016_example\n#&gt; INFO [2025-07-10 07:50:16] ... path to used parameters is data/processed/20250710_075016_example\n#&gt; INFO [2025-07-10 07:50:16] ... path to export is data/processed/20250710_075016_example/example_results_mini.tsv\n#&gt; INFO [2025-07-10 07:50:16] ... path to export is data/processed/20250710_075016_example/example_results_filtered.tsv\n#&gt; INFO [2025-07-10 07:50:16] ... path to export is data/processed/20250710_075016_example/example_results.tsv\n#&gt; ✔ ann_pre completed [44.2s, 3.76 MB]\n#&gt; ✔ ended pipeline [7m 52.4s, 126 completed, 0 skipped]\n#&gt; There were 15 warnings (use warnings() to see them)\n#&gt; Processing complete. Total molecules processed: 54\n#&gt; [1] TRUE\n\nThe final exported file is formatted in order to be easily imported in Cytoscape to further explore your data!\nWe hope you enjoyed using TIMA and are pleased to hear from you!\nFor any remark or suggestion, please fill an issue or feel free to contact us directly.\n\n\n\nCitationBibTeX citation:@online{rutz2025,\n  author = {Rutz, Adriano},\n  title = {3 {Performing} {Taxonomically} {Informed} {Metabolite}\n    {Annotation}},\n  date = {2025-07-10},\n  url = {https://taxonomicallyinformedannotation.github.io/tima/vignettes/articles/III-processing.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRutz, Adriano. 2025. “3 Performing Taxonomically Informed\nMetabolite Annotation.” July 10, 2025. https://taxonomicallyinformedannotation.github.io/tima/vignettes/articles/III-processing.html."
  },
  {
    "objectID": "vignettes/articles/I-gathering.html",
    "href": "vignettes/articles/I-gathering.html",
    "title": "1 Gathering everything you need",
    "section": "",
    "text": "This vignette describes…"
  },
  {
    "objectID": "vignettes/articles/I-gathering.html#parameters",
    "href": "vignettes/articles/I-gathering.html#parameters",
    "title": "1 Gathering everything you need",
    "section": "Parameters",
    "text": "Parameters\nAll steps require parameters. Some default parameters are available and can be accessed in the params/default directory. If you prefer accessing them through the GUI, you can do so. Each parameter contains a small help menu, you can click on, as illustrated below.\n\n\n\n\nFor example, if you want to have an output compatible with Cytoscape, with multiple annotations per features:\n\n\nAll parameters will be saved and reported at the end of your analysis."
  },
  {
    "objectID": "vignettes/articles/I-gathering.html#inputs",
    "href": "vignettes/articles/I-gathering.html#inputs",
    "title": "1 Gathering everything you need",
    "section": "Inputs",
    "text": "Inputs\n\nYour own files\nYou should provide your own files in the main menu. For this tutorial, we will use some example files you can get running:\n\ntima::get_example_files()\n\n\n\nLibraries\nThe following paragraph describes the libraries available by default.\n\nSpectra\nAs a first step, you need spectral libraries to perform MS2-based annotation.\n\nExperimental\nYou can of course use your own experimental spectral library to perform MS2 annotation. We currently support spectral libraries in MSP or MGF format.\nTo get a small example:\n\ntima::get_example_files(\"spectral_lib_with_rt\")\n\n\nGNPS, MassBank & MERLIN\nGNPS, MassBank & MERLIN are downloaded and used by default, for more info about them, see https://github.com/Adafede/SpectRalLibRaRies.\nIn case you want to format your own spectral library to use it for spectral matching, adapt it the same way.\n\n\n\nIn silico\nAs the availability of experimental spectra is limited, we can take advantage of in silico generated spectra.\n\n\n\nWikidata\nWe generated an in silico spectral library of the structures found in Wikidata using CFM4. For more info, see https://doi.org/10.5281/zenodo.5607185. It is made available in both polarities.\nYou can also complement with the in silico spectra from HMDB (not running by default as quite long):\n\n\nHMDB\n\ntima::get_example_files(\"hmdb_is\")\n\n\n\nRetention times\nThis library is optional. As no standard LC method is shared (for now) among laboratories, this library will be heavily laboratory-dependent. It could also be a library of in silico predicted retention times. If you want to prepare you own library, have a look at params/user/prepare_libraries_rt.yaml.\n\n\nStructure-Organism Pairs\n\nLOTUS\nAs we developed LOTUS1 with Taxonomically Informed Metabolite Annotation in mind, we provide it here as a starting point for your structure-organism pairs library.\nThe process to download LOTUS looks like this:\n\n\n\n\n\n\nAs you can see, one target seems outdated. In reality, we force it to search if a new version of LOTUS exists each time. If a newer version exists, it will fetch it and re-run needed steps accordingly.\n\n\nECMDB\nBy default, we also complement LOTUS pairs with the ones coming from ECMDB.\n\n\nHMDB\nAnd we do the same with the ones coming from HMDB.\nFor these first steps, you do not need to change any parameters as they are implemented by default.\n\n\nOther libraries\nAs we want our tool to be flexible, you can also add your own library to LOTUS. You just need to format it in order to be compatible. As example, we prepared some ways too format closed, in house libraries. If you need help formatting your library or would like to share it with us for it to be implemented, feel free to contact us. Before running the corresponding code, do not forget to modify params/user/prepare_libraries_sop_closed.yaml.\n\n\nMerging\nOnce all sub-libraries are ready, they are then merged in a single file that will be used for the next steps.\n\n\n\n\n\n\nWe now recommend you to read the next vignette."
  },
  {
    "objectID": "vignettes/articles/I-gathering.html#footnotes",
    "href": "vignettes/articles/I-gathering.html#footnotes",
    "title": "1 Gathering everything you need",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor more informations, see https://doi.org/10.7554/eLife.70780↩︎"
  },
  {
    "objectID": "vignettes/tima.html",
    "href": "vignettes/tima.html",
    "title": "General comments about the infrastructure",
    "section": "",
    "text": "This vignette describes the philosophy behind the infrastructure of TIMA."
  },
  {
    "objectID": "vignettes/tima.html#philosophy",
    "href": "vignettes/tima.html#philosophy",
    "title": "General comments about the infrastructure",
    "section": "Philosophy",
    "text": "Philosophy\nOur main goals were flexibility and reproducibility.\n\nFlexibility\nTo ensure flexibility, we tried to split the process in as much tiny parts as needed. So you can decide whether to skip an optional part, add your own processing, etc. We tried to cover most use cases, but of course they are not exhaustive. If you feel like something useful to other users is missing, please fill an issue.\n\n\nReproducibility\nAfter some time using TIMA, you will probably wonder: “What was the parameters I used to generate this file?” … Or a collaborator might ask you to share your data and parameters. Writing them down each time might be time-consuming and not really in line with modern computational approaches. Therefore, we chose to implement all parameters of all steps (almost…) as YAML files. They are human-readable and can be used in batches. If you do not like YAML, parameters of each step can also be given as command line arguments. They will then be saved as YAML you will be able to share.\nTo ensure optimal reproducibility and avoiding re-computing endlessly steps that did not change, we decided to build a {targets} pipeline. Each step of the whole pipeline will be described next."
  },
  {
    "objectID": "vignettes/tima.html#use",
    "href": "vignettes/tima.html#use",
    "title": "General comments about the infrastructure",
    "section": "Use",
    "text": "Use\nAll coming steps admit you already installed tima:\n\ninstall.packages(\n  \"tima\",\n  repos = c(\n    \"https://taxonomicallyinformedannotation.r-universe.dev\",\n    \"https://bioc.r-universe.dev\",\n    \"https://cloud.r-project.org\"\n  )\n)\ntima::install()\ntima::get_example_files()\n\nWe now recommend you to read the following vignettes:\n\nhttps://taxonomicallyinformedannotation.github.io/tima/vignettes/articles/I-gathering.html\nhttps://taxonomicallyinformedannotation.github.io/tima/vignettes/articles/II-preparing.html\nhttps://taxonomicallyinformedannotation.github.io/tima/vignettes/articles/III-processing.html\nhttps://taxonomicallyinformedannotation.github.io/tima/vignettes/articles/IV-benchmarking.html\n\n\ntl;dr\nIf you do not feel like going through all the steps, then just do 🚀:\n\ntima::run_app()\n\nIf you do not even need a GUI ☠️:\n\ntima::tima_full()\n\nIn case you just want to change some small parameters between jobs, a convenience function is available:\n\ntima::change_params_small(\n  fil_pat = \"myExamplePattern\",\n  fil_fea_raw = \"myExampleDir/myExampleFeatures.csv\",\n  fil_met_raw = \"myExampleDir2SomeWhereElse/myOptionalMetadata.tsv\",\n  fil_sir_raw = \"myExampleDir3/myAwesomeSiriusProject.zip\",\n  fil_spe_raw = \"myBeautifulSpectra.mgf\",\n  ms_pol = \"pos\",\n  org_tax = \"Gentiana lutea\",\n  hig_con = TRUE,\n  summarize = FALSE\n)"
  },
  {
    "objectID": "vignettes/articles/IV-benchmarking.html",
    "href": "vignettes/articles/IV-benchmarking.html",
    "title": "4 Benchmarking Performance",
    "section": "",
    "text": "This vignette simply shows the actual performance of TIMA.\nThe benchmarking dataset was built using https://zenodo.org/record/5186176.\nIt contained positive and negative MS2 spectra of multiple ion species ([M+H]+, [M+Na]+, [M+H4N]+, …) coming from different mass spectrometers.\nIn positive mode, It was filtered to 27,789 spectra, representing 17,822 structures without stereo. Of those, only 15,005 spectra (54.0%) corresponded to structures present in the library we used to annotate.\nIn negative mode, It was filtered to 12,060 spectra, representing 9,112 structures without stereo. Of those, only 6,282 spectra (52.1%) corresponded to structures present in the library we used to annotate."
  },
  {
    "objectID": "vignettes/articles/IV-benchmarking.html#best-100-candidates",
    "href": "vignettes/articles/IV-benchmarking.html#best-100-candidates",
    "title": "4 Benchmarking Performance",
    "section": "Best 100 candidates",
    "text": "Best 100 candidates\n\nPositive\n\n\n\n\nNegative"
  },
  {
    "objectID": "vignettes/articles/IV-benchmarking.html#best-25-candidates-zoomed",
    "href": "vignettes/articles/IV-benchmarking.html#best-25-candidates-zoomed",
    "title": "4 Benchmarking Performance",
    "section": "Best 25 candidates (zoomed)",
    "text": "Best 25 candidates (zoomed)\n\nPositive\n\n\n\n\nNegative"
  },
  {
    "objectID": "vignettes/articles/IV-benchmarking.html#candidates-distribution",
    "href": "vignettes/articles/IV-benchmarking.html#candidates-distribution",
    "title": "4 Benchmarking Performance",
    "section": "Candidates distribution",
    "text": "Candidates distribution\n\nPositive\n\n\n\n\nNegative"
  },
  {
    "objectID": "vignettes/articles/II-preparing.html",
    "href": "vignettes/articles/II-preparing.html",
    "title": "2 Preparing inputs",
    "section": "",
    "text": "This vignette describes the main steps of the annotation process."
  },
  {
    "objectID": "vignettes/articles/II-preparing.html#structural-annotations-of-your-features",
    "href": "vignettes/articles/II-preparing.html#structural-annotations-of-your-features",
    "title": "2 Preparing inputs",
    "section": "Structural annotations of your features",
    "text": "Structural annotations of your features\nFor the moment, we support 3 different types of annotations:\n\n\nInternal MS1 exact mass-based library search\nInternal MS2 library search (experimental and in silico)\nSIRIUS\n\nIf needed, you can get an example of what your minimal feature table should look like by running:\n\ntima::get_example_files(example = \"features\")\n\nThen, you can prepare your features for the next steps:\n\ntima::prepare_features_tables()\n#&gt; [1] \"data/interim/features/example_features.tsv.gz\"\n\n\nMS1-based\nThese annotations are of the lowest possible quality. However, they allow to annotate unusual adducts, in-source fragments thanks to different small tricks implemented. Try to really restrict the adduct list and structure-organism pairs you want to consider as possibilities explode rapidly.\n\ntima::annotate_masses()\n#&gt;                                           annotations \n#&gt; \"data/interim/annotations/example_ms1Prepared.tsv.gz\" \n#&gt;                                                 edges \n#&gt;       \"data/interim/features/example_edgesMasses.tsv\"\n\n\n\nSpectral\n\ntima::annotate_spectra()\n#&gt;  ■■■■■■■■■■■■■                     41% |  ETA:  1s\n#&gt; [1] \"data/interim/annotations/example_spectralMatches.tsv.gz\"\ntima::prepare_annotations_spectra()\n#&gt; [1] \"data/interim/annotations/example_spectralMatchesPrepared.tsv.gz\"\n\nThere are multiple similarities available, including spectral entropy from https://doi.org/10.1038/s41592-021-01331-z for matching.\n\nGNPS\nOptional\n\ntima::prepare_annotations_gnps()\n#&gt; [1] \"data/interim/annotations/example_gnpsPrepared.tsv.gz\"\n\n\n\n\nFingerprint-based\n\nSirius\nAs SIRIUS jobs are long to perform, we provide example SIRIUS workspaces (both SIRIUS 5 and 6). Note that spectral matches from SIRIUS are not supported for now. They have been generated on the 20 first lines of the example MGF with the following command:\n\n# this is run on SIRIUS 6\nsirius \\\n--noCite \\\n--input=data/source/example_spectra_mini.mgf \\\n--output=data/interim/annotations/example_sirius.sirius/ \\\n--maxmz=800 \\\nconfig \\\n--AlgorithmProfile=orbitrap \\\n--StructureSearchDB=BIO \\\n--Timeout.secondsPerTree=10 \\\n--Timeout.secondsPerInstance=10 \\\nformulas \\\nzodiac \\\nfingerprints \\\nclasses \\\nstructures \\\ndenovo-structures \\\nsummaries \\\n--chemvista \\\n--feature-quality-summary \\\n--full-summary\n\n# this is run on SIRIUS 5\nsirius \\\n--noCite \\\n--input data/source/example_spectra_mini.mgf \\\n--output data/interim/annotations/example_sirius/ \\\n--maxmz 800 \\\nconfig \\\n--AlgorithmProfile orbitrap \\\n--StructureSearchDB BIO \\\n--Timeout.secondsPerTree 10 \\\n--Timeout.secondsPerInstance 10 \\\nformula \\\nzodiac \\\nfingerprint \\\nstructure \\\ncompound-classes \\\nwrite-summaries \\\n--full-summary\n\nThese parameters were not optimized and were only used to give an example output. If you are using the cli, do not forget to generate the summaries with the --full-summary option, or if you use the gui, generate them by clicking the corresponding icon. You can get an example running:\n\ntima:::get_example_sirius()\n#&gt; [1] \"data/interim/annotations/example_sirius.zip\"\n\nThe sirius workspace should ideally have yourPattern_sirius as name and be placed in data/interim/annotations (else it will not be found by default except you provide the right path).\n\ntima::prepare_annotations_sirius()\n#&gt;                                                   canopus \n#&gt; \"data/interim/annotations/example_canopusPrepared.tsv.gz\" \n#&gt;                                                   formula \n#&gt; \"data/interim/annotations/example_formulaPrepared.tsv.gz\" \n#&gt;                                                structural \n#&gt;  \"data/interim/annotations/example_siriusPrepared.tsv.gz\"\n\nIf you want to know how we attempt to combine the CSI score with other ones, see R/transform_score_sirius_csi.R Note that starting from SIRIUS6, the approx confidence score is the one considered, and not the exact one.\n\n\n\n\n\n\nAnnotations are now prepared and can be used for further processing. Your features are not only informed with structural information but also, chemical class information. The latter might be corresponding or not to the chemical class of your annotated structure, depending on the consistency of your annotations."
  },
  {
    "objectID": "vignettes/articles/II-preparing.html#chemical-class-annotation-of-your-features",
    "href": "vignettes/articles/II-preparing.html#chemical-class-annotation-of-your-features",
    "title": "2 Preparing inputs",
    "section": "Chemical class annotation of your features",
    "text": "Chemical class annotation of your features\nWithin our workflow, we offer a new way to attribute chemical classes to your features. It is analog to Network Annotation Propagation, but uses the edges of your network instead of the clusters. This makes more sense in our view, as also recently illustrated by CANOPUS.\n\nWe are currently also working on CANOPUS integration for chemical class annotation but this implies way heavier computations and we want to offer our users a fast solution.\n\nGenerating a network\nA network is generated during the process. The edges are created based on the spectral entropy similarity calculated between your spectra (see https://doi.org/10.1038/s41592-021-01331-z).\n\ntima::create_edges_spectra()\n#&gt; [1] \"data/interim/features/example_edgesSpectra.tsv\"\n\nPrepare the edges:\n\ntima::prepare_features_edges()\n#&gt; [1] \"data/interim/features/example_edges.tsv\"\n\nCreate and prepare the components:\n\ntima::create_components()\n#&gt; [1] \"data/interim/features/example_components.tsv\"\n\n\ntima::prepare_features_components()\n#&gt; [1] \"data/interim/features/example_componentsPrepared.tsv\""
  },
  {
    "objectID": "vignettes/articles/II-preparing.html#biological-source-annotation",
    "href": "vignettes/articles/II-preparing.html#biological-source-annotation",
    "title": "2 Preparing inputs",
    "section": "Biological source annotation",
    "text": "Biological source annotation\nThis step allows you to attribute biological source information to your features. If all your features come from a single extract, it will attribute the biological source of your extract to all your features. If you have multiple extracts aligned, it will take the n (according to your parameters) highest intensities of your aligned feature table and attribute the biological source of corresponding extracts. \n\ntima::prepare_taxa()\n#&gt; [1] \"data/interim/taxa/example_taxed.tsv.gz\""
  },
  {
    "objectID": "vignettes/articles/II-preparing.html#filter-annotations-based-on-retention-time",
    "href": "vignettes/articles/II-preparing.html#filter-annotations-based-on-retention-time",
    "title": "2 Preparing inputs",
    "section": "Filter annotations (based on retention time)",
    "text": "Filter annotations (based on retention time)\nThis step allows you to filter out the annotation of all the tools used, based on your own internal (experimental or predicted) retention times library. It is optional. If you do not have one, it will simply group the annotations of all tools.\n\ntima::filter_annotations()\n#&gt; [1] \"data/interim/annotations/example_annotationsFiltered.tsv.gz\"\n\nYou are almost there! See already all the steps accomplished!\n\n\n\n\n\n\nWe now recommend you to read the next vignette."
  },
  {
    "objectID": "man/annotate_masses.html",
    "href": "man/annotate_masses.html",
    "title": "tima",
    "section": "",
    "text": "This function annotates a feature table based on exact mass match. It requires a structural library, its metadata, and lists of adducts, clusters, and neutral losses to be considered. The polarity has to be pos or neg and retention time and mass tolerances should be given. The feature table is expected to be pre-formatted.\n\n\n\nannotate_masses(\n  features = get_params(step = \"annotate_masses\")\\$files\\$features\\$prepared,\n  output_annotations = get_params(step =\n    \"annotate_masses\")\\$files\\$annotations\\$prepared\\$structural\\$ms1,\n  output_edges = get_params(step = \"annotate_masses\")\\$files\\$networks\\$spectral\\$edges\\$raw,\n  name_source = get_params(step = \"annotate_masses\")\\$names\\$source,\n  name_target = get_params(step = \"annotate_masses\")\\$names\\$target,\n  library = get_params(step = \"annotate_masses\")\\$files\\$libraries\\$sop\\$merged\\$keys,\n  str_stereo = get_params(step =\n    \"annotate_masses\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$stereo,\n  str_met = get_params(step =\n    \"annotate_masses\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$metadata,\n  str_nam = get_params(step =\n    \"annotate_masses\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$names,\n  str_tax_cla = get_params(step =\n    \"annotate_masses\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$taxonomies\\$cla,\n  str_tax_npc = get_params(step =\n    \"annotate_masses\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$taxonomies\\$npc,\n  adducts_list = get_params(step = \"annotate_masses\")\\$ms\\$adducts,\n  clusters_list = get_params(step = \"annotate_masses\")\\$ms\\$clusters,\n  neutral_losses_list = get_params(step = \"annotate_masses\")\\$ms\\$neutral_losses,\n  ms_mode = get_params(step = \"annotate_masses\")\\$ms\\$polarity,\n  tolerance_ppm = get_params(step = \"annotate_masses\")\\$ms\\$tolerances\\$mass\\$ppm\\$ms1,\n  tolerance_rt = get_params(step = \"annotate_masses\")\\$ms\\$tolerances\\$rt\\$adducts\n)\n\n\n\n\n\n\n\nfeatures\n\n\nTable containing your previous annotation to complement\n\n\n\n\noutput_annotations\n\n\nOutput for mass based structural annotations\n\n\n\n\noutput_edges\n\n\nOutput for mass based edges\n\n\n\n\nname_source\n\n\nName of the source features column\n\n\n\n\nname_target\n\n\nName of the target features column\n\n\n\n\nlibrary\n\n\nLibrary containing the keys\n\n\n\n\nstr_stereo\n\n\nFile containing structures stereo\n\n\n\n\nstr_met\n\n\nFile containing structures metadata\n\n\n\n\nstr_nam\n\n\nFile containing structures names\n\n\n\n\nstr_tax_cla\n\n\nFile containing Classyfire taxonomy\n\n\n\n\nstr_tax_npc\n\n\nFile containing NPClassifier taxonomy\n\n\n\n\nadducts_list\n\n\nList of adducts to be used\n\n\n\n\nclusters_list\n\n\nList of clusters to be used\n\n\n\n\nneutral_losses_list\n\n\nList of neutral losses to be used\n\n\n\n\nms_mode\n\n\nIonization mode. Must be ‘pos’ or ‘neg’\n\n\n\n\ntolerance_ppm\n\n\nTolerance to perform annotation. Should be &lt;= 20 ppm\n\n\n\n\ntolerance_rt\n\n\nTolerance to group adducts. Should be &lt;= 0.05 minutes\n\n\n\n\n\n\nThe path to the files containing MS1 annotations and edges\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\ngithub &lt;- \"https://raw.githubusercontent.com/\"\nrepo &lt;- \"taxonomicallyinformedannotation/tima-example-files/main/\"\ndata_interim &lt;- \"data/interim/\"\ndir &lt;- paste0(github, repo)\ndir &lt;- paste0(dir, data_interim)\ndir_sop_mer &lt;- paste0(dir, \"libraries/sop/merged/\")\ndir_str &lt;- paste0(dir_sop_mer, \"structures/\")\ndir_tax &lt;- paste0(dir_str, \"taxonomies/\")\nannotate_masses(\n  features = paste0(dir, \"features/example_features.tsv\"),\n  library = paste0(dir_sop_mer, \"keys.tsv\"),\n  str_stereo = paste0(dir_str, \"stereo.tsv\"),\n  str_met = paste0(dir_str, \"metadata.tsv\"),\n  str_nam = paste0(dir_str, \"names.tsv\"),\n  str_tax_cla = paste0(dir_tax, \"classyfire.tsv\"),\n  str_tax_npc = paste0(dir_tax, \"npc.tsv\")\n)\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/annotate_masses.html#annotate-masses",
    "href": "man/annotate_masses.html#annotate-masses",
    "title": "tima",
    "section": "",
    "text": "This function annotates a feature table based on exact mass match. It requires a structural library, its metadata, and lists of adducts, clusters, and neutral losses to be considered. The polarity has to be pos or neg and retention time and mass tolerances should be given. The feature table is expected to be pre-formatted.\n\n\n\nannotate_masses(\n  features = get_params(step = \"annotate_masses\")\\$files\\$features\\$prepared,\n  output_annotations = get_params(step =\n    \"annotate_masses\")\\$files\\$annotations\\$prepared\\$structural\\$ms1,\n  output_edges = get_params(step = \"annotate_masses\")\\$files\\$networks\\$spectral\\$edges\\$raw,\n  name_source = get_params(step = \"annotate_masses\")\\$names\\$source,\n  name_target = get_params(step = \"annotate_masses\")\\$names\\$target,\n  library = get_params(step = \"annotate_masses\")\\$files\\$libraries\\$sop\\$merged\\$keys,\n  str_stereo = get_params(step =\n    \"annotate_masses\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$stereo,\n  str_met = get_params(step =\n    \"annotate_masses\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$metadata,\n  str_nam = get_params(step =\n    \"annotate_masses\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$names,\n  str_tax_cla = get_params(step =\n    \"annotate_masses\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$taxonomies\\$cla,\n  str_tax_npc = get_params(step =\n    \"annotate_masses\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$taxonomies\\$npc,\n  adducts_list = get_params(step = \"annotate_masses\")\\$ms\\$adducts,\n  clusters_list = get_params(step = \"annotate_masses\")\\$ms\\$clusters,\n  neutral_losses_list = get_params(step = \"annotate_masses\")\\$ms\\$neutral_losses,\n  ms_mode = get_params(step = \"annotate_masses\")\\$ms\\$polarity,\n  tolerance_ppm = get_params(step = \"annotate_masses\")\\$ms\\$tolerances\\$mass\\$ppm\\$ms1,\n  tolerance_rt = get_params(step = \"annotate_masses\")\\$ms\\$tolerances\\$rt\\$adducts\n)\n\n\n\n\n\n\n\nfeatures\n\n\nTable containing your previous annotation to complement\n\n\n\n\noutput_annotations\n\n\nOutput for mass based structural annotations\n\n\n\n\noutput_edges\n\n\nOutput for mass based edges\n\n\n\n\nname_source\n\n\nName of the source features column\n\n\n\n\nname_target\n\n\nName of the target features column\n\n\n\n\nlibrary\n\n\nLibrary containing the keys\n\n\n\n\nstr_stereo\n\n\nFile containing structures stereo\n\n\n\n\nstr_met\n\n\nFile containing structures metadata\n\n\n\n\nstr_nam\n\n\nFile containing structures names\n\n\n\n\nstr_tax_cla\n\n\nFile containing Classyfire taxonomy\n\n\n\n\nstr_tax_npc\n\n\nFile containing NPClassifier taxonomy\n\n\n\n\nadducts_list\n\n\nList of adducts to be used\n\n\n\n\nclusters_list\n\n\nList of clusters to be used\n\n\n\n\nneutral_losses_list\n\n\nList of neutral losses to be used\n\n\n\n\nms_mode\n\n\nIonization mode. Must be ‘pos’ or ‘neg’\n\n\n\n\ntolerance_ppm\n\n\nTolerance to perform annotation. Should be &lt;= 20 ppm\n\n\n\n\ntolerance_rt\n\n\nTolerance to group adducts. Should be &lt;= 0.05 minutes\n\n\n\n\n\n\nThe path to the files containing MS1 annotations and edges\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\ngithub &lt;- \"https://raw.githubusercontent.com/\"\nrepo &lt;- \"taxonomicallyinformedannotation/tima-example-files/main/\"\ndata_interim &lt;- \"data/interim/\"\ndir &lt;- paste0(github, repo)\ndir &lt;- paste0(dir, data_interim)\ndir_sop_mer &lt;- paste0(dir, \"libraries/sop/merged/\")\ndir_str &lt;- paste0(dir_sop_mer, \"structures/\")\ndir_tax &lt;- paste0(dir_str, \"taxonomies/\")\nannotate_masses(\n  features = paste0(dir, \"features/example_features.tsv\"),\n  library = paste0(dir_sop_mer, \"keys.tsv\"),\n  str_stereo = paste0(dir_str, \"stereo.tsv\"),\n  str_met = paste0(dir_str, \"metadata.tsv\"),\n  str_nam = paste0(dir_str, \"names.tsv\"),\n  str_tax_cla = paste0(dir_tax, \"classyfire.tsv\"),\n  str_tax_npc = paste0(dir_tax, \"npc.tsv\")\n)\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/filter_annotations.html",
    "href": "man/filter_annotations.html",
    "title": "tima",
    "section": "",
    "text": "This function filters initial annotations.\n\n\n\nfilter_annotations(\n  annotations = get_params(step =\n    \"filter_annotations\")\\$files\\$annotations\\$prepared\\$structural,\n  features = get_params(step = \"filter_annotations\")\\$files\\$features\\$prepared,\n  rts = get_params(step = \"filter_annotations\")\\$files\\$libraries\\$temporal\\$prepared,\n  output = get_params(step = \"filter_annotations\")\\$files\\$annotations\\$filtered,\n  tolerance_rt = get_params(step = \"filter_annotations\")\\$ms\\$tolerances\\$rt\\$library\n)\n\n\n\n\n\n\n\nannotations\n\n\nPrepared annotations file\n\n\n\n\nfeatures\n\n\nPrepared features file\n\n\n\n\nrts\n\n\nPrepared retention time library\n\n\n\n\noutput\n\n\nOutput file\n\n\n\n\ntolerance_rt\n\n\nTolerance to filter retention time\n\n\n\n\n\n\nThe path to the filtered annotations\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\ngithub &lt;- \"https://raw.githubusercontent.com/\"\nrepo &lt;- \"taxonomicallyinformedannotation/tima-example-files/main/\"\ndir &lt;- paste0(github, repo)\nannotations &lt;- get_params(step = \"filter_annotations\")$files$annotations$prepared$structural[[2]] |&gt;\n  gsub(\n    pattern = \".gz\",\n    replacement = \"\",\n    fixed = TRUE\n  )\nfeatures &lt;- get_params(step = \"filter_annotations\")$files$features$prepared |&gt;\n  gsub(\n    pattern = \".gz\",\n    replacement = \"\",\n    fixed = TRUE\n  )\nrts &lt;- get_params(step = \"filter_annotations\")$files$libraries$temporal$prepared |&gt;\n  gsub(\n    pattern = \".gz\",\n    replacement = \"\",\n    fixed = TRUE\n  )\nget_file(url = paste0(dir, annotations), export = annotations)\nget_file(url = paste0(dir, features), export = features)\nget_file(url = paste0(dir, rts), export = rts)\nfilter_annotations(\n  annotations = annotations,\n  features = features,\n  rts = rts\n)\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/filter_annotations.html#filter-annotations",
    "href": "man/filter_annotations.html#filter-annotations",
    "title": "tima",
    "section": "",
    "text": "This function filters initial annotations.\n\n\n\nfilter_annotations(\n  annotations = get_params(step =\n    \"filter_annotations\")\\$files\\$annotations\\$prepared\\$structural,\n  features = get_params(step = \"filter_annotations\")\\$files\\$features\\$prepared,\n  rts = get_params(step = \"filter_annotations\")\\$files\\$libraries\\$temporal\\$prepared,\n  output = get_params(step = \"filter_annotations\")\\$files\\$annotations\\$filtered,\n  tolerance_rt = get_params(step = \"filter_annotations\")\\$ms\\$tolerances\\$rt\\$library\n)\n\n\n\n\n\n\n\nannotations\n\n\nPrepared annotations file\n\n\n\n\nfeatures\n\n\nPrepared features file\n\n\n\n\nrts\n\n\nPrepared retention time library\n\n\n\n\noutput\n\n\nOutput file\n\n\n\n\ntolerance_rt\n\n\nTolerance to filter retention time\n\n\n\n\n\n\nThe path to the filtered annotations\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\ngithub &lt;- \"https://raw.githubusercontent.com/\"\nrepo &lt;- \"taxonomicallyinformedannotation/tima-example-files/main/\"\ndir &lt;- paste0(github, repo)\nannotations &lt;- get_params(step = \"filter_annotations\")$files$annotations$prepared$structural[[2]] |&gt;\n  gsub(\n    pattern = \".gz\",\n    replacement = \"\",\n    fixed = TRUE\n  )\nfeatures &lt;- get_params(step = \"filter_annotations\")$files$features$prepared |&gt;\n  gsub(\n    pattern = \".gz\",\n    replacement = \"\",\n    fixed = TRUE\n  )\nrts &lt;- get_params(step = \"filter_annotations\")$files$libraries$temporal$prepared |&gt;\n  gsub(\n    pattern = \".gz\",\n    replacement = \"\",\n    fixed = TRUE\n  )\nget_file(url = paste0(dir, annotations), export = annotations)\nget_file(url = paste0(dir, features), export = features)\nget_file(url = paste0(dir, rts), export = rts)\nfilter_annotations(\n  annotations = annotations,\n  features = features,\n  rts = rts\n)\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/weight_annotations.html",
    "href": "man/weight_annotations.html",
    "title": "tima",
    "section": "",
    "text": "This function weights annotations.\n\n\n\nweight_annotations(\n  library = get_params(step = \"weight_annotations\")\\$files\\$libraries\\$sop\\$merged\\$keys,\n  org_tax_ott = get_params(step =\n    \"weight_annotations\")\\$files\\$libraries\\$sop\\$merged\\$organisms\\$taxonomies\\$ott,\n  str_stereo = get_params(step =\n    \"weight_annotations\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$stereo,\n  annotations = get_params(step = \"weight_annotations\")\\$files\\$annotations\\$filtered,\n  canopus = get_params(step = \"weight_annotations\")\\$files\\$annotations\\$prepared\\$canopus,\n  formula = get_params(step = \"weight_annotations\")\\$files\\$annotations\\$prepared\\$formula,\n  components = get_params(step =\n    \"weight_annotations\")\\$files\\$networks\\$spectral\\$components\\$prepared,\n  edges = get_params(step = \"weight_annotations\")\\$files\\$networks\\$spectral\\$edges\\$prepared,\n  taxa = get_params(step = \"weight_annotations\")\\$files\\$metadata\\$prepared,\n  output = get_params(step = \"weight_annotations\")\\$files\\$annotations\\$processed,\n  candidates_neighbors = get_params(step =\n    \"weight_annotations\")\\$annotations\\$candidates\\$neighbors,\n  candidates_final = get_params(step = \"weight_annotations\")\\$annotations\\$candidates\\$final,\n  weight_spectral = get_params(step = \"weight_annotations\")\\$weights\\$global\\$spectral,\n  weight_chemical = get_params(step = \"weight_annotations\")\\$weights\\$global\\$chemical,\n  weight_biological = get_params(step = \"weight_annotations\")\\$weights\\$global\\$biological,\n  score_biological_domain = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$domain,\n  score_biological_kingdom = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$kingdom,\n  score_biological_phylum = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$phylum,\n  score_biological_class = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$class,\n  score_biological_order = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$order,\n  score_biological_infraorder = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$infraorder,\n  score_biological_family = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$family,\n  score_biological_subfamily = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$subfamily,\n  score_biological_tribe = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$tribe,\n  score_biological_subtribe = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$subtribe,\n  score_biological_genus = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$genus,\n  score_biological_subgenus = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$subgenus,\n  score_biological_species = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$species,\n  score_biological_subspecies = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$subspecies,\n  score_biological_variety = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$variety,\n  score_chemical_cla_kingdom = get_params(step =\n    \"weight_annotations\")\\$weights\\$chemical\\$cla\\$kingdom,\n  score_chemical_cla_superclass = get_params(step =\n    \"weight_annotations\")\\$weights\\$chemical\\$cla\\$superclass,\n  score_chemical_cla_class = get_params(step =\n    \"weight_annotations\")\\$weights\\$chemical\\$cla\\$class,\n  score_chemical_cla_parent = get_params(step =\n    \"weight_annotations\")\\$weights\\$chemical\\$cla\\$parent,\n  score_chemical_npc_pathway = get_params(step =\n    \"weight_annotations\")\\$weights\\$chemical\\$npc\\$pathway,\n  score_chemical_npc_superclass = get_params(step =\n    \"weight_annotations\")\\$weights\\$chemical\\$npc\\$superclass,\n  score_chemical_npc_class = get_params(step =\n    \"weight_annotations\")\\$weights\\$chemical\\$npc\\$class,\n  minimal_consistency = get_params(step =\n    \"weight_annotations\")\\$annotations\\$thresholds\\$consistency,\n  minimal_ms1_bio = get_params(step =\n    \"weight_annotations\")\\$annotations\\$thresholds\\$ms1\\$biological,\n  minimal_ms1_chemo = get_params(step =\n    \"weight_annotations\")\\$annotations\\$thresholds\\$ms1\\$chemical,\n  minimal_ms1_condition = get_params(step =\n    \"weight_annotations\")\\$annotations\\$thresholds\\$ms1\\$condition,\n  ms1_only = get_params(step = \"weight_annotations\")\\$annotations\\$ms1only,\n  compounds_names = get_params(step = \"weight_annotations\")\\$options\\$compounds_names,\n  high_confidence = get_params(step = \"weight_annotations\")\\$options\\$high_confidence,\n  remove_ties = get_params(step = \"weight_annotations\")\\$options\\$remove_ties,\n  summarize = get_params(step = \"weight_annotations\")\\$options\\$summarize,\n  pattern = get_params(step = \"weight_annotations\")\\$files\\$pattern,\n  force = get_params(step = \"weight_annotations\")\\$options\\$force\n)\n\n\n\n\n\n\n\nlibrary\n\n\nLibrary containing the keys\n\n\n\n\norg_tax_ott\n\n\nFile containing organisms taxonomy (OTT)\n\n\n\n\nstr_stereo\n\n\nFile containing structures stereo\n\n\n\n\nannotations\n\n\nPrepared annotations file\n\n\n\n\ncanopus\n\n\nPrepared canopus file\n\n\n\n\nformula\n\n\nPrepared formula file\n\n\n\n\ncomponents\n\n\nPrepared components file\n\n\n\n\nedges\n\n\nPrepared edges file\n\n\n\n\ntaxa\n\n\nPrepared taxed features file\n\n\n\n\noutput\n\n\nOutput file\n\n\n\n\ncandidates_neighbors\n\n\nNumber of neighbors candidates to keep\n\n\n\n\ncandidates_final\n\n\nNumber of final candidates to keep\n\n\n\n\nweight_spectral\n\n\nWeight for the spectral score\n\n\n\n\nweight_chemical\n\n\nWeight for the biological score\n\n\n\n\nweight_biological\n\n\nWeight for the chemical consistency score\n\n\n\n\nscore_biological_domain\n\n\nScore for a domain match (should be lower than kingdom)\n\n\n\n\nscore_biological_kingdom\n\n\nScore for a kingdom match (should be lower than phylum)\n\n\n\n\nscore_biological_phylum\n\n\nScore for a phylum match (should be lower than class)\n\n\n\n\nscore_biological_class\n\n\nScore for a class match (should be lower than order)\n\n\n\n\nscore_biological_order\n\n\nScore for a order match (should be lower than infraorder)\n\n\n\n\nscore_biological_infraorder\n\n\nScore for a infraorder match (should be lower than order)\n\n\n\n\nscore_biological_family\n\n\nScore for a family match (should be lower than subfamily)\n\n\n\n\nscore_biological_subfamily\n\n\nScore for a subfamily match (should be lower than family)\n\n\n\n\nscore_biological_tribe\n\n\nScore for a tribe match (should be lower than subtribe)\n\n\n\n\nscore_biological_subtribe\n\n\nScore for a subtribe match (should be lower than genus)\n\n\n\n\nscore_biological_genus\n\n\nScore for a genus match (should be lower than subgenus)\n\n\n\n\nscore_biological_subgenus\n\n\nScore for a subgenus match (should be lower than species)\n\n\n\n\nscore_biological_species\n\n\nScore for a species match (should be lower than subspecies)\n\n\n\n\nscore_biological_subspecies\n\n\nScore for a subspecies match (should be lower than variety)\n\n\n\n\nscore_biological_variety\n\n\nScore for a variety match (should be the highest)\n\n\n\n\nscore_chemical_cla_kingdom\n\n\nScore for a Classyfire kingdom match (should be lower than  Classyfire superclass)\n\n\n\n\nscore_chemical_cla_superclass\n\n\nScore for a Classyfire superclass match (should be lower than Classyfire class)\n\n\n\n\nscore_chemical_cla_class\n\n\nScore for a Classyfire class match (should be lower than Classyfire parent)\n\n\n\n\nscore_chemical_cla_parent\n\n\nScore for a Classyfire parent match (should be the highest)\n\n\n\n\nscore_chemical_npc_pathway\n\n\nScore for a NPC pathway match (should be lower than  NPC superclass)\n\n\n\n\nscore_chemical_npc_superclass\n\n\nScore for a NPC superclass match (should be lower than NPC class)\n\n\n\n\nscore_chemical_npc_class\n\n\nScore for a NPC class match (should be the highest)\n\n\n\n\nminimal_consistency\n\n\nMinimal consistency score for a class. FLOAT\n\n\n\n\nminimal_ms1_bio\n\n\nMinimal biological score to keep MS1 based annotation\n\n\n\n\nminimal_ms1_chemo\n\n\nMinimal chemical score to keep MS1 based annotation\n\n\n\n\nminimal_ms1_condition\n\n\nCondition to be used. Must be \"OR\" or \"AND\".\n\n\n\n\nms1_only\n\n\nKeep only MS1 annotations. BOOLEAN\n\n\n\n\ncompounds_names\n\n\nReport compounds names. Can be very large. BOOLEAN\n\n\n\n\nhigh_confidence\n\n\nReport high confidence candidates only. BOOLEAN\n\n\n\n\nremove_ties\n\n\nRemove ties. BOOLEAN\n\n\n\n\nsummarize\n\n\nSummarize results (1 row per feature). BOOLEAN\n\n\n\n\npattern\n\n\nPattern to identify your job. STRING\n\n\n\n\nforce\n\n\nForce parameters. Use it at your own risk\n\n\n\n\n\n\nThe path to the weighted annotations\n\n\n\nannotate_masses weight_bio weight_chemo\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\ngithub &lt;- \"https://raw.githubusercontent.com/\"\nrepo &lt;- \"taxonomicallyinformedannotation/tima-example-files/main/\"\ndir &lt;- paste0(github, repo)\nlibrary &lt;- get_params(step = \"weight_annotations\")$files$libraries$sop$merged$keys |&gt;\n  gsub(\n    pattern = \".gz\",\n    replacement = \"\",\n    fixed = TRUE\n  )\norg_tax_ott &lt;- paste0(\n  \"data/interim/libraries/\",\n  \"sop/merged/organisms/taxonomies/ott.tsv\"\n)\nstr_stereo &lt;- paste0(\n  \"data/interim/libraries/\",\n  \"sop/merged/structures/stereo.tsv\"\n)\nannotations &lt;- paste0(\n  \"data/interim/annotations/\",\n  \"example_annotationsFiltered.tsv\"\n)\ncanopus &lt;- paste0(\n  \"data/interim/annotations/\",\n  \"example_canopusPrepared.tsv\"\n)\nformula &lt;- paste0(\n  \"data/interim/annotations/\",\n  \"example_formulaPrepared.tsv\"\n)\ncomponents &lt;- paste0(\n  \"data/interim/features/\",\n  \"example_componentsPrepared.tsv\"\n)\nedges &lt;- paste0(\n  \"data/interim/features/\",\n  \"example_edges.tsv\"\n)\ntaxa &lt;- paste0(\n  \"data/interim/taxa/\",\n  \"example_taxed.tsv\"\n)\nget_file(url = paste0(dir, library), export = library)\nget_file(url = paste0(dir, org_tax_ott), export = org_tax_ott)\nget_file(url = paste0(dir, str_stereo), export = str_stereo)\nget_file(url = paste0(dir, annotations), export = annotations)\nget_file(url = paste0(dir, canopus), export = canopus)\nget_file(url = paste0(dir, formula), export = formula)\nget_file(url = paste0(dir, components), export = components)\nget_file(url = paste0(dir, edges), export = edges)\nget_file(url = paste0(dir, taxa), export = taxa)\nweight_annotations(\n  library = library,\n  org_tax_ott = org_tax_ott,\n  str_stereo = str_stereo,\n  annotations = annotations,\n  canopus = canopus,\n  formula = formula,\n  components = components,\n  edges = edges,\n  taxa = taxa\n)\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/weight_annotations.html#weight-annotations",
    "href": "man/weight_annotations.html#weight-annotations",
    "title": "tima",
    "section": "",
    "text": "This function weights annotations.\n\n\n\nweight_annotations(\n  library = get_params(step = \"weight_annotations\")\\$files\\$libraries\\$sop\\$merged\\$keys,\n  org_tax_ott = get_params(step =\n    \"weight_annotations\")\\$files\\$libraries\\$sop\\$merged\\$organisms\\$taxonomies\\$ott,\n  str_stereo = get_params(step =\n    \"weight_annotations\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$stereo,\n  annotations = get_params(step = \"weight_annotations\")\\$files\\$annotations\\$filtered,\n  canopus = get_params(step = \"weight_annotations\")\\$files\\$annotations\\$prepared\\$canopus,\n  formula = get_params(step = \"weight_annotations\")\\$files\\$annotations\\$prepared\\$formula,\n  components = get_params(step =\n    \"weight_annotations\")\\$files\\$networks\\$spectral\\$components\\$prepared,\n  edges = get_params(step = \"weight_annotations\")\\$files\\$networks\\$spectral\\$edges\\$prepared,\n  taxa = get_params(step = \"weight_annotations\")\\$files\\$metadata\\$prepared,\n  output = get_params(step = \"weight_annotations\")\\$files\\$annotations\\$processed,\n  candidates_neighbors = get_params(step =\n    \"weight_annotations\")\\$annotations\\$candidates\\$neighbors,\n  candidates_final = get_params(step = \"weight_annotations\")\\$annotations\\$candidates\\$final,\n  weight_spectral = get_params(step = \"weight_annotations\")\\$weights\\$global\\$spectral,\n  weight_chemical = get_params(step = \"weight_annotations\")\\$weights\\$global\\$chemical,\n  weight_biological = get_params(step = \"weight_annotations\")\\$weights\\$global\\$biological,\n  score_biological_domain = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$domain,\n  score_biological_kingdom = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$kingdom,\n  score_biological_phylum = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$phylum,\n  score_biological_class = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$class,\n  score_biological_order = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$order,\n  score_biological_infraorder = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$infraorder,\n  score_biological_family = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$family,\n  score_biological_subfamily = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$subfamily,\n  score_biological_tribe = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$tribe,\n  score_biological_subtribe = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$subtribe,\n  score_biological_genus = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$genus,\n  score_biological_subgenus = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$subgenus,\n  score_biological_species = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$species,\n  score_biological_subspecies = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$subspecies,\n  score_biological_variety = get_params(step =\n    \"weight_annotations\")\\$weights\\$biological\\$variety,\n  score_chemical_cla_kingdom = get_params(step =\n    \"weight_annotations\")\\$weights\\$chemical\\$cla\\$kingdom,\n  score_chemical_cla_superclass = get_params(step =\n    \"weight_annotations\")\\$weights\\$chemical\\$cla\\$superclass,\n  score_chemical_cla_class = get_params(step =\n    \"weight_annotations\")\\$weights\\$chemical\\$cla\\$class,\n  score_chemical_cla_parent = get_params(step =\n    \"weight_annotations\")\\$weights\\$chemical\\$cla\\$parent,\n  score_chemical_npc_pathway = get_params(step =\n    \"weight_annotations\")\\$weights\\$chemical\\$npc\\$pathway,\n  score_chemical_npc_superclass = get_params(step =\n    \"weight_annotations\")\\$weights\\$chemical\\$npc\\$superclass,\n  score_chemical_npc_class = get_params(step =\n    \"weight_annotations\")\\$weights\\$chemical\\$npc\\$class,\n  minimal_consistency = get_params(step =\n    \"weight_annotations\")\\$annotations\\$thresholds\\$consistency,\n  minimal_ms1_bio = get_params(step =\n    \"weight_annotations\")\\$annotations\\$thresholds\\$ms1\\$biological,\n  minimal_ms1_chemo = get_params(step =\n    \"weight_annotations\")\\$annotations\\$thresholds\\$ms1\\$chemical,\n  minimal_ms1_condition = get_params(step =\n    \"weight_annotations\")\\$annotations\\$thresholds\\$ms1\\$condition,\n  ms1_only = get_params(step = \"weight_annotations\")\\$annotations\\$ms1only,\n  compounds_names = get_params(step = \"weight_annotations\")\\$options\\$compounds_names,\n  high_confidence = get_params(step = \"weight_annotations\")\\$options\\$high_confidence,\n  remove_ties = get_params(step = \"weight_annotations\")\\$options\\$remove_ties,\n  summarize = get_params(step = \"weight_annotations\")\\$options\\$summarize,\n  pattern = get_params(step = \"weight_annotations\")\\$files\\$pattern,\n  force = get_params(step = \"weight_annotations\")\\$options\\$force\n)\n\n\n\n\n\n\n\nlibrary\n\n\nLibrary containing the keys\n\n\n\n\norg_tax_ott\n\n\nFile containing organisms taxonomy (OTT)\n\n\n\n\nstr_stereo\n\n\nFile containing structures stereo\n\n\n\n\nannotations\n\n\nPrepared annotations file\n\n\n\n\ncanopus\n\n\nPrepared canopus file\n\n\n\n\nformula\n\n\nPrepared formula file\n\n\n\n\ncomponents\n\n\nPrepared components file\n\n\n\n\nedges\n\n\nPrepared edges file\n\n\n\n\ntaxa\n\n\nPrepared taxed features file\n\n\n\n\noutput\n\n\nOutput file\n\n\n\n\ncandidates_neighbors\n\n\nNumber of neighbors candidates to keep\n\n\n\n\ncandidates_final\n\n\nNumber of final candidates to keep\n\n\n\n\nweight_spectral\n\n\nWeight for the spectral score\n\n\n\n\nweight_chemical\n\n\nWeight for the biological score\n\n\n\n\nweight_biological\n\n\nWeight for the chemical consistency score\n\n\n\n\nscore_biological_domain\n\n\nScore for a domain match (should be lower than kingdom)\n\n\n\n\nscore_biological_kingdom\n\n\nScore for a kingdom match (should be lower than phylum)\n\n\n\n\nscore_biological_phylum\n\n\nScore for a phylum match (should be lower than class)\n\n\n\n\nscore_biological_class\n\n\nScore for a class match (should be lower than order)\n\n\n\n\nscore_biological_order\n\n\nScore for a order match (should be lower than infraorder)\n\n\n\n\nscore_biological_infraorder\n\n\nScore for a infraorder match (should be lower than order)\n\n\n\n\nscore_biological_family\n\n\nScore for a family match (should be lower than subfamily)\n\n\n\n\nscore_biological_subfamily\n\n\nScore for a subfamily match (should be lower than family)\n\n\n\n\nscore_biological_tribe\n\n\nScore for a tribe match (should be lower than subtribe)\n\n\n\n\nscore_biological_subtribe\n\n\nScore for a subtribe match (should be lower than genus)\n\n\n\n\nscore_biological_genus\n\n\nScore for a genus match (should be lower than subgenus)\n\n\n\n\nscore_biological_subgenus\n\n\nScore for a subgenus match (should be lower than species)\n\n\n\n\nscore_biological_species\n\n\nScore for a species match (should be lower than subspecies)\n\n\n\n\nscore_biological_subspecies\n\n\nScore for a subspecies match (should be lower than variety)\n\n\n\n\nscore_biological_variety\n\n\nScore for a variety match (should be the highest)\n\n\n\n\nscore_chemical_cla_kingdom\n\n\nScore for a Classyfire kingdom match (should be lower than  Classyfire superclass)\n\n\n\n\nscore_chemical_cla_superclass\n\n\nScore for a Classyfire superclass match (should be lower than Classyfire class)\n\n\n\n\nscore_chemical_cla_class\n\n\nScore for a Classyfire class match (should be lower than Classyfire parent)\n\n\n\n\nscore_chemical_cla_parent\n\n\nScore for a Classyfire parent match (should be the highest)\n\n\n\n\nscore_chemical_npc_pathway\n\n\nScore for a NPC pathway match (should be lower than  NPC superclass)\n\n\n\n\nscore_chemical_npc_superclass\n\n\nScore for a NPC superclass match (should be lower than NPC class)\n\n\n\n\nscore_chemical_npc_class\n\n\nScore for a NPC class match (should be the highest)\n\n\n\n\nminimal_consistency\n\n\nMinimal consistency score for a class. FLOAT\n\n\n\n\nminimal_ms1_bio\n\n\nMinimal biological score to keep MS1 based annotation\n\n\n\n\nminimal_ms1_chemo\n\n\nMinimal chemical score to keep MS1 based annotation\n\n\n\n\nminimal_ms1_condition\n\n\nCondition to be used. Must be \"OR\" or \"AND\".\n\n\n\n\nms1_only\n\n\nKeep only MS1 annotations. BOOLEAN\n\n\n\n\ncompounds_names\n\n\nReport compounds names. Can be very large. BOOLEAN\n\n\n\n\nhigh_confidence\n\n\nReport high confidence candidates only. BOOLEAN\n\n\n\n\nremove_ties\n\n\nRemove ties. BOOLEAN\n\n\n\n\nsummarize\n\n\nSummarize results (1 row per feature). BOOLEAN\n\n\n\n\npattern\n\n\nPattern to identify your job. STRING\n\n\n\n\nforce\n\n\nForce parameters. Use it at your own risk\n\n\n\n\n\n\nThe path to the weighted annotations\n\n\n\nannotate_masses weight_bio weight_chemo\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\ngithub &lt;- \"https://raw.githubusercontent.com/\"\nrepo &lt;- \"taxonomicallyinformedannotation/tima-example-files/main/\"\ndir &lt;- paste0(github, repo)\nlibrary &lt;- get_params(step = \"weight_annotations\")$files$libraries$sop$merged$keys |&gt;\n  gsub(\n    pattern = \".gz\",\n    replacement = \"\",\n    fixed = TRUE\n  )\norg_tax_ott &lt;- paste0(\n  \"data/interim/libraries/\",\n  \"sop/merged/organisms/taxonomies/ott.tsv\"\n)\nstr_stereo &lt;- paste0(\n  \"data/interim/libraries/\",\n  \"sop/merged/structures/stereo.tsv\"\n)\nannotations &lt;- paste0(\n  \"data/interim/annotations/\",\n  \"example_annotationsFiltered.tsv\"\n)\ncanopus &lt;- paste0(\n  \"data/interim/annotations/\",\n  \"example_canopusPrepared.tsv\"\n)\nformula &lt;- paste0(\n  \"data/interim/annotations/\",\n  \"example_formulaPrepared.tsv\"\n)\ncomponents &lt;- paste0(\n  \"data/interim/features/\",\n  \"example_componentsPrepared.tsv\"\n)\nedges &lt;- paste0(\n  \"data/interim/features/\",\n  \"example_edges.tsv\"\n)\ntaxa &lt;- paste0(\n  \"data/interim/taxa/\",\n  \"example_taxed.tsv\"\n)\nget_file(url = paste0(dir, library), export = library)\nget_file(url = paste0(dir, org_tax_ott), export = org_tax_ott)\nget_file(url = paste0(dir, str_stereo), export = str_stereo)\nget_file(url = paste0(dir, annotations), export = annotations)\nget_file(url = paste0(dir, canopus), export = canopus)\nget_file(url = paste0(dir, formula), export = formula)\nget_file(url = paste0(dir, components), export = components)\nget_file(url = paste0(dir, edges), export = edges)\nget_file(url = paste0(dir, taxa), export = taxa)\nweight_annotations(\n  library = library,\n  org_tax_ott = org_tax_ott,\n  str_stereo = str_stereo,\n  annotations = annotations,\n  canopus = canopus,\n  formula = formula,\n  components = components,\n  edges = edges,\n  taxa = taxa\n)\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/select_sirius_columns_structures.html",
    "href": "man/select_sirius_columns_structures.html",
    "title": "tima",
    "section": "",
    "text": "This function selects sirius columns (structures)\n\n\n\nselect_sirius_columns_structures(df, sirius_version)\n\n\n\n\n\n\n\ndf\n\n\nDataframe\n\n\n\n\nsirius_version\n\n\nSirius version\n\n\n\n\n\n\nThe dataframe with selected structure columns\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/select_sirius_columns_structures.html#select-sirius-columns-structures",
    "href": "man/select_sirius_columns_structures.html#select-sirius-columns-structures",
    "title": "tima",
    "section": "",
    "text": "This function selects sirius columns (structures)\n\n\n\nselect_sirius_columns_structures(df, sirius_version)\n\n\n\n\n\n\n\ndf\n\n\nDataframe\n\n\n\n\nsirius_version\n\n\nSirius version\n\n\n\n\n\n\nThe dataframe with selected structure columns\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/get_gnps_tables.html",
    "href": "man/get_gnps_tables.html",
    "title": "tima",
    "section": "",
    "text": "This function gets GNPS tables from corresponding job ID.\n\n\n\nget_gnps_tables(\n  gnps_job_id,\n  gnps_job_example = get_default_paths()\\$gnps\\$example,\n  filename,\n  workflow = \"fbmn\",\n  path_features,\n  path_metadata,\n  path_spectra,\n  path_source = get_default_paths()\\$data\\$source\\$path,\n  path_interim_a = get_default_paths()\\$data\\$interim\\$annotations\\$path,\n  path_interim_f = get_default_paths()\\$data\\$interim\\$features\\$path\n)\n\n\n\n\n\n\n\ngnps_job_id\n\n\nGNPS job ID\n\n\n\n\ngnps_job_example\n\n\nGNPS job example\n\n\n\n\nfilename\n\n\nName of the file\n\n\n\n\nworkflow\n\n\nCharacter string indicating the type of workflow, either \"fbmn\" or \"classical\"\n\n\n\n\npath_features\n\n\nPath to features\n\n\n\n\npath_metadata\n\n\nPath to metadata\n\n\n\n\npath_spectra\n\n\nPath to spectra\n\n\n\n\npath_source\n\n\nPath to store the source files\n\n\n\n\npath_interim_a\n\n\nPath to store the interim annotations file\n\n\n\n\npath_interim_f\n\n\nPath to store the interim features files\n\n\n\n\n\n\nThe downloaded GNPS tables\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/get_gnps_tables.html#get-gnps-tables",
    "href": "man/get_gnps_tables.html#get-gnps-tables",
    "title": "tima",
    "section": "",
    "text": "This function gets GNPS tables from corresponding job ID.\n\n\n\nget_gnps_tables(\n  gnps_job_id,\n  gnps_job_example = get_default_paths()\\$gnps\\$example,\n  filename,\n  workflow = \"fbmn\",\n  path_features,\n  path_metadata,\n  path_spectra,\n  path_source = get_default_paths()\\$data\\$source\\$path,\n  path_interim_a = get_default_paths()\\$data\\$interim\\$annotations\\$path,\n  path_interim_f = get_default_paths()\\$data\\$interim\\$features\\$path\n)\n\n\n\n\n\n\n\ngnps_job_id\n\n\nGNPS job ID\n\n\n\n\ngnps_job_example\n\n\nGNPS job example\n\n\n\n\nfilename\n\n\nName of the file\n\n\n\n\nworkflow\n\n\nCharacter string indicating the type of workflow, either \"fbmn\" or \"classical\"\n\n\n\n\npath_features\n\n\nPath to features\n\n\n\n\npath_metadata\n\n\nPath to metadata\n\n\n\n\npath_spectra\n\n\nPath to spectra\n\n\n\n\npath_source\n\n\nPath to store the source files\n\n\n\n\npath_interim_a\n\n\nPath to store the interim annotations file\n\n\n\n\npath_interim_f\n\n\nPath to store the interim features files\n\n\n\n\n\n\nThe downloaded GNPS tables\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/get_organism_taxonomy_ott.html",
    "href": "man/get_organism_taxonomy_ott.html",
    "title": "tima",
    "section": "",
    "text": "This function retrieves taxonomy from the Open Tree of Life taxonomy\n\n\n\nget_organism_taxonomy_ott(\n  df,\n  url = \"https://api.opentreeoflife.org/v3/taxonomy/about\",\n  retry = TRUE\n)\n\n\n\n\n\n\n\ndf\n\n\nDataframe containing your organism(s) name(s)\n\n\n\n\nurl\n\n\nurl of the ott api (for testing purposes)\n\n\n\n\nretry\n\n\nBoolean. Retry with generic epithet\n\n\n\n\n\n\nThe path to the obtained OTT taxonomy\n\n\n\n\nlibrary(\"tima\")\n\ndf &lt;- data.frame(\"organism\" = \"Homo sapiens\")\nget_organism_taxonomy_ott(df)"
  },
  {
    "objectID": "man/get_organism_taxonomy_ott.html#get-organism-taxonomy-open-tree-of-life-taxonomy",
    "href": "man/get_organism_taxonomy_ott.html#get-organism-taxonomy-open-tree-of-life-taxonomy",
    "title": "tima",
    "section": "",
    "text": "This function retrieves taxonomy from the Open Tree of Life taxonomy\n\n\n\nget_organism_taxonomy_ott(\n  df,\n  url = \"https://api.opentreeoflife.org/v3/taxonomy/about\",\n  retry = TRUE\n)\n\n\n\n\n\n\n\ndf\n\n\nDataframe containing your organism(s) name(s)\n\n\n\n\nurl\n\n\nurl of the ott api (for testing purposes)\n\n\n\n\nretry\n\n\nBoolean. Retry with generic epithet\n\n\n\n\n\n\nThe path to the obtained OTT taxonomy\n\n\n\n\nlibrary(\"tima\")\n\ndf &lt;- data.frame(\"organism\" = \"Homo sapiens\")\nget_organism_taxonomy_ott(df)"
  },
  {
    "objectID": "man/weight_bio.html",
    "href": "man/weight_bio.html",
    "title": "tima",
    "section": "",
    "text": "This function weights the eventually MS1 complemented annotations according their biological source\n\n\n\nweight_bio(\n  annotation_table_taxed = get(\"annotation_table_taxed\", envir = parent.frame()),\n  structure_organism_pairs_table = get(\"structure_organism_pairs_table\", envir =\n    parent.frame()),\n  weight_spectral = get(\"weight_spectral\", envir = parent.frame()),\n  weight_biological = get(\"weight_biological\", envir = parent.frame()),\n  score_biological_domain = get(\"score_biological_domain\", envir = parent.frame()),\n  score_biological_kingdom = get(\"score_biological_kingdom\", envir = parent.frame()),\n  score_biological_phylum = get(\"score_biological_phylum\", envir = parent.frame()),\n  score_biological_class = get(\"score_biological_class\", envir = parent.frame()),\n  score_biological_order = get(\"score_biological_order\", envir = parent.frame()),\n  score_biological_family = get(\"score_biological_family\", envir = parent.frame()),\n  score_biological_tribe = get(\"score_biological_tribe\", envir = parent.frame()),\n  score_biological_genus = get(\"score_biological_genus\", envir = parent.frame()),\n  score_biological_species = get(\"score_biological_species\", envir = parent.frame()),\n  score_biological_variety = get(\"score_biological_variety\", envir = parent.frame())\n)\n\n\n\n\n\n\n\nannotation_table_taxed\n\n\nTable containing the initial annotation eventually complemented by additional MS1 annotations\n\n\n\n\nstructure_organism_pairs_table\n\n\nTable containing the structure - organism pairs\n\n\n\n\nweight_spectral\n\n\nWeight for the spectral score\n\n\n\n\nweight_biological\n\n\nWeight for the biological score\n\n\n\n\nscore_biological_domain\n\n\nScore for a domain match (should be lower than kingdom)\n\n\n\n\nscore_biological_kingdom\n\n\nScore for a kingdom match (should be lower than phylum)\n\n\n\n\nscore_biological_phylum\n\n\nScore for a phylum match (should be lower than class)\n\n\n\n\nscore_biological_class\n\n\nScore for a class match (should be lower than order)\n\n\n\n\nscore_biological_order\n\n\nScore for a order match (should be lower than family)\n\n\n\n\nscore_biological_family\n\n\nScore for a family match (should be lower than tribe)\n\n\n\n\nscore_biological_tribe\n\n\nScore for a tribe match (should be lower than genus)\n\n\n\n\nscore_biological_genus\n\n\nScore for a genus match (should be lower than species)\n\n\n\n\nscore_biological_species\n\n\nScore for a species match (should be lower than variety)\n\n\n\n\nscore_biological_variety\n\n\nScore for a variety match (should be the highest)\n\n\n\n\n\n\nA table containing the biologically weighted annotation\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/weight_bio.html#weight-bio",
    "href": "man/weight_bio.html#weight-bio",
    "title": "tima",
    "section": "",
    "text": "This function weights the eventually MS1 complemented annotations according their biological source\n\n\n\nweight_bio(\n  annotation_table_taxed = get(\"annotation_table_taxed\", envir = parent.frame()),\n  structure_organism_pairs_table = get(\"structure_organism_pairs_table\", envir =\n    parent.frame()),\n  weight_spectral = get(\"weight_spectral\", envir = parent.frame()),\n  weight_biological = get(\"weight_biological\", envir = parent.frame()),\n  score_biological_domain = get(\"score_biological_domain\", envir = parent.frame()),\n  score_biological_kingdom = get(\"score_biological_kingdom\", envir = parent.frame()),\n  score_biological_phylum = get(\"score_biological_phylum\", envir = parent.frame()),\n  score_biological_class = get(\"score_biological_class\", envir = parent.frame()),\n  score_biological_order = get(\"score_biological_order\", envir = parent.frame()),\n  score_biological_family = get(\"score_biological_family\", envir = parent.frame()),\n  score_biological_tribe = get(\"score_biological_tribe\", envir = parent.frame()),\n  score_biological_genus = get(\"score_biological_genus\", envir = parent.frame()),\n  score_biological_species = get(\"score_biological_species\", envir = parent.frame()),\n  score_biological_variety = get(\"score_biological_variety\", envir = parent.frame())\n)\n\n\n\n\n\n\n\nannotation_table_taxed\n\n\nTable containing the initial annotation eventually complemented by additional MS1 annotations\n\n\n\n\nstructure_organism_pairs_table\n\n\nTable containing the structure - organism pairs\n\n\n\n\nweight_spectral\n\n\nWeight for the spectral score\n\n\n\n\nweight_biological\n\n\nWeight for the biological score\n\n\n\n\nscore_biological_domain\n\n\nScore for a domain match (should be lower than kingdom)\n\n\n\n\nscore_biological_kingdom\n\n\nScore for a kingdom match (should be lower than phylum)\n\n\n\n\nscore_biological_phylum\n\n\nScore for a phylum match (should be lower than class)\n\n\n\n\nscore_biological_class\n\n\nScore for a class match (should be lower than order)\n\n\n\n\nscore_biological_order\n\n\nScore for a order match (should be lower than family)\n\n\n\n\nscore_biological_family\n\n\nScore for a family match (should be lower than tribe)\n\n\n\n\nscore_biological_tribe\n\n\nScore for a tribe match (should be lower than genus)\n\n\n\n\nscore_biological_genus\n\n\nScore for a genus match (should be lower than species)\n\n\n\n\nscore_biological_species\n\n\nScore for a species match (should be lower than variety)\n\n\n\n\nscore_biological_variety\n\n\nScore for a variety match (should be the highest)\n\n\n\n\n\n\nA table containing the biologically weighted annotation\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/prepare_libraries_rt.html",
    "href": "man/prepare_libraries_rt.html",
    "title": "tima",
    "section": "",
    "text": "This function prepares retention times libraries to be used for later\n\n\n\nprepare_libraries_rt(\n  mgf_exp = get_params(step = \"prepare_libraries_rt\")\\$files\\$libraries\\$temporal\\$exp\\$mgf,\n  mgf_is = get_params(step = \"prepare_libraries_rt\")\\$files\\$libraries\\$temporal\\$is\\$mgf,\n  temp_exp = get_params(step = \"prepare_libraries_rt\")\\$files\\$libraries\\$temporal\\$exp\\$csv,\n  temp_is = get_params(step = \"prepare_libraries_rt\")\\$files\\$libraries\\$temporal\\$is\\$csv,\n  output_rt = get_params(step = \"prepare_libraries_rt\")\\$files\\$libraries\\$temporal\\$prepared,\n  output_sop = get_params(step = \"prepare_libraries_rt\")\\$files\\$libraries\\$sop\\$prepared\\$rt,\n  col_ik = get_params(step = \"prepare_libraries_rt\")\\$names\\$mgf\\$inchikey,\n  col_rt = get_params(step = \"prepare_libraries_rt\")\\$names\\$mgf\\$retention_time,\n  col_sm = get_params(step = \"prepare_libraries_rt\")\\$names\\$mgf\\$smiles,\n  name_inchikey = get_params(step = \"prepare_libraries_rt\")\\$names\\$inchikey,\n  name_rt = get_params(step = \"prepare_libraries_rt\")\\$names\\$rt\\$library,\n  name_smiles = get_params(step = \"prepare_libraries_rt\")\\$names\\$smiles,\n  unit_rt = get_params(step = \"prepare_libraries_rt\")\\$units\\$rt\n)\n\n\n\n\n\n\n\nmgf_exp\n\n\nMGF containing experimental retention times\n\n\n\n\nmgf_is\n\n\nMGF containing in silico predicted retention times\n\n\n\n\ntemp_exp\n\n\nFile containing experimental retention times\n\n\n\n\ntemp_is\n\n\nFile containing in silico predicted retention times\n\n\n\n\noutput_rt\n\n\nOutput retention time file\n\n\n\n\noutput_sop\n\n\nOutput pseudo sop file\n\n\n\n\ncol_ik\n\n\nName of the InChIKey in mgf\n\n\n\n\ncol_rt\n\n\nName of the retention time in mgf\n\n\n\n\ncol_sm\n\n\nName of the SMILES in mgf\n\n\n\n\nname_inchikey\n\n\nName of the InChIKey in file\n\n\n\n\nname_rt\n\n\nName of the retention time in file\n\n\n\n\nname_smiles\n\n\nName of the SMILES in file\n\n\n\n\nunit_rt\n\n\nUnit of the retention time. Must be \"seconds\" or \"minutes\"\n\n\n\n\n\n\nThe path to the prepared retention time library\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\nprepare_libraries_rt()\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/prepare_libraries_rt.html#prepare-libraries-of-retention-times",
    "href": "man/prepare_libraries_rt.html#prepare-libraries-of-retention-times",
    "title": "tima",
    "section": "",
    "text": "This function prepares retention times libraries to be used for later\n\n\n\nprepare_libraries_rt(\n  mgf_exp = get_params(step = \"prepare_libraries_rt\")\\$files\\$libraries\\$temporal\\$exp\\$mgf,\n  mgf_is = get_params(step = \"prepare_libraries_rt\")\\$files\\$libraries\\$temporal\\$is\\$mgf,\n  temp_exp = get_params(step = \"prepare_libraries_rt\")\\$files\\$libraries\\$temporal\\$exp\\$csv,\n  temp_is = get_params(step = \"prepare_libraries_rt\")\\$files\\$libraries\\$temporal\\$is\\$csv,\n  output_rt = get_params(step = \"prepare_libraries_rt\")\\$files\\$libraries\\$temporal\\$prepared,\n  output_sop = get_params(step = \"prepare_libraries_rt\")\\$files\\$libraries\\$sop\\$prepared\\$rt,\n  col_ik = get_params(step = \"prepare_libraries_rt\")\\$names\\$mgf\\$inchikey,\n  col_rt = get_params(step = \"prepare_libraries_rt\")\\$names\\$mgf\\$retention_time,\n  col_sm = get_params(step = \"prepare_libraries_rt\")\\$names\\$mgf\\$smiles,\n  name_inchikey = get_params(step = \"prepare_libraries_rt\")\\$names\\$inchikey,\n  name_rt = get_params(step = \"prepare_libraries_rt\")\\$names\\$rt\\$library,\n  name_smiles = get_params(step = \"prepare_libraries_rt\")\\$names\\$smiles,\n  unit_rt = get_params(step = \"prepare_libraries_rt\")\\$units\\$rt\n)\n\n\n\n\n\n\n\nmgf_exp\n\n\nMGF containing experimental retention times\n\n\n\n\nmgf_is\n\n\nMGF containing in silico predicted retention times\n\n\n\n\ntemp_exp\n\n\nFile containing experimental retention times\n\n\n\n\ntemp_is\n\n\nFile containing in silico predicted retention times\n\n\n\n\noutput_rt\n\n\nOutput retention time file\n\n\n\n\noutput_sop\n\n\nOutput pseudo sop file\n\n\n\n\ncol_ik\n\n\nName of the InChIKey in mgf\n\n\n\n\ncol_rt\n\n\nName of the retention time in mgf\n\n\n\n\ncol_sm\n\n\nName of the SMILES in mgf\n\n\n\n\nname_inchikey\n\n\nName of the InChIKey in file\n\n\n\n\nname_rt\n\n\nName of the retention time in file\n\n\n\n\nname_smiles\n\n\nName of the SMILES in file\n\n\n\n\nunit_rt\n\n\nUnit of the retention time. Must be \"seconds\" or \"minutes\"\n\n\n\n\n\n\nThe path to the prepared retention time library\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\nprepare_libraries_rt()\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/decorate_chemo.html",
    "href": "man/decorate_chemo.html",
    "title": "tima",
    "section": "",
    "text": "This function outputs information about chemical weighting\n\n\n\ndecorate_chemo(\n  annot_table_wei_chemo = get(\"annot_table_wei_chemo\", envir = parent.frame()),\n  score_chemical_cla_kingdom = get(\"score_chemical_cla_kingdom\", envir = parent.frame()),\n  score_chemical_cla_superclass = get(\"score_chemical_cla_superclass\", envir =\n    parent.frame()),\n  score_chemical_cla_class = get(\"score_chemical_cla_class\", envir = parent.frame()),\n  score_chemical_cla_parent = get(\"score_chemical_cla_parent\", envir = parent.frame()),\n  score_chemical_npc_pathway = get(\"score_chemical_npc_pathway\", envir = parent.frame()),\n  score_chemical_npc_superclass = get(\"score_chemical_npc_superclass\", envir =\n    parent.frame()),\n  score_chemical_npc_class = get(\"score_chemical_npc_class\", envir = parent.frame())\n)\n\n\n\n\n\n\n\nannot_table_wei_chemo\n\n\nTable to decorate\n\n\n\n\nscore_chemical_cla_kingdom\n\n\nClassyfire kingdom score\n\n\n\n\nscore_chemical_cla_superclass\n\n\nClassyfire superclass score\n\n\n\n\nscore_chemical_cla_class\n\n\nClassyfire class score\n\n\n\n\nscore_chemical_cla_parent\n\n\nClassyfire parent score\n\n\n\n\nscore_chemical_npc_pathway\n\n\nNPC pathway score\n\n\n\n\nscore_chemical_npc_superclass\n\n\nNPC superclass score\n\n\n\n\nscore_chemical_npc_class\n\n\nNPC class score\n\n\n\n\n\n\nMessage indicating the number of annotations weighted at each chemical level\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/decorate_chemo.html#decorate-chemo",
    "href": "man/decorate_chemo.html#decorate-chemo",
    "title": "tima",
    "section": "",
    "text": "This function outputs information about chemical weighting\n\n\n\ndecorate_chemo(\n  annot_table_wei_chemo = get(\"annot_table_wei_chemo\", envir = parent.frame()),\n  score_chemical_cla_kingdom = get(\"score_chemical_cla_kingdom\", envir = parent.frame()),\n  score_chemical_cla_superclass = get(\"score_chemical_cla_superclass\", envir =\n    parent.frame()),\n  score_chemical_cla_class = get(\"score_chemical_cla_class\", envir = parent.frame()),\n  score_chemical_cla_parent = get(\"score_chemical_cla_parent\", envir = parent.frame()),\n  score_chemical_npc_pathway = get(\"score_chemical_npc_pathway\", envir = parent.frame()),\n  score_chemical_npc_superclass = get(\"score_chemical_npc_superclass\", envir =\n    parent.frame()),\n  score_chemical_npc_class = get(\"score_chemical_npc_class\", envir = parent.frame())\n)\n\n\n\n\n\n\n\nannot_table_wei_chemo\n\n\nTable to decorate\n\n\n\n\nscore_chemical_cla_kingdom\n\n\nClassyfire kingdom score\n\n\n\n\nscore_chemical_cla_superclass\n\n\nClassyfire superclass score\n\n\n\n\nscore_chemical_cla_class\n\n\nClassyfire class score\n\n\n\n\nscore_chemical_cla_parent\n\n\nClassyfire parent score\n\n\n\n\nscore_chemical_npc_pathway\n\n\nNPC pathway score\n\n\n\n\nscore_chemical_npc_superclass\n\n\nNPC superclass score\n\n\n\n\nscore_chemical_npc_class\n\n\nNPC class score\n\n\n\n\n\n\nMessage indicating the number of annotations weighted at each chemical level\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/filter_high_confidence_only.html",
    "href": "man/filter_high_confidence_only.html",
    "title": "tima",
    "section": "",
    "text": "Filter high confidence only \n\nDescription\nThis function filters highly confident annotations only.\n\n\nUsage\nfilter_high_confidence_only(\n  df,\n  score_bio_min = 0.85,\n  score_ini_min = 0.95,\n  score_final_min = 0.75,\n  error_rt_max = 0.1\n)\n\n\n\nArguments\n\n\n\ndf\n\n\nDataframe\n\n\n\n\nscore_bio_min\n\n\nMinimal biological score. Current default to 0.85.\n\n\n\n\nscore_ini_min\n\n\nMinimal initial score. Current default to 0.95.\n\n\n\n\nscore_final_min\n\n\nMinimal final score. Current default to 0.75.\n\n\n\n\nerror_rt_max\n\n\nMaximal RT error. Current default to 0.1.\n\n\n\n\n\nValue\nA dataframe containing only high confidence annotations\n\n\nExamples\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/export_params.html",
    "href": "man/export_params.html",
    "title": "tima",
    "section": "",
    "text": "This function writes the parameters to a YAML file in the specified directory.\n\n\n\nexport_params(\n  parameters = get(\"parameters\", envir = parent.frame()),\n  directory = get_default_paths()\\$data\\$interim\\$params\\$path,\n  step\n)\n\n\n\n\n\n\n\nparameters\n\n\nlist of parameters to be exported\n\n\n\n\ndirectory\n\n\ndirectory where the YAML file will be saved\n\n\n\n\nstep\n\n\nstep identifier to be included in the YAML file name\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/export_params.html#export-parameters",
    "href": "man/export_params.html#export-parameters",
    "title": "tima",
    "section": "",
    "text": "This function writes the parameters to a YAML file in the specified directory.\n\n\n\nexport_params(\n  parameters = get(\"parameters\", envir = parent.frame()),\n  directory = get_default_paths()\\$data\\$interim\\$params\\$path,\n  step\n)\n\n\n\n\n\n\n\nparameters\n\n\nlist of parameters to be exported\n\n\n\n\ndirectory\n\n\ndirectory where the YAML file will be saved\n\n\n\n\nstep\n\n\nstep identifier to be included in the YAML file name\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/dist_groups.html",
    "href": "man/dist_groups.html",
    "title": "tima",
    "section": "",
    "text": "This function gets distances per group\n\n\n\ndist_groups(d, g)\n\n\n\n\n\n\n\nd\n\n\nA distance object\n\n\n\n\ng\n\n\nA grouping vector for the distance object\n\n\n\n\n\n\nA data frame containing distance information between pairs of observations in the distance object, with columns for the names or indices of the observations, the group labels for each observation, and the distance between the observations. The label column indicates whether the distance is within a group or between groups.\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/dist_groups.html#dist-groups",
    "href": "man/dist_groups.html#dist-groups",
    "title": "tima",
    "section": "",
    "text": "This function gets distances per group\n\n\n\ndist_groups(d, g)\n\n\n\n\n\n\n\nd\n\n\nA distance object\n\n\n\n\ng\n\n\nA grouping vector for the distance object\n\n\n\n\n\n\nA data frame containing distance information between pairs of observations in the distance object, with columns for the names or indices of the observations, the group labels for each observation, and the distance between the observations. The label column indicates whether the distance is within a group or between groups.\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/annotate_spectra.html",
    "href": "man/annotate_spectra.html",
    "title": "tima",
    "section": "",
    "text": "This function annotates spectra\n\n\n\nannotate_spectra(\n  input = get_params(step = \"annotate_spectra\")\\$files\\$spectral\\$raw,\n  libraries = get_params(step = \"annotate_spectra\")\\$files\\$libraries\\$spectral,\n  polarity = get_params(step = \"annotate_spectra\")\\$ms\\$polarity,\n  output = get_params(step = \"annotate_spectra\")\\$files\\$annotations\\$raw\\$spectral\\$spectral,\n  method = get_params(step = \"annotate_spectra\")\\$similarities\\$methods\\$annotations,\n  threshold = get_params(step = \"annotate_spectra\")\\$similarities\\$thresholds\\$annotations,\n  ppm = get_params(step = \"annotate_spectra\")\\$ms\\$tolerances\\$mass\\$ppm\\$ms2,\n  dalton = get_params(step = \"annotate_spectra\")\\$ms\\$tolerances\\$mass\\$dalton\\$ms2,\n  qutoff = get_params(step = \"annotate_spectra\")\\$ms\\$thresholds\\$ms2\\$intensity,\n  approx = get_params(step = \"annotate_spectra\")\\$annotations\\$ms2approx\n)\n\n\n\n\n\n\n\ninput\n\n\nQuery file containing spectra. Currently an ‘.mgf’ file\n\n\n\n\nlibraries\n\n\nLibraries containing spectra to match against. Can be ‘.mgf’ or ‘.sqlite’ (Spectra formatted)\n\n\n\n\npolarity\n\n\nMS polarity. Must be ‘pos’ or ‘neg’.\n\n\n\n\noutput\n\n\nOutput file.\n\n\n\n\nmethod\n\n\nSimilarity method\n\n\n\n\nthreshold\n\n\nMinimal similarity to report\n\n\n\n\nppm\n\n\nRelative ppm tolerance to be used\n\n\n\n\ndalton\n\n\nAbsolute Dalton tolerance to be used\n\n\n\n\nqutoff\n\n\nIntensity under which ms2 fragments will be removed.\n\n\n\n\napprox\n\n\nPerform matching without precursor match\n\n\n\n\n\n\nIt takes two files as input. A query file that will be matched against a library file.\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\nget_file(\n  url = get_default_paths()$urls$examples$spectra_mini,\n  export = get_params(step = \"annotate_spectra\")$files$spectral$raw\n)\nget_file(\n  url = get_default_paths()$urls$examples$spectral_lib_mini$with_rt,\n  export = get_default_paths()$data$source$libraries$spectra$exp$with_rt\n)\nannotate_spectra(\n  libraries = get_default_paths()$data$source$libraries$spectra$exp$with_rt\n)\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/annotate_spectra.html#annotate-spectra",
    "href": "man/annotate_spectra.html#annotate-spectra",
    "title": "tima",
    "section": "",
    "text": "This function annotates spectra\n\n\n\nannotate_spectra(\n  input = get_params(step = \"annotate_spectra\")\\$files\\$spectral\\$raw,\n  libraries = get_params(step = \"annotate_spectra\")\\$files\\$libraries\\$spectral,\n  polarity = get_params(step = \"annotate_spectra\")\\$ms\\$polarity,\n  output = get_params(step = \"annotate_spectra\")\\$files\\$annotations\\$raw\\$spectral\\$spectral,\n  method = get_params(step = \"annotate_spectra\")\\$similarities\\$methods\\$annotations,\n  threshold = get_params(step = \"annotate_spectra\")\\$similarities\\$thresholds\\$annotations,\n  ppm = get_params(step = \"annotate_spectra\")\\$ms\\$tolerances\\$mass\\$ppm\\$ms2,\n  dalton = get_params(step = \"annotate_spectra\")\\$ms\\$tolerances\\$mass\\$dalton\\$ms2,\n  qutoff = get_params(step = \"annotate_spectra\")\\$ms\\$thresholds\\$ms2\\$intensity,\n  approx = get_params(step = \"annotate_spectra\")\\$annotations\\$ms2approx\n)\n\n\n\n\n\n\n\ninput\n\n\nQuery file containing spectra. Currently an ‘.mgf’ file\n\n\n\n\nlibraries\n\n\nLibraries containing spectra to match against. Can be ‘.mgf’ or ‘.sqlite’ (Spectra formatted)\n\n\n\n\npolarity\n\n\nMS polarity. Must be ‘pos’ or ‘neg’.\n\n\n\n\noutput\n\n\nOutput file.\n\n\n\n\nmethod\n\n\nSimilarity method\n\n\n\n\nthreshold\n\n\nMinimal similarity to report\n\n\n\n\nppm\n\n\nRelative ppm tolerance to be used\n\n\n\n\ndalton\n\n\nAbsolute Dalton tolerance to be used\n\n\n\n\nqutoff\n\n\nIntensity under which ms2 fragments will be removed.\n\n\n\n\napprox\n\n\nPerform matching without precursor match\n\n\n\n\n\n\nIt takes two files as input. A query file that will be matched against a library file.\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\nget_file(\n  url = get_default_paths()$urls$examples$spectra_mini,\n  export = get_params(step = \"annotate_spectra\")$files$spectral$raw\n)\nget_file(\n  url = get_default_paths()$urls$examples$spectral_lib_mini$with_rt,\n  export = get_default_paths()$data$source$libraries$spectra$exp$with_rt\n)\nannotate_spectra(\n  libraries = get_default_paths()$data$source$libraries$spectra$exp$with_rt\n)\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/prepare_features_tables.html",
    "href": "man/prepare_features_tables.html",
    "title": "tima",
    "section": "",
    "text": "This function prepares features\n\n\n\nprepare_features_tables(\n  features = get_params(step = \"prepare_features_tables\")\\$files\\$features\\$raw,\n  output = get_params(step = \"prepare_features_tables\")\\$files\\$features\\$prepared,\n  candidates = get_params(step = \"prepare_features_tables\")\\$annotations\\$canidates\\$samples,\n  name_adduct = get_params(step = \"prepare_features_tables\")\\$names\\$adduct,\n  name_features = get_params(step = \"prepare_features_tables\")\\$names\\$features,\n  name_rt = get_params(step = \"prepare_features_tables\")\\$names\\$rt\\$features,\n  name_mz = get_params(step = \"prepare_features_tables\")\\$names\\$precursor\n)\n\n\n\n\n\n\n\nfeatures\n\n\nPath to the file containing the features data\n\n\n\n\noutput\n\n\nPath to the file to export the merged data to\n\n\n\n\ncandidates\n\n\nNumber of samples to be retained per feature top intensities\n\n\n\n\nname_adduct\n\n\nName of the adduct column in the features data\n\n\n\n\nname_features\n\n\nName of the features column in the features data\n\n\n\n\nname_rt\n\n\nName of the retention time column in the features data\n\n\n\n\nname_mz\n\n\nName of the m/z column in the features data\n\n\n\n\n\n\nThe path to the prepared feature table\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\nget_file(\n  url = get_default_paths()$urls$examples$features,\n  export = get_params(step = \"prepare_features_tables\")$files$features$raw\n)\nprepare_features_tables()\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/prepare_features_tables.html#prepare-features-table",
    "href": "man/prepare_features_tables.html#prepare-features-table",
    "title": "tima",
    "section": "",
    "text": "This function prepares features\n\n\n\nprepare_features_tables(\n  features = get_params(step = \"prepare_features_tables\")\\$files\\$features\\$raw,\n  output = get_params(step = \"prepare_features_tables\")\\$files\\$features\\$prepared,\n  candidates = get_params(step = \"prepare_features_tables\")\\$annotations\\$canidates\\$samples,\n  name_adduct = get_params(step = \"prepare_features_tables\")\\$names\\$adduct,\n  name_features = get_params(step = \"prepare_features_tables\")\\$names\\$features,\n  name_rt = get_params(step = \"prepare_features_tables\")\\$names\\$rt\\$features,\n  name_mz = get_params(step = \"prepare_features_tables\")\\$names\\$precursor\n)\n\n\n\n\n\n\n\nfeatures\n\n\nPath to the file containing the features data\n\n\n\n\noutput\n\n\nPath to the file to export the merged data to\n\n\n\n\ncandidates\n\n\nNumber of samples to be retained per feature top intensities\n\n\n\n\nname_adduct\n\n\nName of the adduct column in the features data\n\n\n\n\nname_features\n\n\nName of the features column in the features data\n\n\n\n\nname_rt\n\n\nName of the retention time column in the features data\n\n\n\n\nname_mz\n\n\nName of the m/z column in the features data\n\n\n\n\n\n\nThe path to the prepared feature table\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\nget_file(\n  url = get_default_paths()$urls$examples$features,\n  export = get_params(step = \"prepare_features_tables\")$files$features$raw\n)\nprepare_features_tables()\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/sanitize_spectra.html",
    "href": "man/sanitize_spectra.html",
    "title": "tima",
    "section": "",
    "text": "This function sanitizes spectra\n\n\n\nsanitize_spectra(spectra, cutoff = 0, dalton = 0.01, ppm = 10)\n\n\n\n\n\n\n\nspectra\n\n\nSpectra object\n\n\n\n\ncutoff\n\n\nAbsolute minimal intensity\n\n\n\n\ndalton\n\n\nDalton tolerance\n\n\n\n\nppm\n\n\nPPM tolerance\n\n\n\n\n\n\nThe sanitized spectra\n\n\n\n\nlibrary(\"tima\")\n\ndata.frame(\n  FEATURE_ID = c(\"FT001\", \"FT002\", \"FT003\"),\n  mz = c(list(123.4567, 234.5678, 345.6789))\n) |&gt;\n  Spectra::Spectra() |&gt;\n  sanitize_spectra()"
  },
  {
    "objectID": "man/sanitize_spectra.html#sanitize-spectra",
    "href": "man/sanitize_spectra.html#sanitize-spectra",
    "title": "tima",
    "section": "",
    "text": "This function sanitizes spectra\n\n\n\nsanitize_spectra(spectra, cutoff = 0, dalton = 0.01, ppm = 10)\n\n\n\n\n\n\n\nspectra\n\n\nSpectra object\n\n\n\n\ncutoff\n\n\nAbsolute minimal intensity\n\n\n\n\ndalton\n\n\nDalton tolerance\n\n\n\n\nppm\n\n\nPPM tolerance\n\n\n\n\n\n\nThe sanitized spectra\n\n\n\n\nlibrary(\"tima\")\n\ndata.frame(\n  FEATURE_ID = c(\"FT001\", \"FT002\", \"FT003\"),\n  mz = c(list(123.4567, 234.5678, 345.6789))\n) |&gt;\n  Spectra::Spectra() |&gt;\n  sanitize_spectra()"
  },
  {
    "objectID": "man/minimize_results.html",
    "href": "man/minimize_results.html",
    "title": "tima",
    "section": "",
    "text": "This function minimizes results\n\n\n\nminimize_results(\n  df,\n  features_table,\n  min_score_classes = 0.6,\n  min_score_compounds = 0.4,\n  best_percentile = 0.9\n)\n\n\n\n\n\n\n\ndf\n\n\nDataframe\n\n\n\n\nfeatures_table\n\n\nPrepared features file\n\n\n\n\nmin_score_classes\n\n\nMinimal score to keep classes\n\n\n\n\nmin_score_compounds\n\n\nMinimal score to keep compounds\n\n\n\n\nbest_percentile\n\n\nBest percentile\n\n\n\n\n\n\nA minimized table\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/minimize_results.html#minimize-results",
    "href": "man/minimize_results.html#minimize-results",
    "title": "tima",
    "section": "",
    "text": "This function minimizes results\n\n\n\nminimize_results(\n  df,\n  features_table,\n  min_score_classes = 0.6,\n  min_score_compounds = 0.4,\n  best_percentile = 0.9\n)\n\n\n\n\n\n\n\ndf\n\n\nDataframe\n\n\n\n\nfeatures_table\n\n\nPrepared features file\n\n\n\n\nmin_score_classes\n\n\nMinimal score to keep classes\n\n\n\n\nmin_score_compounds\n\n\nMinimal score to keep compounds\n\n\n\n\nbest_percentile\n\n\nBest percentile\n\n\n\n\n\n\nA minimized table\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/load_yaml_files.html",
    "href": "man/load_yaml_files.html",
    "title": "tima",
    "section": "",
    "text": "This function load yaml files\n\n\n\nload_yaml_files()\n\n\n\n\nA list of loaded yaml files\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/load_yaml_files.html#load-yaml-files",
    "href": "man/load_yaml_files.html#load-yaml-files",
    "title": "tima",
    "section": "",
    "text": "This function load yaml files\n\n\n\nload_yaml_files()\n\n\n\n\nA list of loaded yaml files\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/select_sop_columns.html",
    "href": "man/select_sop_columns.html",
    "title": "tima",
    "section": "",
    "text": "This function selects sop columns\n\n\n\nselect_sop_columns(df)\n\n\n\n\n\n\n\ndf\n\n\nDataframe\n\n\n\n\n\n\nThe dataframe with selected structure organism pairs columns\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/select_sop_columns.html#select-sop-columns",
    "href": "man/select_sop_columns.html#select-sop-columns",
    "title": "tima",
    "section": "",
    "text": "This function selects sop columns\n\n\n\nselect_sop_columns(df)\n\n\n\n\n\n\n\ndf\n\n\nDataframe\n\n\n\n\n\n\nThe dataframe with selected structure organism pairs columns\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/export_spectra_rds.html",
    "href": "man/export_spectra_rds.html",
    "title": "tima",
    "section": "",
    "text": "This function exports spectra in RDS\n\n\n\nexport_spectra_rds(file, spectra)\n\n\n\n\n\n\n\nfile\n\n\nFile where spectra will be exported.\n\n\n\n\nspectra\n\n\nThe spectra object where spectra are stored\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/export_spectra_rds.html#export-spectra-rds",
    "href": "man/export_spectra_rds.html#export-spectra-rds",
    "title": "tima",
    "section": "",
    "text": "This function exports spectra in RDS\n\n\n\nexport_spectra_rds(file, spectra)\n\n\n\n\n\n\n\nfile\n\n\nFile where spectra will be exported.\n\n\n\n\nspectra\n\n\nThe spectra object where spectra are stored\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/prepare_annotations_gnps.html",
    "href": "man/prepare_annotations_gnps.html",
    "title": "tima",
    "section": "",
    "text": "This function prepares GNPS obtained annotations\n\n\n\nprepare_annotations_gnps(\n  input = get_params(step =\n    \"prepare_annotations_gnps\")\\$files\\$annotations\\$raw\\$spectral\\$gnps,\n  output = get_params(step =\n    \"prepare_annotations_gnps\")\\$files\\$annotations\\$prepared\\$structural\\$gnps,\n  str_stereo = get_params(step =\n    \"prepare_annotations_gnps\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$stereo,\n  str_met = get_params(step =\n    \"prepare_annotations_gnps\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$metadata,\n  str_nam = get_params(step =\n    \"prepare_annotations_gnps\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$names,\n  str_tax_cla = get_params(step =\n    \"prepare_annotations_gnps\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$taxonomies\\$cla,\n  str_tax_npc = get_params(step =\n    \"prepare_annotations_gnps\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$taxonomies\\$npc\n)\n\n\n\n\n\n\n\ninput\n\n\nInput file\n\n\n\n\noutput\n\n\nOutput file\n\n\n\n\nstr_stereo\n\n\nFile containing structures stereo\n\n\n\n\nstr_met\n\n\nFile containing structures metadata\n\n\n\n\nstr_nam\n\n\nFile containing structures names\n\n\n\n\nstr_tax_cla\n\n\nFile containing Classyfire taxonomy\n\n\n\n\nstr_tax_npc\n\n\nFile containing NPClassifier taxonomy\n\n\n\n\n\n\nThe path to the prepared GNPS annotations\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\nprepare_annotations_gnps()\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/prepare_annotations_gnps.html#prepare-annotations-gnps",
    "href": "man/prepare_annotations_gnps.html#prepare-annotations-gnps",
    "title": "tima",
    "section": "",
    "text": "This function prepares GNPS obtained annotations\n\n\n\nprepare_annotations_gnps(\n  input = get_params(step =\n    \"prepare_annotations_gnps\")\\$files\\$annotations\\$raw\\$spectral\\$gnps,\n  output = get_params(step =\n    \"prepare_annotations_gnps\")\\$files\\$annotations\\$prepared\\$structural\\$gnps,\n  str_stereo = get_params(step =\n    \"prepare_annotations_gnps\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$stereo,\n  str_met = get_params(step =\n    \"prepare_annotations_gnps\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$metadata,\n  str_nam = get_params(step =\n    \"prepare_annotations_gnps\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$names,\n  str_tax_cla = get_params(step =\n    \"prepare_annotations_gnps\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$taxonomies\\$cla,\n  str_tax_npc = get_params(step =\n    \"prepare_annotations_gnps\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$taxonomies\\$npc\n)\n\n\n\n\n\n\n\ninput\n\n\nInput file\n\n\n\n\noutput\n\n\nOutput file\n\n\n\n\nstr_stereo\n\n\nFile containing structures stereo\n\n\n\n\nstr_met\n\n\nFile containing structures metadata\n\n\n\n\nstr_nam\n\n\nFile containing structures names\n\n\n\n\nstr_tax_cla\n\n\nFile containing Classyfire taxonomy\n\n\n\n\nstr_tax_npc\n\n\nFile containing NPClassifier taxonomy\n\n\n\n\n\n\nThe path to the prepared GNPS annotations\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\nprepare_annotations_gnps()\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/create_components.html",
    "href": "man/create_components.html",
    "title": "tima",
    "section": "",
    "text": "This function create components from edges\n\n\n\ncreate_components(\n  input = get_params(step = \"create_components\")\\$files\\$networks\\$spectral\\$edges\\$prepared,\n  output = get_params(step = \"create_components\")\\$files\\$networks\\$spectral\\$components\\$raw\n)\n\n\n\n\n\n\n\ninput\n\n\nInput file(s) containing edges\n\n\n\n\noutput\n\n\nOutput file.\n\n\n\n\n\n\nThe path to the created components\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\ngithub &lt;- \"https://raw.githubusercontent.com/\"\nrepo &lt;- \"taxonomicallyinformedannotation/tima-example-files/main/\"\ndata_interim &lt;- \"data/interim/\"\ndir &lt;- paste0(github, repo)\ndir &lt;- paste0(dir, data_interim)\nget_file(\n  url = paste0(dir, \"features/example_edges.tsv\"),\n  export = get_params(step = \"create_components\")$files$networks$spectral$edges$prepared\n)\ncreate_components()\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/create_components.html#create-components",
    "href": "man/create_components.html#create-components",
    "title": "tima",
    "section": "",
    "text": "This function create components from edges\n\n\n\ncreate_components(\n  input = get_params(step = \"create_components\")\\$files\\$networks\\$spectral\\$edges\\$prepared,\n  output = get_params(step = \"create_components\")\\$files\\$networks\\$spectral\\$components\\$raw\n)\n\n\n\n\n\n\n\ninput\n\n\nInput file(s) containing edges\n\n\n\n\noutput\n\n\nOutput file.\n\n\n\n\n\n\nThe path to the created components\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\ngithub &lt;- \"https://raw.githubusercontent.com/\"\nrepo &lt;- \"taxonomicallyinformedannotation/tima-example-files/main/\"\ndata_interim &lt;- \"data/interim/\"\ndir &lt;- paste0(github, repo)\ndir &lt;- paste0(dir, data_interim)\nget_file(\n  url = paste0(dir, \"features/example_edges.tsv\"),\n  export = get_params(step = \"create_components\")$files$networks$spectral$edges$prepared\n)\ncreate_components()\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/pre_harmonize_names_sirius.html",
    "href": "man/pre_harmonize_names_sirius.html",
    "title": "tima",
    "section": "",
    "text": "This function pre harmonizes Sirius names to make them compatible\n\n\n\npre_harmonize_names_sirius(x)\n\n\n\n\n\n\n\nx\n\n\nCharacter string containing a name\n\n\n\n\n\n\nCharacter string with the name modified according to the rules specified in the function\n\n\n\n\nlibrary(\"tima\")\n\nprepared_name &lt;- pre_harmonize_names_sirius(\"My name/suffix\")"
  },
  {
    "objectID": "man/pre_harmonize_names_sirius.html#pre-harmonize-names-sirius",
    "href": "man/pre_harmonize_names_sirius.html#pre-harmonize-names-sirius",
    "title": "tima",
    "section": "",
    "text": "This function pre harmonizes Sirius names to make them compatible\n\n\n\npre_harmonize_names_sirius(x)\n\n\n\n\n\n\n\nx\n\n\nCharacter string containing a name\n\n\n\n\n\n\nCharacter string with the name modified according to the rules specified in the function\n\n\n\n\nlibrary(\"tima\")\n\nprepared_name &lt;- pre_harmonize_names_sirius(\"My name/suffix\")"
  },
  {
    "objectID": "man/fake_ecmdb.html",
    "href": "man/fake_ecmdb.html",
    "title": "tima",
    "section": "",
    "text": "This function fakes ECMDB in case the download failed\n\n\n\nfake_ecmdb(export)\n\n\n\n\n\n\n\nexport\n\n\nPath to save the file to\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/fake_ecmdb.html#fake-ecmdb",
    "href": "man/fake_ecmdb.html#fake-ecmdb",
    "title": "tima",
    "section": "",
    "text": "This function fakes ECMDB in case the download failed\n\n\n\nfake_ecmdb(export)\n\n\n\n\n\n\n\nexport\n\n\nPath to save the file to\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/dist_get.html",
    "href": "man/dist_get.html",
    "title": "tima",
    "section": "",
    "text": "This function calculates the distance between two elements in a distance matrix\n\n\n\ndist_get(d, idx1, idx2)\n\n\n\n\n\n\n\nd\n\n\nDistance matrix\n\n\n\n\nidx1\n\n\nIndex of the first element\n\n\n\n\nidx2\n\n\nIndex of the second element\n\n\n\n\n\n\nCredit goes to usedist package\n\n\n\nDistance between the two elements\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/dist_get.html#distance-between-two-elements-in-a-distance-matrix",
    "href": "man/dist_get.html#distance-between-two-elements-in-a-distance-matrix",
    "title": "tima",
    "section": "",
    "text": "This function calculates the distance between two elements in a distance matrix\n\n\n\ndist_get(d, idx1, idx2)\n\n\n\n\n\n\n\nd\n\n\nDistance matrix\n\n\n\n\nidx1\n\n\nIndex of the first element\n\n\n\n\nidx2\n\n\nIndex of the second element\n\n\n\n\n\n\nCredit goes to usedist package\n\n\n\nDistance between the two elements\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/harmonize_adducts.html",
    "href": "man/harmonize_adducts.html",
    "title": "tima",
    "section": "",
    "text": "This function annotates masses\n\n\n\nharmonize_adducts(df, adducts_colname = \"adduct\", adducts_translations)\n\n\n\n\n\n\n\ndf\n\n\nDataframe\n\n\n\n\nadducts_colname\n\n\nAdducts colname\n\n\n\n\nadducts_translations\n\n\nAdducts translations\n\n\n\n\n\n\nA table with harmonized adducts\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/harmonize_adducts.html#harmonize-adducts",
    "href": "man/harmonize_adducts.html#harmonize-adducts",
    "title": "tima",
    "section": "",
    "text": "This function annotates masses\n\n\n\nharmonize_adducts(df, adducts_colname = \"adduct\", adducts_translations)\n\n\n\n\n\n\n\ndf\n\n\nDataframe\n\n\n\n\nadducts_colname\n\n\nAdducts colname\n\n\n\n\nadducts_translations\n\n\nAdducts translations\n\n\n\n\n\n\nA table with harmonized adducts\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/split_tables_sop.html",
    "href": "man/split_tables_sop.html",
    "title": "tima",
    "section": "",
    "text": "This function splits the structure organism table.\n\n\n\nsplit_tables_sop(table, cache)\n\n\n\n\n\n\n\ntable\n\n\nTable to split\n\n\n\n\ncache\n\n\nCache where already processed SMILES are located\n\n\n\n\n\n\nA list of tables from the structure organism pairs tables\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/split_tables_sop.html#split-structure-organism-pairs-table",
    "href": "man/split_tables_sop.html#split-structure-organism-pairs-table",
    "title": "tima",
    "section": "",
    "text": "This function splits the structure organism table.\n\n\n\nsplit_tables_sop(table, cache)\n\n\n\n\n\n\n\ntable\n\n\nTable to split\n\n\n\n\ncache\n\n\nCache where already processed SMILES are located\n\n\n\n\n\n\nA list of tables from the structure organism pairs tables\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/weight_chemo.html",
    "href": "man/weight_chemo.html",
    "title": "tima",
    "section": "",
    "text": "This function weights the biologically weighted annotations according their chemical consistency\n\n\n\nweight_chemo(\n  annot_table_wei_bio_clean = get(\"annot_table_wei_bio_clean\", envir = parent.frame()),\n  weight_spectral = get(\"weight_spectral\", envir = parent.frame()),\n  weight_biological = get(\"weight_biological\", envir = parent.frame()),\n  weight_chemical = get(\"weight_chemical\", envir = parent.frame()),\n  score_chemical_cla_kingdom = get(\"score_chemical_cla_kingdom\", envir = parent.frame()),\n  score_chemical_cla_superclass = get(\"score_chemical_cla_superclass\", envir =\n    parent.frame()),\n  score_chemical_cla_class = get(\"score_chemical_cla_class\", envir = parent.frame()),\n  score_chemical_cla_parent = get(\"score_chemical_cla_parent\", envir = parent.frame()),\n  score_chemical_npc_pathway = get(\"score_chemical_npc_pathway\", envir = parent.frame()),\n  score_chemical_npc_superclass = get(\"score_chemical_npc_superclass\", envir =\n    parent.frame()),\n  score_chemical_npc_class = get(\"score_chemical_npc_class\", envir = parent.frame())\n)\n\n\n\n\n\n\n\nannot_table_wei_bio_clean\n\n\nTable containing the biologically weighted annotation\n\n\n\n\nweight_spectral\n\n\nWeight for the spectral score\n\n\n\n\nweight_biological\n\n\nWeight for the biological score\n\n\n\n\nweight_chemical\n\n\nWeight for the chemical consistency score\n\n\n\n\nscore_chemical_cla_kingdom\n\n\nScore for a Classyfire kingdom match (should be lower than  Classyfire superclass)\n\n\n\n\nscore_chemical_cla_superclass\n\n\nScore for a Classyfire superclass match (should be lower than Classyfire class)\n\n\n\n\nscore_chemical_cla_class\n\n\nScore for a Classyfire class match (should be lower than Classyfire parent)\n\n\n\n\nscore_chemical_cla_parent\n\n\nScore for a Classyfire parent match (should be the highest)\n\n\n\n\nscore_chemical_npc_pathway\n\n\nScore for a pathway match (should be lower than superclass)\n\n\n\n\nscore_chemical_npc_superclass\n\n\nScore for a superclass match (should be lower than class)\n\n\n\n\nscore_chemical_npc_class\n\n\nScore for a class match (should be the highest)\n\n\n\n\n\n\nA table containing the chemically weighted annotation\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/weight_chemo.html#weight-chemo",
    "href": "man/weight_chemo.html#weight-chemo",
    "title": "tima",
    "section": "",
    "text": "This function weights the biologically weighted annotations according their chemical consistency\n\n\n\nweight_chemo(\n  annot_table_wei_bio_clean = get(\"annot_table_wei_bio_clean\", envir = parent.frame()),\n  weight_spectral = get(\"weight_spectral\", envir = parent.frame()),\n  weight_biological = get(\"weight_biological\", envir = parent.frame()),\n  weight_chemical = get(\"weight_chemical\", envir = parent.frame()),\n  score_chemical_cla_kingdom = get(\"score_chemical_cla_kingdom\", envir = parent.frame()),\n  score_chemical_cla_superclass = get(\"score_chemical_cla_superclass\", envir =\n    parent.frame()),\n  score_chemical_cla_class = get(\"score_chemical_cla_class\", envir = parent.frame()),\n  score_chemical_cla_parent = get(\"score_chemical_cla_parent\", envir = parent.frame()),\n  score_chemical_npc_pathway = get(\"score_chemical_npc_pathway\", envir = parent.frame()),\n  score_chemical_npc_superclass = get(\"score_chemical_npc_superclass\", envir =\n    parent.frame()),\n  score_chemical_npc_class = get(\"score_chemical_npc_class\", envir = parent.frame())\n)\n\n\n\n\n\n\n\nannot_table_wei_bio_clean\n\n\nTable containing the biologically weighted annotation\n\n\n\n\nweight_spectral\n\n\nWeight for the spectral score\n\n\n\n\nweight_biological\n\n\nWeight for the biological score\n\n\n\n\nweight_chemical\n\n\nWeight for the chemical consistency score\n\n\n\n\nscore_chemical_cla_kingdom\n\n\nScore for a Classyfire kingdom match (should be lower than  Classyfire superclass)\n\n\n\n\nscore_chemical_cla_superclass\n\n\nScore for a Classyfire superclass match (should be lower than Classyfire class)\n\n\n\n\nscore_chemical_cla_class\n\n\nScore for a Classyfire class match (should be lower than Classyfire parent)\n\n\n\n\nscore_chemical_cla_parent\n\n\nScore for a Classyfire parent match (should be the highest)\n\n\n\n\nscore_chemical_npc_pathway\n\n\nScore for a pathway match (should be lower than superclass)\n\n\n\n\nscore_chemical_npc_superclass\n\n\nScore for a superclass match (should be lower than class)\n\n\n\n\nscore_chemical_npc_class\n\n\nScore for a class match (should be the highest)\n\n\n\n\n\n\nA table containing the chemically weighted annotation\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/get_path.html",
    "href": "man/get_path.html",
    "title": "tima",
    "section": "",
    "text": "This function gets path\n\n\n\nget_path(base_path)\n\n\n\n\n\n\n\nbase_path\n\n\nBase path\n\n\n\n\n\n\nA path\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/get_path.html#get-path",
    "href": "man/get_path.html#get-path",
    "title": "tima",
    "section": "",
    "text": "This function gets path\n\n\n\nget_path(base_path)\n\n\n\n\n\n\n\nbase_path\n\n\nBase path\n\n\n\n\n\n\nA path\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/process_smiles.html",
    "href": "man/process_smiles.html",
    "title": "tima",
    "section": "",
    "text": "This function processes SMILES\n\n\n\nprocess_smiles(df, smiles_colname = \"structure_smiles_initial\", cache = NULL)\n\n\n\n\n\n\n\ndf\n\n\nDataframe to use\n\n\n\n\nsmiles_colname\n\n\nColumn name of the SMILES variable\n\n\n\n\ncache\n\n\nCache where already processed SMILES are located\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nsmiles &lt;- \"C=C[C@H]1[C@H](OC=C2C1=CCOC2=O)O[C@H]3[C@H]([C@H]([C@H]([C@H](O3)CO)O)O)O\"\ndata.frame(\n  \"structure_smiles_initial\" = smiles\n) |&gt;\n  process_smiles()\n\nProcessing complete. Total molecules processed: 1\n\n\n# A tidytable: 1 × 8\n  structure_smiles_initial                   structure_smiles structure_inchikey\n  &lt;chr&gt;                                      &lt;chr&gt;            &lt;chr&gt;             \n1 C=C[C@H]1[C@H](OC=C2C1=CCOC2=O)O[C@H]3[C@… C=C[C@@H]1C2=CC… DUAGQYUORDTXOR-NO…\n# ℹ 5 more variables: structure_molecular_formula &lt;chr&gt;,\n#   structure_exact_mass &lt;dbl&gt;, structure_smiles_no_stereo &lt;chr&gt;,\n#   structure_xlogp &lt;dbl&gt;, structure_inchikey_connectivity_layer &lt;chr&gt;"
  },
  {
    "objectID": "man/process_smiles.html#process-smiles",
    "href": "man/process_smiles.html#process-smiles",
    "title": "tima",
    "section": "",
    "text": "This function processes SMILES\n\n\n\nprocess_smiles(df, smiles_colname = \"structure_smiles_initial\", cache = NULL)\n\n\n\n\n\n\n\ndf\n\n\nDataframe to use\n\n\n\n\nsmiles_colname\n\n\nColumn name of the SMILES variable\n\n\n\n\ncache\n\n\nCache where already processed SMILES are located\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nsmiles &lt;- \"C=C[C@H]1[C@H](OC=C2C1=CCOC2=O)O[C@H]3[C@H]([C@H]([C@H]([C@H](O3)CO)O)O)O\"\ndata.frame(\n  \"structure_smiles_initial\" = smiles\n) |&gt;\n  process_smiles()\n\nProcessing complete. Total molecules processed: 1\n\n\n# A tidytable: 1 × 8\n  structure_smiles_initial                   structure_smiles structure_inchikey\n  &lt;chr&gt;                                      &lt;chr&gt;            &lt;chr&gt;             \n1 C=C[C@H]1[C@H](OC=C2C1=CCOC2=O)O[C@H]3[C@… C=C[C@@H]1C2=CC… DUAGQYUORDTXOR-NO…\n# ℹ 5 more variables: structure_molecular_formula &lt;chr&gt;,\n#   structure_exact_mass &lt;dbl&gt;, structure_smiles_no_stereo &lt;chr&gt;,\n#   structure_xlogp &lt;dbl&gt;, structure_inchikey_connectivity_layer &lt;chr&gt;"
  },
  {
    "objectID": "man/parse_yaml_params.html",
    "href": "man/parse_yaml_params.html",
    "title": "tima",
    "section": "",
    "text": "This function parses YAML parameters\n\n\n\nparse_yaml_params(\n  def = get(\"default_path\", envir = parent.frame()),\n  usr = get(\"user_path\", envir = parent.frame())\n)\n\n\n\n\n\n\n\ndef\n\n\nDefault path\n\n\n\n\nusr\n\n\nUser path\n\n\n\n\n\n\nA list containing the parameters specified in the YAML files\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/parse_yaml_params.html#parse-yaml-parameters",
    "href": "man/parse_yaml_params.html#parse-yaml-parameters",
    "title": "tima",
    "section": "",
    "text": "This function parses YAML parameters\n\n\n\nparse_yaml_params(\n  def = get(\"default_path\", envir = parent.frame()),\n  usr = get(\"user_path\", envir = parent.frame())\n)\n\n\n\n\n\n\n\ndef\n\n\nDefault path\n\n\n\n\nusr\n\n\nUser path\n\n\n\n\n\n\nA list containing the parameters specified in the YAML files\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/complement_metadata_structures.html",
    "href": "man/complement_metadata_structures.html",
    "title": "tima",
    "section": "",
    "text": "This function complement structural metadata\n\n\n\ncomplement_metadata_structures(\n  df,\n  str_stereo = get(\"str_stereo\", envir = parent.frame()),\n  str_met = get(\"str_met\", envir = parent.frame()),\n  str_nam = get(\"str_nam\", envir = parent.frame()),\n  str_tax_cla = get(\"str_tax_cla\", envir = parent.frame()),\n  str_tax_npc = get(\"str_tax_npc\", envir = parent.frame())\n)\n\n\n\n\n\n\n\ndf\n\n\nData frame with structural metadata to be complemented\n\n\n\n\nstr_stereo\n\n\nFile containing structures stereo\n\n\n\n\nstr_met\n\n\nFile containing structures metadata\n\n\n\n\nstr_nam\n\n\nFile containing structures names\n\n\n\n\nstr_tax_cla\n\n\nFile containing Classyfire taxonomy\n\n\n\n\nstr_tax_npc\n\n\nFile containing NPClassifier taxonomy\n\n\n\n\n\n\nData frame with complemented structural metadata\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/complement_metadata_structures.html#complement-metadata-of-structures",
    "href": "man/complement_metadata_structures.html#complement-metadata-of-structures",
    "title": "tima",
    "section": "",
    "text": "This function complement structural metadata\n\n\n\ncomplement_metadata_structures(\n  df,\n  str_stereo = get(\"str_stereo\", envir = parent.frame()),\n  str_met = get(\"str_met\", envir = parent.frame()),\n  str_nam = get(\"str_nam\", envir = parent.frame()),\n  str_tax_cla = get(\"str_tax_cla\", envir = parent.frame()),\n  str_tax_npc = get(\"str_tax_npc\", envir = parent.frame())\n)\n\n\n\n\n\n\n\ndf\n\n\nData frame with structural metadata to be complemented\n\n\n\n\nstr_stereo\n\n\nFile containing structures stereo\n\n\n\n\nstr_met\n\n\nFile containing structures metadata\n\n\n\n\nstr_nam\n\n\nFile containing structures names\n\n\n\n\nstr_tax_cla\n\n\nFile containing Classyfire taxonomy\n\n\n\n\nstr_tax_npc\n\n\nFile containing NPClassifier taxonomy\n\n\n\n\n\n\nData frame with complemented structural metadata\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/transform_score_sirius_csi.html",
    "href": "man/transform_score_sirius_csi.html",
    "title": "tima",
    "section": "",
    "text": "This function calculates the mass of M\n\n\n\ntransform_score_sirius_csi(csi_score, K = 50, scale = 10)\n\n\n\n\n\n\n\ncsi_score\n\n\nOriginal CSI score\n\n\n\n\nK\n\n\nShift\n\n\n\n\nscale\n\n\nScale\n\n\n\n\n\n\nA mass\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/transform_score_sirius_csi.html#transform-score-sirius-csi",
    "href": "man/transform_score_sirius_csi.html#transform-score-sirius-csi",
    "title": "tima",
    "section": "",
    "text": "This function calculates the mass of M\n\n\n\ntransform_score_sirius_csi(csi_score, K = 50, scale = 10)\n\n\n\n\n\n\n\ncsi_score\n\n\nOriginal CSI score\n\n\n\n\nK\n\n\nShift\n\n\n\n\nscale\n\n\nScale\n\n\n\n\n\n\nA mass\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/get_last_version_from_zenodo.html",
    "href": "man/get_last_version_from_zenodo.html",
    "title": "tima",
    "section": "",
    "text": "This function gets the last version of a file from a Zenodo record\n\n\n\nget_last_version_from_zenodo(doi, pattern, path)\n\n\n\n\n\n\n\ndoi\n\n\nDOI of the Zenodo record\n\n\n\n\npattern\n\n\nPattern to identify the file to download\n\n\n\n\npath\n\n\nPath to save the file to\n\n\n\n\n\n\nCredit goes to partially to https://inbo.github.io/inborutils/\n\n\n\nThe path to the file\n\n\n\n\nlibrary(\"tima\")\n\nget_last_version_from_zenodo(\n  doi = \"10.5281/zenodo.5794106\",\n  pattern = \"frozen.csv.gz\",\n  path = \"frozen.csv.gz\"\n)"
  },
  {
    "objectID": "man/get_last_version_from_zenodo.html#get-last-version-from-zenodo",
    "href": "man/get_last_version_from_zenodo.html#get-last-version-from-zenodo",
    "title": "tima",
    "section": "",
    "text": "This function gets the last version of a file from a Zenodo record\n\n\n\nget_last_version_from_zenodo(doi, pattern, path)\n\n\n\n\n\n\n\ndoi\n\n\nDOI of the Zenodo record\n\n\n\n\npattern\n\n\nPattern to identify the file to download\n\n\n\n\npath\n\n\nPath to save the file to\n\n\n\n\n\n\nCredit goes to partially to https://inbo.github.io/inborutils/\n\n\n\nThe path to the file\n\n\n\n\nlibrary(\"tima\")\n\nget_last_version_from_zenodo(\n  doi = \"10.5281/zenodo.5794106\",\n  pattern = \"frozen.csv.gz\",\n  path = \"frozen.csv.gz\"\n)"
  },
  {
    "objectID": "man/prepare_params.html",
    "href": "man/prepare_params.html",
    "title": "tima",
    "section": "",
    "text": "This function prepares main parameters\n\n\n\nprepare_params(\n  params_small = get_params(step = \"prepare_params\"),\n  params_advanced = get_params(step = \"prepare_params_advanced\"),\n  step = NA\n)\n\n\n\n\n\n\n\nparams_small\n\n\nparams_small\n\n\n\n\nparams_advanced\n\n\nparams_advanced\n\n\n\n\nstep\n\n\nStep\n\n\n\n\n\n\nThe path to the yaml files containing prepared parameters\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/prepare_params.html#prepare-params",
    "href": "man/prepare_params.html#prepare-params",
    "title": "tima",
    "section": "",
    "text": "This function prepares main parameters\n\n\n\nprepare_params(\n  params_small = get_params(step = \"prepare_params\"),\n  params_advanced = get_params(step = \"prepare_params_advanced\"),\n  step = NA\n)\n\n\n\n\n\n\n\nparams_small\n\n\nparams_small\n\n\n\n\nparams_advanced\n\n\nparams_advanced\n\n\n\n\nstep\n\n\nStep\n\n\n\n\n\n\nThe path to the yaml files containing prepared parameters\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/create_edges_spectra.html",
    "href": "man/create_edges_spectra.html",
    "title": "tima",
    "section": "",
    "text": "This function create edges based on fragmentation spectra similarity\n\n\n\ncreate_edges_spectra(\n  input = get_params(step = \"create_edges_spectra\")\\$files\\$spectral\\$raw,\n  output = get_params(step = \"create_edges_spectra\")\\$files\\$networks\\$spectral\\$edges\\$raw,\n  name_source = get_params(step = \"create_edges_spectra\")\\$names\\$source,\n  name_target = get_params(step = \"create_edges_spectra\")\\$names\\$target,\n  method = get_params(step = \"create_edges_spectra\")\\$similarities\\$methods\\$edges,\n  threshold = get_params(step = \"create_edges_spectra\")\\$similarities\\$thresholds\\$edges,\n  matched_peaks = get_params(step =\n    \"create_edges_spectra\")\\$similarities\\$thresholds\\$matched_peaks,\n  ppm = get_params(step = \"create_edges_spectra\")\\$ms\\$tolerances\\$mass\\$ppm\\$ms2,\n  dalton = get_params(step = \"create_edges_spectra\")\\$ms\\$tolerances\\$mass\\$dalton\\$ms2,\n  qutoff = get_params(step = \"create_edges_spectra\")\\$ms\\$thresholds\\$ms2\\$intensity\n)\n\n\n\n\n\n\n\ninput\n\n\nQuery file containing spectra. Currently an ‘.mgf’ file\n\n\n\n\noutput\n\n\nOutput file.\n\n\n\n\nname_source\n\n\nName of the source features column\n\n\n\n\nname_target\n\n\nName of the target features column\n\n\n\n\nmethod\n\n\nSimilarity method\n\n\n\n\nthreshold\n\n\nMinimal similarity to report\n\n\n\n\nmatched_peaks\n\n\nMinimal number of matched peaks\n\n\n\n\nppm\n\n\nRelative ppm tolerance to be used\n\n\n\n\ndalton\n\n\nAbsolute Dalton tolerance to be used\n\n\n\n\nqutoff\n\n\nIntensity under which ms2 fragments will be removed.\n\n\n\n\n\n\nThe path to the created spectral edges\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\nget_file(\n  url = get_default_paths()$urls$examples$spectra_mini,\n  export = get_params(step = \"create_edges_spectra\")$files$spectral$raw\n)\ncreate_edges_spectra()\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/create_edges_spectra.html#create-edges-spectra",
    "href": "man/create_edges_spectra.html#create-edges-spectra",
    "title": "tima",
    "section": "",
    "text": "This function create edges based on fragmentation spectra similarity\n\n\n\ncreate_edges_spectra(\n  input = get_params(step = \"create_edges_spectra\")\\$files\\$spectral\\$raw,\n  output = get_params(step = \"create_edges_spectra\")\\$files\\$networks\\$spectral\\$edges\\$raw,\n  name_source = get_params(step = \"create_edges_spectra\")\\$names\\$source,\n  name_target = get_params(step = \"create_edges_spectra\")\\$names\\$target,\n  method = get_params(step = \"create_edges_spectra\")\\$similarities\\$methods\\$edges,\n  threshold = get_params(step = \"create_edges_spectra\")\\$similarities\\$thresholds\\$edges,\n  matched_peaks = get_params(step =\n    \"create_edges_spectra\")\\$similarities\\$thresholds\\$matched_peaks,\n  ppm = get_params(step = \"create_edges_spectra\")\\$ms\\$tolerances\\$mass\\$ppm\\$ms2,\n  dalton = get_params(step = \"create_edges_spectra\")\\$ms\\$tolerances\\$mass\\$dalton\\$ms2,\n  qutoff = get_params(step = \"create_edges_spectra\")\\$ms\\$thresholds\\$ms2\\$intensity\n)\n\n\n\n\n\n\n\ninput\n\n\nQuery file containing spectra. Currently an ‘.mgf’ file\n\n\n\n\noutput\n\n\nOutput file.\n\n\n\n\nname_source\n\n\nName of the source features column\n\n\n\n\nname_target\n\n\nName of the target features column\n\n\n\n\nmethod\n\n\nSimilarity method\n\n\n\n\nthreshold\n\n\nMinimal similarity to report\n\n\n\n\nmatched_peaks\n\n\nMinimal number of matched peaks\n\n\n\n\nppm\n\n\nRelative ppm tolerance to be used\n\n\n\n\ndalton\n\n\nAbsolute Dalton tolerance to be used\n\n\n\n\nqutoff\n\n\nIntensity under which ms2 fragments will be removed.\n\n\n\n\n\n\nThe path to the created spectral edges\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\nget_file(\n  url = get_default_paths()$urls$examples$spectra_mini,\n  export = get_params(step = \"create_edges_spectra\")$files$spectral$raw\n)\ncreate_edges_spectra()\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/copy_backbone.html",
    "href": "man/copy_backbone.html",
    "title": "tima",
    "section": "",
    "text": "This function copies backbone\n\n\n\ncopy_backbone(cache_dir = fs::path_home(\".tima\"), package = \"tima\")\n\n\n\n\n\n\n\ncache_dir\n\n\nCache directory\n\n\n\n\npackage\n\n\nPackage\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/copy_backbone.html#copy-backbone",
    "href": "man/copy_backbone.html#copy-backbone",
    "title": "tima",
    "section": "",
    "text": "This function copies backbone\n\n\n\ncopy_backbone(cache_dir = fs::path_home(\".tima\"), package = \"tima\")\n\n\n\n\n\n\n\ncache_dir\n\n\nCache directory\n\n\n\n\npackage\n\n\nPackage\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/change_params_small.html",
    "href": "man/change_params_small.html",
    "title": "tima",
    "section": "",
    "text": "This function helps changing convenience parameters.\n\n\n\nchange_params_small(\n  fil_pat = NULL,\n  fil_fea_raw = NULL,\n  fil_met_raw = NULL,\n  fil_sir_raw = NULL,\n  fil_spe_raw = NULL,\n  ms_pol = NULL,\n  org_tax = NULL,\n  hig_con = NULL,\n  summarize = NULL\n)\n\n\n\n\n\n\n\nfil_pat\n\n\nThe pattern identifying your whole job. You can put whatever you want. STRING\n\n\n\n\nfil_fea_raw\n\n\nThe path to the file containing your features’ intensities. Can be generated by mzmine, SLAW, or SIRIUS. STRING\n\n\n\n\nfil_met_raw\n\n\nThe path to the file containing your metadata. If your experiment contains a single taxon, you can provide it below instead. STRING\n\n\n\n\nfil_sir_raw\n\n\nThe directory containing the sirius annotations. STRING\n\n\n\n\nfil_spe_raw\n\n\nThe path to the file containing your features’ spectra. Can contain MS1 and/or MS2 spectra. STRING\n\n\n\n\nms_pol\n\n\nThe polarity used. Must be either \"pos\" or \"neg\". STRING\n\n\n\n\norg_tax\n\n\nIf your experiment contains a single taxon, its scientific name. \"Homo sapiens\". STRING\n\n\n\n\nhig_con\n\n\nFilter high confidence candidates only. BOOLEAN\n\n\n\n\nsummarize\n\n\nSummarize all candidates per feature to a single row. BOOLEAN\n\n\n\n\n\n\nYAML file with changed parameters.\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ntima::change_params_small(\n  fil_pat = \"myExamplePattern\",\n  fil_fea_raw = \"myExampleDir/myExampleFeatures.csv\",\n  fil_met_raw = \"myExampleDir2SomeWhereElse/myOptionalMetadata.tsv\",\n  fil_sir_raw = \"myExampleDir3/myAwesomeSiriusProject.zip\",\n  fil_spe_raw = \"myBeautifulSpectra.mgf\",\n  ms_pol = \"pos\",\n  org_tax = \"Gentiana lutea\",\n  hig_con = TRUE,\n  summarize = FALSE\n)"
  },
  {
    "objectID": "man/change_params_small.html#change-params-small",
    "href": "man/change_params_small.html#change-params-small",
    "title": "tima",
    "section": "",
    "text": "This function helps changing convenience parameters.\n\n\n\nchange_params_small(\n  fil_pat = NULL,\n  fil_fea_raw = NULL,\n  fil_met_raw = NULL,\n  fil_sir_raw = NULL,\n  fil_spe_raw = NULL,\n  ms_pol = NULL,\n  org_tax = NULL,\n  hig_con = NULL,\n  summarize = NULL\n)\n\n\n\n\n\n\n\nfil_pat\n\n\nThe pattern identifying your whole job. You can put whatever you want. STRING\n\n\n\n\nfil_fea_raw\n\n\nThe path to the file containing your features’ intensities. Can be generated by mzmine, SLAW, or SIRIUS. STRING\n\n\n\n\nfil_met_raw\n\n\nThe path to the file containing your metadata. If your experiment contains a single taxon, you can provide it below instead. STRING\n\n\n\n\nfil_sir_raw\n\n\nThe directory containing the sirius annotations. STRING\n\n\n\n\nfil_spe_raw\n\n\nThe path to the file containing your features’ spectra. Can contain MS1 and/or MS2 spectra. STRING\n\n\n\n\nms_pol\n\n\nThe polarity used. Must be either \"pos\" or \"neg\". STRING\n\n\n\n\norg_tax\n\n\nIf your experiment contains a single taxon, its scientific name. \"Homo sapiens\". STRING\n\n\n\n\nhig_con\n\n\nFilter high confidence candidates only. BOOLEAN\n\n\n\n\nsummarize\n\n\nSummarize all candidates per feature to a single row. BOOLEAN\n\n\n\n\n\n\nYAML file with changed parameters.\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ntima::change_params_small(\n  fil_pat = \"myExamplePattern\",\n  fil_fea_raw = \"myExampleDir/myExampleFeatures.csv\",\n  fil_met_raw = \"myExampleDir2SomeWhereElse/myOptionalMetadata.tsv\",\n  fil_sir_raw = \"myExampleDir3/myAwesomeSiriusProject.zip\",\n  fil_spe_raw = \"myBeautifulSpectra.mgf\",\n  ms_pol = \"pos\",\n  org_tax = \"Gentiana lutea\",\n  hig_con = TRUE,\n  summarize = FALSE\n)"
  },
  {
    "objectID": "man/prepare_annotations_sirius.html",
    "href": "man/prepare_annotations_sirius.html",
    "title": "tima",
    "section": "",
    "text": "This function prepares Sirius results to make them compatible\n\n\n\nprepare_annotations_sirius(\n  input_directory = get_params(step =\n    \"prepare_annotations_sirius\")\\$files\\$annotations\\$raw\\$sirius,\n  output_ann = get_params(step =\n    \"prepare_annotations_sirius\")\\$files\\$annotations\\$prepared\\$structural\\$sirius,\n  output_can = get_params(step =\n    \"prepare_annotations_sirius\")\\$files\\$annotations\\$prepared\\$canopus,\n  output_for = get_params(step =\n    \"prepare_annotations_sirius\")\\$files\\$annotations\\$prepared\\$formula,\n  sirius_version = get_params(step = \"prepare_annotations_sirius\")\\$tools\\$sirius\\$version,\n  str_stereo = get_params(step =\n    \"prepare_annotations_sirius\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$stereo,\n  str_met = get_params(step =\n    \"prepare_annotations_sirius\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$metadata,\n  str_nam = get_params(step =\n    \"prepare_annotations_sirius\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$names,\n  str_tax_cla = get_params(step =\n    \"prepare_annotations_sirius\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$taxonomies\\$cla,\n  str_tax_npc = get_params(step =\n    \"prepare_annotations_sirius\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$taxonomies\\$npc\n)\n\n\n\n\n\n\n\ninput_directory\n\n\nDirectory containing the Sirius results\n\n\n\n\noutput_ann\n\n\nOutput where to save prepared annotation results\n\n\n\n\noutput_can\n\n\nOutput where to save prepared canopus results\n\n\n\n\noutput_for\n\n\nOutput where to save prepared formula results\n\n\n\n\nsirius_version\n\n\nSirius version\n\n\n\n\nstr_stereo\n\n\nFile containing structures stereo\n\n\n\n\nstr_met\n\n\nFile containing structures metadata\n\n\n\n\nstr_nam\n\n\nFile containing structures names\n\n\n\n\nstr_tax_cla\n\n\nFile containing Classyfire taxonomy\n\n\n\n\nstr_tax_npc\n\n\nFile containing NPClassifier taxonomy\n\n\n\n\n\n\nThe path to the prepared SIRIUS annotations\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\nprepare_annotations_sirius()\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/prepare_annotations_sirius.html#prepare-annotations-sirius",
    "href": "man/prepare_annotations_sirius.html#prepare-annotations-sirius",
    "title": "tima",
    "section": "",
    "text": "This function prepares Sirius results to make them compatible\n\n\n\nprepare_annotations_sirius(\n  input_directory = get_params(step =\n    \"prepare_annotations_sirius\")\\$files\\$annotations\\$raw\\$sirius,\n  output_ann = get_params(step =\n    \"prepare_annotations_sirius\")\\$files\\$annotations\\$prepared\\$structural\\$sirius,\n  output_can = get_params(step =\n    \"prepare_annotations_sirius\")\\$files\\$annotations\\$prepared\\$canopus,\n  output_for = get_params(step =\n    \"prepare_annotations_sirius\")\\$files\\$annotations\\$prepared\\$formula,\n  sirius_version = get_params(step = \"prepare_annotations_sirius\")\\$tools\\$sirius\\$version,\n  str_stereo = get_params(step =\n    \"prepare_annotations_sirius\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$stereo,\n  str_met = get_params(step =\n    \"prepare_annotations_sirius\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$metadata,\n  str_nam = get_params(step =\n    \"prepare_annotations_sirius\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$names,\n  str_tax_cla = get_params(step =\n    \"prepare_annotations_sirius\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$taxonomies\\$cla,\n  str_tax_npc = get_params(step =\n    \"prepare_annotations_sirius\")\\$files\\$libraries\\$sop\\$merged\\$structures\\$taxonomies\\$npc\n)\n\n\n\n\n\n\n\ninput_directory\n\n\nDirectory containing the Sirius results\n\n\n\n\noutput_ann\n\n\nOutput where to save prepared annotation results\n\n\n\n\noutput_can\n\n\nOutput where to save prepared canopus results\n\n\n\n\noutput_for\n\n\nOutput where to save prepared formula results\n\n\n\n\nsirius_version\n\n\nSirius version\n\n\n\n\nstr_stereo\n\n\nFile containing structures stereo\n\n\n\n\nstr_met\n\n\nFile containing structures metadata\n\n\n\n\nstr_nam\n\n\nFile containing structures names\n\n\n\n\nstr_tax_cla\n\n\nFile containing Classyfire taxonomy\n\n\n\n\nstr_tax_npc\n\n\nFile containing NPClassifier taxonomy\n\n\n\n\n\n\nThe path to the prepared SIRIUS annotations\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\nprepare_annotations_sirius()\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/prepare_features_components.html",
    "href": "man/prepare_features_components.html",
    "title": "tima",
    "section": "",
    "text": "This function prepares the components (clusters in molecular network) for further use\n\n\n\nprepare_features_components(\n  input = get_params(step =\n    \"prepare_features_components\")\\$files\\$networks\\$spectral\\$components\\$raw,\n  output = get_params(step =\n    \"prepare_features_components\")\\$files\\$networks\\$spectral\\$components\\$prepared\n)\n\n\n\n\n\n\n\ninput\n\n\nInput file\n\n\n\n\noutput\n\n\nOutput file\n\n\n\n\n\n\nThe path to the prepared features’ components\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\ngithub &lt;- \"https://raw.githubusercontent.com/\"\nrepo &lt;- \"taxonomicallyinformedannotation/tima-example-files/main/\"\ndir &lt;- paste0(github, repo)\ninput &lt;- get_params(step = \"prepare_features_components\")$files$networks$spectral$components$raw\nget_file(url = paste0(dir, input), export = input)\nprepare_features_components(\n  input = input\n)\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/prepare_features_components.html#prepare-features-components",
    "href": "man/prepare_features_components.html#prepare-features-components",
    "title": "tima",
    "section": "",
    "text": "This function prepares the components (clusters in molecular network) for further use\n\n\n\nprepare_features_components(\n  input = get_params(step =\n    \"prepare_features_components\")\\$files\\$networks\\$spectral\\$components\\$raw,\n  output = get_params(step =\n    \"prepare_features_components\")\\$files\\$networks\\$spectral\\$components\\$prepared\n)\n\n\n\n\n\n\n\ninput\n\n\nInput file\n\n\n\n\noutput\n\n\nOutput file\n\n\n\n\n\n\nThe path to the prepared features’ components\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\ngithub &lt;- \"https://raw.githubusercontent.com/\"\nrepo &lt;- \"taxonomicallyinformedannotation/tima-example-files/main/\"\ndir &lt;- paste0(github, repo)\ninput &lt;- get_params(step = \"prepare_features_components\")$files$networks$spectral$components$raw\nget_file(url = paste0(dir, input), export = input)\nprepare_features_components(\n  input = input\n)\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/clean_chemo.html",
    "href": "man/clean_chemo.html",
    "title": "tima",
    "section": "",
    "text": "This function cleans the results obtained after chemical weighting\n\n\n\nclean_chemo(\n  annot_table_wei_chemo = get(\"annot_table_wei_chemo\", envir = parent.frame()),\n  components_table = get(\"components_table\", envir = parent.frame()),\n  features_table = get(\"features_table\", envir = parent.frame()),\n  structure_organism_pairs_table = get(\"structure_organism_pairs_table\", envir =\n    parent.frame()),\n  candidates_final = get(\"candidates_final\", envir = parent.frame()),\n  minimal_ms1_bio = get(\"minimal_ms1_bio\", envir = parent.frame()),\n  minimal_ms1_chemo = get(\"minimal_ms1_chemo\", envir = parent.frame()),\n  minimal_ms1_condition = get(\"minimal_ms1_condition\", envir = parent.frame()),\n  compounds_names = get(\"compounds_names\", envir = parent.frame()),\n  high_confidence = get(\"high_confidence\", envir = parent.frame()),\n  remove_ties = get(\"remove_ties\", envir = parent.frame()),\n  summarize = get(\"summarize\", envir = parent.frame())\n)\n\n\n\n\n\n\n\nannot_table_wei_chemo\n\n\nTable containing your chemically weighted annotation\n\n\n\n\ncomponents_table\n\n\nPrepared components file\n\n\n\n\nfeatures_table\n\n\nPrepared features file\n\n\n\n\nstructure_organism_pairs_table\n\n\nTable containing the structure - organism pairs\n\n\n\n\ncandidates_final\n\n\nNumber of final candidates to keep\n\n\n\n\nminimal_ms1_bio\n\n\nMinimal biological score to keep MS1 based annotation\n\n\n\n\nminimal_ms1_chemo\n\n\nMinimal chemical score to keep MS1 based annotation\n\n\n\n\nminimal_ms1_condition\n\n\nCondition to be used. Must be \"OR\" or \"AND\".\n\n\n\n\ncompounds_names\n\n\nReport compounds names. Can be very large. BOOLEAN\n\n\n\n\nhigh_confidence\n\n\nReport high confidence candidates only. BOOLEAN\n\n\n\n\nremove_ties\n\n\nRemove ties. BOOLEAN\n\n\n\n\nsummarize\n\n\nBoolean. summarize results (1 row per feature)\n\n\n\n\n\n\nA table containing the chemically weighted annotation where only a given number of initial candidates are kept\n\n\n\nweight_chemo\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/clean_chemo.html#clean-chemo",
    "href": "man/clean_chemo.html#clean-chemo",
    "title": "tima",
    "section": "",
    "text": "This function cleans the results obtained after chemical weighting\n\n\n\nclean_chemo(\n  annot_table_wei_chemo = get(\"annot_table_wei_chemo\", envir = parent.frame()),\n  components_table = get(\"components_table\", envir = parent.frame()),\n  features_table = get(\"features_table\", envir = parent.frame()),\n  structure_organism_pairs_table = get(\"structure_organism_pairs_table\", envir =\n    parent.frame()),\n  candidates_final = get(\"candidates_final\", envir = parent.frame()),\n  minimal_ms1_bio = get(\"minimal_ms1_bio\", envir = parent.frame()),\n  minimal_ms1_chemo = get(\"minimal_ms1_chemo\", envir = parent.frame()),\n  minimal_ms1_condition = get(\"minimal_ms1_condition\", envir = parent.frame()),\n  compounds_names = get(\"compounds_names\", envir = parent.frame()),\n  high_confidence = get(\"high_confidence\", envir = parent.frame()),\n  remove_ties = get(\"remove_ties\", envir = parent.frame()),\n  summarize = get(\"summarize\", envir = parent.frame())\n)\n\n\n\n\n\n\n\nannot_table_wei_chemo\n\n\nTable containing your chemically weighted annotation\n\n\n\n\ncomponents_table\n\n\nPrepared components file\n\n\n\n\nfeatures_table\n\n\nPrepared features file\n\n\n\n\nstructure_organism_pairs_table\n\n\nTable containing the structure - organism pairs\n\n\n\n\ncandidates_final\n\n\nNumber of final candidates to keep\n\n\n\n\nminimal_ms1_bio\n\n\nMinimal biological score to keep MS1 based annotation\n\n\n\n\nminimal_ms1_chemo\n\n\nMinimal chemical score to keep MS1 based annotation\n\n\n\n\nminimal_ms1_condition\n\n\nCondition to be used. Must be \"OR\" or \"AND\".\n\n\n\n\ncompounds_names\n\n\nReport compounds names. Can be very large. BOOLEAN\n\n\n\n\nhigh_confidence\n\n\nReport high confidence candidates only. BOOLEAN\n\n\n\n\nremove_ties\n\n\nRemove ties. BOOLEAN\n\n\n\n\nsummarize\n\n\nBoolean. summarize results (1 row per feature)\n\n\n\n\n\n\nA table containing the chemically weighted annotation where only a given number of initial candidates are kept\n\n\n\nweight_chemo\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/benchmark_taxize_spectra.html",
    "href": "man/benchmark_taxize_spectra.html",
    "title": "tima",
    "section": "",
    "text": "This function adds taxa to the benchmark\n\n\n\nbenchmark_taxize_spectra(input, keys, org_tax_ott, output)\n\n\n\n\n\n\n\ninput\n\n\nInitial features\n\n\n\n\nkeys\n\n\nSOP keys\n\n\n\n\norg_tax_ott\n\n\nTaxonomy\n\n\n\n\noutput\n\n\nPrepared features\n\n\n\n\n\n\nBecause they are still quite dirty\n\n\n\nThe path to the taxed benchmark\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/benchmark_taxize_spectra.html#benchmark-taxize-spectra",
    "href": "man/benchmark_taxize_spectra.html#benchmark-taxize-spectra",
    "title": "tima",
    "section": "",
    "text": "This function adds taxa to the benchmark\n\n\n\nbenchmark_taxize_spectra(input, keys, org_tax_ott, output)\n\n\n\n\n\n\n\ninput\n\n\nInitial features\n\n\n\n\nkeys\n\n\nSOP keys\n\n\n\n\norg_tax_ott\n\n\nTaxonomy\n\n\n\n\noutput\n\n\nPrepared features\n\n\n\n\n\n\nBecause they are still quite dirty\n\n\n\nThe path to the taxed benchmark\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/prepare_libraries_spectra.html",
    "href": "man/prepare_libraries_spectra.html",
    "title": "tima",
    "section": "",
    "text": "This function prepares spectra to be used for spectral matching\n\n\n\nprepare_libraries_spectra(\n  input = get_params(step = \"prepare_libraries_spectra\")\\$files\\$libraries\\$spectral\\$raw,\n  nam_lib = get_params(step = \"prepare_libraries_spectra\")\\$names\\$libraries,\n  col_ad = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$adduct,\n  col_ce = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$collision_energy,\n  col_ci = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$compound_id,\n  col_em = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$exact_mass,\n  col_in = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$inchi,\n  col_io = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$inchi_no_stereo,\n  col_ik = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$inchikey,\n  col_il = get_params(step =\n    \"prepare_libraries_spectra\")\\$names\\$mgf\\$inchikey_connectivity_layer,\n  col_mf = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$molecular_formula,\n  col_na = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$name,\n  col_po = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$polarity,\n  col_sm = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$smiles,\n  col_sn = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$smiles_no_stereo,\n  col_si = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$spectrum_id,\n  col_sp = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$splash,\n  col_sy = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$synonyms,\n  col_xl = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$xlogp\n)\n\n\n\n\n\n\n\ninput\n\n\nFile containing spectra\n\n\n\n\nnam_lib\n\n\nMetadata to identify the library\n\n\n\n\ncol_ad\n\n\nName of the adduct in mgf\n\n\n\n\ncol_ce\n\n\nName of the collision energy in mgf\n\n\n\n\ncol_ci\n\n\nName of the compound id in mgf\n\n\n\n\ncol_em\n\n\nName of the exact mass in mgf\n\n\n\n\ncol_in\n\n\nName of the InChI in mgf\n\n\n\n\ncol_io\n\n\nName of the InChI without stereo in mgf\n\n\n\n\ncol_ik\n\n\nName of the InChIKey in mgf\n\n\n\n\ncol_il\n\n\nName of the InChIKey without stereo in mgf\n\n\n\n\ncol_mf\n\n\nName of the molecular formula in mgf\n\n\n\n\ncol_na\n\n\nName of the name in mgf\n\n\n\n\ncol_po\n\n\nName of the polarity in mgf\n\n\n\n\ncol_sm\n\n\nName of the SMILES in mgf\n\n\n\n\ncol_sn\n\n\nName of the SMILES without stereo in mgf\n\n\n\n\ncol_si\n\n\nName of the spectrum id in mgf\n\n\n\n\ncol_sp\n\n\nName of the SPLASH in mgf\n\n\n\n\ncol_sy\n\n\nName of the synonyms in mgf\n\n\n\n\ncol_xl\n\n\nName of the xlogp in mgf\n\n\n\n\npolarity\n\n\nMS polarity\n\n\n\n\n\n\nThe path to the prepared spectral library\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\nprepare_libraries_spectra()\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/prepare_libraries_spectra.html#prepare-libraries-of-spectra",
    "href": "man/prepare_libraries_spectra.html#prepare-libraries-of-spectra",
    "title": "tima",
    "section": "",
    "text": "This function prepares spectra to be used for spectral matching\n\n\n\nprepare_libraries_spectra(\n  input = get_params(step = \"prepare_libraries_spectra\")\\$files\\$libraries\\$spectral\\$raw,\n  nam_lib = get_params(step = \"prepare_libraries_spectra\")\\$names\\$libraries,\n  col_ad = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$adduct,\n  col_ce = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$collision_energy,\n  col_ci = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$compound_id,\n  col_em = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$exact_mass,\n  col_in = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$inchi,\n  col_io = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$inchi_no_stereo,\n  col_ik = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$inchikey,\n  col_il = get_params(step =\n    \"prepare_libraries_spectra\")\\$names\\$mgf\\$inchikey_connectivity_layer,\n  col_mf = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$molecular_formula,\n  col_na = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$name,\n  col_po = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$polarity,\n  col_sm = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$smiles,\n  col_sn = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$smiles_no_stereo,\n  col_si = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$spectrum_id,\n  col_sp = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$splash,\n  col_sy = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$synonyms,\n  col_xl = get_params(step = \"prepare_libraries_spectra\")\\$names\\$mgf\\$xlogp\n)\n\n\n\n\n\n\n\ninput\n\n\nFile containing spectra\n\n\n\n\nnam_lib\n\n\nMetadata to identify the library\n\n\n\n\ncol_ad\n\n\nName of the adduct in mgf\n\n\n\n\ncol_ce\n\n\nName of the collision energy in mgf\n\n\n\n\ncol_ci\n\n\nName of the compound id in mgf\n\n\n\n\ncol_em\n\n\nName of the exact mass in mgf\n\n\n\n\ncol_in\n\n\nName of the InChI in mgf\n\n\n\n\ncol_io\n\n\nName of the InChI without stereo in mgf\n\n\n\n\ncol_ik\n\n\nName of the InChIKey in mgf\n\n\n\n\ncol_il\n\n\nName of the InChIKey without stereo in mgf\n\n\n\n\ncol_mf\n\n\nName of the molecular formula in mgf\n\n\n\n\ncol_na\n\n\nName of the name in mgf\n\n\n\n\ncol_po\n\n\nName of the polarity in mgf\n\n\n\n\ncol_sm\n\n\nName of the SMILES in mgf\n\n\n\n\ncol_sn\n\n\nName of the SMILES without stereo in mgf\n\n\n\n\ncol_si\n\n\nName of the spectrum id in mgf\n\n\n\n\ncol_sp\n\n\nName of the SPLASH in mgf\n\n\n\n\ncol_sy\n\n\nName of the synonyms in mgf\n\n\n\n\ncol_xl\n\n\nName of the xlogp in mgf\n\n\n\n\npolarity\n\n\nMS polarity\n\n\n\n\n\n\nThe path to the prepared spectral library\n\n\n\n\nlibrary(\"tima\")\n\ncopy_backbone()\ngo_to_cache()\nprepare_libraries_spectra()\nunlink(\"data\", recursive = TRUE)"
  },
  {
    "objectID": "man/gnps_wrapper.html",
    "href": "man/gnps_wrapper.html",
    "title": "tima",
    "section": "",
    "text": "Wrapper for the C function \"gnps\"\n\n\n\ngnps_wrapper(x, y)\n\n\n\n\n\n\n\nx\n\n\nA numeric matrix.\n\n\n\n\ny\n\n\nA numeric matrix.\n\n\n\n\n\n\nThe result from the C function."
  },
  {
    "objectID": "man/gnps_wrapper.html#wrapper-for-the-c-function-gnps",
    "href": "man/gnps_wrapper.html#wrapper-for-the-c-function-gnps",
    "title": "tima",
    "section": "",
    "text": "Wrapper for the C function \"gnps\"\n\n\n\ngnps_wrapper(x, y)\n\n\n\n\n\n\n\nx\n\n\nA numeric matrix.\n\n\n\n\ny\n\n\nA numeric matrix.\n\n\n\n\n\n\nThe result from the C function."
  },
  {
    "objectID": "man/round_reals.html",
    "href": "man/round_reals.html",
    "title": "tima",
    "section": "",
    "text": "This function rounds reals in columns of a dataframe\n\n\n\nround_reals(df, dig = 5L, cols = c(\"structure_exact_mass\", \"structure_xlogp\"))\n\n\n\n\n\n\n\ndf\n\n\nDataframe to use\n\n\n\n\ndig\n\n\nNumber of digits\n\n\n\n\ncols\n\n\nColumns\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/round_reals.html#round-reals",
    "href": "man/round_reals.html#round-reals",
    "title": "tima",
    "section": "",
    "text": "This function rounds reals in columns of a dataframe\n\n\n\nround_reals(df, dig = 5L, cols = c(\"structure_exact_mass\", \"structure_xlogp\"))\n\n\n\n\n\n\n\ndf\n\n\nDataframe to use\n\n\n\n\ndig\n\n\nNumber of digits\n\n\n\n\ncols\n\n\nColumns\n\n\n\n\n\n\n\nlibrary(\"tima\")\n\nNULL\n\nNULL"
  },
  {
    "objectID": "man/export_output.html",
    "href": "man/export_output.html",
    "title": "tima",
    "section": "",
    "text": "This function creates the output directory if it doesn’t exist and exports the data frame to a tab-delimited file.\n\n\n\nexport_output(x, file = output)\n\n\n\n\n\n\n\nx\n\n\ndata frame to be exported\n\n\n\n\nfile\n\n\npath to the output file\n\n\n\n\n\n\nThe path of the exported file\n\n\n\n\nlibrary(\"tima\")\n\nexport_output(x = data.frame(), file = \"output/file.tsv\")\nunlink(\"output\", recursive = TRUE)"
  },
  {
    "objectID": "man/export_output.html#export-output",
    "href": "man/export_output.html#export-output",
    "title": "tima",
    "section": "",
    "text": "This function creates the output directory if it doesn’t exist and exports the data frame to a tab-delimited file.\n\n\n\nexport_output(x, file = output)\n\n\n\n\n\n\n\nx\n\n\ndata frame to be exported\n\n\n\n\nfile\n\n\npath to the output file\n\n\n\n\n\n\nThe path of the exported file\n\n\n\n\nlibrary(\"tima\")\n\nexport_output(x = data.frame(), file = \"output/file.tsv\")\nunlink(\"output\", recursive = TRUE)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "tima ",
    "section": "",
    "text": "The initial work is available at https://doi.org/10.3389/fpls.2019.01329, with many improvements made since then. The workflow is illustrated below.\n\n\nThis repository contains everything needed to perform Taxonomically Informed Metabolite Annotation.\n\n\nHere is what you minimally need:\n\nA feature list (.csv) (see example features)\nA spectral file corresponding to the feature list (.mgf) (see example spectra)\nThe biological source(s) of the sample(s) you are annotating (.csv) (see example metadata) (File is optional if only a single organism)\n\nOptionally, you may want to add:\n\nAn in-house structure-organism pairs library (we provide LOTUS as starting point for each user)\nYour own manual or automated annotations (we currently support annotations coming from SIRIUS (with some limitations))\n\n\n\n\nAs the package is not (yet) available on CRAN, you will need to install with:\ninstall.packages(\n  \"tima\",\n  repos = c(\n    \"https://taxonomicallyinformedannotation.r-universe.dev\",\n    \"https://bioc.r-universe.dev\",\n    \"https://cloud.r-project.org\"\n  )\n)\nThen, you should be able to install the rest with:\ntima::install()\nNormally, everything you need should then be installed (as tested in here). If for some reason, some packages were not installed, try to install them manually. To avoid such issues, we offer a containerized version (see Docker).\nOnce installed, you are ready to go through our documentation, with the major steps detailed.\nIn case you do not have your data ready, you can obtain some example data using:\ntima::get_example_files()\nOnce you are done, you can open a small GUI to adapt your parameters and launch your job:\ntima::run_app()\nThis command will open a small app in your default browser.\n\n\nA container is also available, together with a small compose file. Main commands are below:\ndocker pull adafede/tima-r\n# docker build . -t adafede/tima-r\ndocker run --user tima-user -v \"$(pwd)/.tima/data:/home/tima-user/.tima/data\" -p 3838:3838 adafede/tima-r Rscript -e \"tima::run_app()\"\n# docker run --user tima-user -v \"$(pwd)/.tima/data:/home/tima-user/.tima/data\" adafede/tima-r Rscript -e \"tima::tima_full()\"\n\n\n\n\nAccording to which steps you used, please give credit to the authors of the tools/resources used.\n\n\nGeneral: https://doi.org/10.3389/fpls.2019.01329\n⚠️ Do not forget to cite which version you used: https://doi.org/10.5281/zenodo.5797920\n\n\n\nGeneral: https://doi.org/10.7554/eLife.70780\n⚠️ Do not forget to cite which version you used: https://doi.org/10.5281/zenodo.5794106\n\n\n\nGeneral: https://doi.org/10.1021/acs.analchem.5b04804\n⚠️ Do not forget to cite which version you used: https://doi.org/10.5281/zenodo.5607185\n\n\n\nGeneral: https://doi.org/10.1038/nbt.3597\n\n\n\nGeneral: https://doi.org/10.1038/s41592-019-0344-8\n\nCSI:FingerId: https://doi.org/10.1073/pnas.1509788112\nZODIAC: https://doi.org/10.1038/s42256-020-00234-6\nCANOPUS: https://doi.org/10.1038/s41587-020-0740-8\nCOSMIC: https://doi.org/10.1038/s41587-021-01045-9\n\n\n\n\n\nThe RforMassSpectrometry packages suite: https://doi.org/10.3390/metabo12020173\nECMDB 2.0: https://doi.org/10.1093/nar/gkv1060\nHMDB 5.0: https://doi.org/10.1093/nar/gkab1062\nMassBank: https://doi.org/10.5281/zenodo.3378723\nMerlin: https://doi.org/10.5281/zenodo.13911806\nNPClassifier: https://doi.org/10.1021/acs.jnatprod.1c00399\nROTL: https://doi.org/10.1111/2041-210X.12593\nSpectral entropy: https://doi.org/10.1038/s41592-021-01331-z"
  },
  {
    "objectID": "index.html#requirements",
    "href": "index.html#requirements",
    "title": "tima ",
    "section": "",
    "text": "Here is what you minimally need:\n\nA feature list (.csv) (see example features)\nA spectral file corresponding to the feature list (.mgf) (see example spectra)\nThe biological source(s) of the sample(s) you are annotating (.csv) (see example metadata) (File is optional if only a single organism)\n\nOptionally, you may want to add:\n\nAn in-house structure-organism pairs library (we provide LOTUS as starting point for each user)\nYour own manual or automated annotations (we currently support annotations coming from SIRIUS (with some limitations))"
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "tima ",
    "section": "",
    "text": "As the package is not (yet) available on CRAN, you will need to install with:\ninstall.packages(\n  \"tima\",\n  repos = c(\n    \"https://taxonomicallyinformedannotation.r-universe.dev\",\n    \"https://bioc.r-universe.dev\",\n    \"https://cloud.r-project.org\"\n  )\n)\nThen, you should be able to install the rest with:\ntima::install()\nNormally, everything you need should then be installed (as tested in here). If for some reason, some packages were not installed, try to install them manually. To avoid such issues, we offer a containerized version (see Docker).\nOnce installed, you are ready to go through our documentation, with the major steps detailed.\nIn case you do not have your data ready, you can obtain some example data using:\ntima::get_example_files()\nOnce you are done, you can open a small GUI to adapt your parameters and launch your job:\ntima::run_app()\nThis command will open a small app in your default browser.\n\n\nA container is also available, together with a small compose file. Main commands are below:\ndocker pull adafede/tima-r\n# docker build . -t adafede/tima-r\ndocker run --user tima-user -v \"$(pwd)/.tima/data:/home/tima-user/.tima/data\" -p 3838:3838 adafede/tima-r Rscript -e \"tima::run_app()\"\n# docker run --user tima-user -v \"$(pwd)/.tima/data:/home/tima-user/.tima/data\" adafede/tima-r Rscript -e \"tima::tima_full()\""
  },
  {
    "objectID": "index.html#main-citations",
    "href": "index.html#main-citations",
    "title": "tima ",
    "section": "",
    "text": "According to which steps you used, please give credit to the authors of the tools/resources used.\n\n\nGeneral: https://doi.org/10.3389/fpls.2019.01329\n⚠️ Do not forget to cite which version you used: https://doi.org/10.5281/zenodo.5797920\n\n\n\nGeneral: https://doi.org/10.7554/eLife.70780\n⚠️ Do not forget to cite which version you used: https://doi.org/10.5281/zenodo.5794106\n\n\n\nGeneral: https://doi.org/10.1021/acs.analchem.5b04804\n⚠️ Do not forget to cite which version you used: https://doi.org/10.5281/zenodo.5607185\n\n\n\nGeneral: https://doi.org/10.1038/nbt.3597\n\n\n\nGeneral: https://doi.org/10.1038/s41592-019-0344-8\n\nCSI:FingerId: https://doi.org/10.1073/pnas.1509788112\nZODIAC: https://doi.org/10.1038/s42256-020-00234-6\nCANOPUS: https://doi.org/10.1038/s41587-020-0740-8\nCOSMIC: https://doi.org/10.1038/s41587-021-01045-9\n\n\n\n\n\nThe RforMassSpectrometry packages suite: https://doi.org/10.3390/metabo12020173\nECMDB 2.0: https://doi.org/10.1093/nar/gkv1060\nHMDB 5.0: https://doi.org/10.1093/nar/gkab1062\nMassBank: https://doi.org/10.5281/zenodo.3378723\nMerlin: https://doi.org/10.5281/zenodo.13911806\nNPClassifier: https://doi.org/10.1021/acs.jnatprod.1c00399\nROTL: https://doi.org/10.1111/2041-210X.12593\nSpectral entropy: https://doi.org/10.1038/s41592-021-01331-z"
  },
  {
    "objectID": "NEWS.html",
    "href": "NEWS.html",
    "title": "tima",
    "section": "",
    "text": "tima\n\n\ntima 2.12.0\n\nAdded a minimal output\nAdded a parameter to limit the numbers of neighbors used for chemical consistency calculation (#193)\nAdded MERLIN spectral libraries (#190)\nAdded RDKit-based structures processing through reticulate (#19)\nBreaking Change: .RDS spectra are now stored more efficiently. To avoid errors, delete any .RDS files created before version 2.12.0\nExternalized spectral libraries preparation to SpectRalLibRaRies\nIntroduced similarity method argument (entropy and GNPS for now)\nImplemented GNPS similarity method in C\nImproved high confidence filtering\nImproved logs using logger (#189)\nKeep (only) best molecular formula and canopus annotations from SIRIUS\nNew ISDB version with 1 million compounds (see https://doi.org/10.5281/zenodo.14887271)\nRefactored MS1 annotation step to work per sample (#194)\nSwitched documentation from pkgdown to altdoc\nUpdated to Massbank version 2025.05.1\nUpdated minimal R version to 4.4.0 (and related Bioconductor dependencies)\n\n\n\ntima 2.11.1 (unreleased)\n\nAdded SIRIUS feature tables support (#185)\nAdded .rar compression support for SIRIUS workspaces (#186)\n\n\n\ntima 2.11.0\n\nAdded convenience function to change small parameters (#177)\nAdded demo files download to the app\nBetter packaging\nImproved documentation\nFixed all CRAN warnings\nFixed some edge cases in spectra import\nReduced dependencies\nReduced exports\nRemoved CompoundDb dependency as it was causing too many issues\nRemoved pak install and switched to r-universe\nReplaced internal functions by Spectra equivalents (#166)\nShinylive version available at https://taxonomicallyinformedannotation.github.io/tima-shinylive\nSimplified install and vignettes\nSwitched from base::lapply to purrr::map\n\n\n\ntima 2.10.0\n\nAdded alt text to vignettes\nAdded the possibility to add internal libraries through the GUI (#159)\nAdded the possibility to filter confident annotations only (#140)\nAdded number of peaks in spectrum\nBrought back some older dependencies to be compatible with oldrel\nChanged package name, usethis update\nClearer handling of SIRIUS scores (#146, #147)\nExposed more parameters to the GUI (#159)\nFacilitated install, no need to clone the directory anymore\nFinally made it to the r-universe\nFixed adducts and removed nitrogen rule\nFixed number of matched peaks\nImproved imports\nReduced warnings\nUpdated benchmarking steps\n\n\n\ntima 2.9.6\n\nAdded light-switch thanks to pkgdown 2.1.0.\nAttempt to simplify installation\nFixed library/adducts confusion (#123)\nFixed some incorrect adduct differences annotations\nRefactored adducts / neutral losses / dimers annotation to allow for more flexibility (#141, #144)\n\n\n\ntima 2.9.5\n\nDo not re-package if already the latest version\nSIRIUS 6 default and compatible (keeping SIRIUS 5 backward compatibility)\nUpdated to Massbank version 2024.06\n\n\n\ntima 2.9.4\n\nAutomated update\nAdded an option to remove ties (#134)\nAdded some details for SIRIUS, added manual workspace addition (#132)\nAdditional preprocessing (reduction) of noisy spectra\nDependencies update\nDocker updates (#131)\nHandle cases when same (feature_id, mslevel) pairs are present within an MGF (#133)\nImproved documentation\nNew working directory at $HOME/.tima\nUpdated R and Bioconductor versions\n\n\n\ntima 2.9.3\n\nAllowed for SIRIUS jobs containing only summaries\nAllowed for underscores in job pattern\nChanged some default values (less stringent)\nDependencies update\nMigrated app testing to shinytest2\nRemoved further some inconsistent MS1 annotations\nRemoved tests dependencies by default\n\n\n\ntima 2.9.2\n\nAdded Nitrogen rule to filter out some annotations\nBetter handling of partial downloads (#118)\nDependencies update (mainly targets 1.5.1, will invalidate previous targets)\nFixed some port issues in Shiny (#122)\nRemoved completely empty columns from final output to avoid confusion (#120)\n\n\n\ntima 2.9.1\n\nAdded Waystation action\nAdded structures from spectral libraries to SOP library (#113)\nExposed all parameters (#107, #108)\nFixed for Zenodo API\nHMDB structures support\nOptimized grep/gsub by adding perl=TRUE or fixed=TRUE\nUpdated to Massbank version 2023.11\nUpdated SIRIUS preparation (#74, #115)\n\n\n\ntima 2.9.0\n\nAdded compounds names as parameter\nAdded MassBank spectral library (#77)\nAllowed files outside data/source (#89)\nAdded RT library as annotation library (#86)\nBetter handling of download errors\nFixed Docker mount path\nImproved naming (#91)\nInternal variables refactoring\nMultiple Shiny fixes and tests addition (#60)\nMultiple fixes (#71, #81, #82)\nNew adducts (#79, #80)\nRefactored adducts, clusters and neutral losses\nRefactored biological and chemical score\nRefactored RT matching (#76)\nRefactored Sirius scores (#92)\nRemoved GNPS dependency by default\n\n\n\ntima 2.8.2\n\nAdded spectral entropy\nAdded MS1 only possibility\nAdded Fluorine adduct\nChanged from pbmclapply to pblapply\nDocumentation improvement\nFixed empty chemical classes\nFixed not classified taxa\nGitHub Actions improvement\nrenv removal\nPerformance improvement by replacing the tidyverse by the fastverse (in progress)\nReduced warnings (CRAN and jscpd)\n\n\n\ntima 2.8.1\n\nAdapted tests\nAdded retry parameter to get_organism_taxonomy_ott\nDependencies update\nMinor fixes\nMoved /params and paths.yaml to /inst as more standard. (see https://r-pkgs.org/misc.html#other-directories)\nPerformance improvement by replacing the tidyverse by the fastverse (in progress)\nReplaced extdata loading\n\n\n\ntima 2.8.0\n\nAdded GUI prototype\nStarted using renv\n\n\n\ntima 2.7.4\n\nClearer vocabulary\nECMDB support\nEdges (mass and spectra-based) and components are generated if not present.\nFixed case when no GNPS job ID\nFurther Targets improvements\nLot of fixes\nParameters refactoring\nRe-introduced Classyfire support.\nRetention time matching additionally to MS2 if RT present in library\nSteps refactoring\n\n\n\ntima 2.7.3\n\nImproved calculations over redundant formulas\nMinor fixes\nParameters refactoring\nSpectral matching update (see https://github.com/rformassspectrometry/MetaboAnnotation/issues/93)\nTargets implementation\n\n\n\ntima 2.7.2\n\nBenchmark update (including negative mode)\nImproved parameters documentation\nMinor fixes\nSpectral comparison + intensity filtering update\nSwitched r-base Docker image to bioconductor with ARM support\n\n\n\ntima 2.7.1\n\nAdded MONA helpers\nAdded parallelization on process_spectra\nAdded sqlite storing for spectra\nImproved code documentation\nImproved testing time\nMinor fixes\n\n\n\ntima 2.7.0\n\nAdded HMDB helpers for both taxo and ISDB\nAdded MS2 annotation capability (kudos @jorainer for the awesome Spectra suite)\nMinor fixes\n\n\n\ntima 2.6.0\n\nAdded Docker container\nChanged data architecture\nMinor fixes\n\n\n\ntima 2.5.6\n\nDependencies removal (e.g. metabo-store)\nMinor fixes\nPartial functions cleanup\n\n\n\ntima 2.5.5\n\nAutomation and parameters improvement\nMinor fixes\n\n\n\ntima 2.5.4\n\nMinor fixes\nMetadata completion improvement\nMolecular formula and adducts formalism improvement\n\n\n\ntima 2.5.3\n\nImports improvements\nLOTUS update\n\n\n\ntima 2.5.2\n\nPackaging improvements\n\n\n\ntima 2.5.1\n\nImproved support for SIRIUS (with new summaries)\n\n\n\ntima 2.5.0\n\nLOTUS update\nMinor fixes\n\n\n\ntima 2.4.0\n\nAdded chemical names and xlogp to output (#33)\nAdded support for case when no consensus is found (#30)\nImproved output (#34)\nMinor fixes\n\n\n\ntima 2.3.0\n\nAdded support for annotation without MN (#28)\nAdded support for multi tool annotations (#27)\nAdded support for classical MN GNPS jobs (#25)\nAdded support for new version of LOTUS\nGeneral improvements for manual inputs\nImproved tests code coverage\nMinor fixes\nUpdated adducts\n\n\n\ntima 2.2.2\n\nAdditional benchmark figure (Candidates distribution)\nMinor fixes\n\n\n\ntima 2.2.1\n\nMinor version name fixes\n\n\n\ntima 2.2.0\n\nAdded benchmark (here)\nVarious fixes\n\n\n\ntima 2.1.0\n\nFixes, deletion of binary dependencies.\n\n\n\ntima 2.0.0\n\nInitial version."
  }
]